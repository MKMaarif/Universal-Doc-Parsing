{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# read json\n",
    "with open('fixed_res/GT/benchmark_data.json', encoding=\"utf8\") as f:\n",
    "    benchmark_data = json.load(f)\n",
    " \n",
    "with open('fixed_res/GT/benchmark-AF24_Alexander_Redman_Final.pdf.json', encoding=\"utf8\") as f:\n",
    "    redman_benchmark_data = json.load(f)\n",
    "\n",
    "with open('fixed_res/GT/benchmark-attention_paper.pdf.json', encoding=\"utf8\") as f:\n",
    "    attention_benchmark_data = json.load(f)\n",
    "\n",
    "with open('fixed_res/GT/benchmark-Astra_AR_2023 (15052024)_LR-1-220.pdf.json', encoding=\"utf8\") as f:\n",
    "    astra_ar_220_benchmark_data = json.load(f)\n",
    "\n",
    "with open('fixed_res/GT/benchmark-AR for improved learnability.pdf.json', encoding=\"utf8\") as f:\n",
    "    ar_benchmark_data = json.load(f)\n",
    "\n",
    "with open('fixed_res/GT/benchmark-Astra_2024_12_31 Rilis Kinerja.pdf.json', encoding=\"utf8\") as f:\n",
    "    astra_2024_benchmark_data = json.load(f)\n",
    "\n",
    "# compare the two dictionaries[\"pages\"]\n",
    "combined_benchmark_data = benchmark_data[\"pages\"].copy() + redman_benchmark_data[\"pages\"].copy() + attention_benchmark_data[\"pages\"].copy() + astra_ar_220_benchmark_data[\"pages\"].copy() + ar_benchmark_data[\"pages\"].copy()\n",
    "\n",
    "len(combined_benchmark_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchmetrics python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Character Error rate (CER)\n",
    "from torchmetrics.text import CharErrorRate\n",
    "from torchmetrics.text import WordErrorRate\n",
    "from torchmetrics.text.rouge import ROUGEScore\n",
    "from torchmetrics.text import BLEUScore\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.translate.meteor_score import single_meteor_score\n",
    "import Levenshtein\n",
    "import tqdm\n",
    "\n",
    "cer = CharErrorRate()\n",
    "wer = WordErrorRate()\n",
    "rouge = ROUGEScore()\n",
    "bleu = BLEUScore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score: \n",
      "rouge1_fmeasure: 1.0\n",
      "rouge1_precision: 1.0\n",
      "rouge1_recall: 1.0\n",
      "rouge2_fmeasure: 1.0\n",
      "rouge2_precision: 1.0\n",
      "rouge2_recall: 1.0\n",
      "rougeL_fmeasure: 1.0\n",
      "rougeL_precision: 1.0\n",
      "rougeL_recall: 1.0\n",
      "rougeLsum_fmeasure: 1.0\n",
      "rougeLsum_precision: 1.0\n",
      "rougeLsum_recall: 1.0\n",
      "\n",
      "BLEU Score: 0.8807735443115234\n",
      "\n",
      "METEOR Score: 0.9635765283355645\n"
     ]
    }
   ],
   "source": [
    "hypothesis = 'CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\\n\\nContents lists available at ScienceDirect\\n\\nCIRP Journal of Manufacturing Science and Technology'\n",
    "reference = 'CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\\n\\nContents lists available at ScienceDirect\\n\\n# CIRP Journal of Manufacturing Science and Technology'\n",
    "\n",
    "# rouge score\n",
    "rouge_score= rouge(preds=hypothesis, target=reference)\n",
    "\n",
    "# bleu score\n",
    "bleu_score = bleu(preds=[hypothesis], target=[[reference]]).item()\n",
    "\n",
    "# meteor score\n",
    "meteor_score = single_meteor_score(word_tokenize(reference), word_tokenize(hypothesis))\n",
    "\n",
    "# print scores\n",
    "print(f\"Rouge Score: \")\n",
    "for key, value in rouge_score.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nBLEU Score: {bleu_score}\")\n",
    "print(f\"\\nMETEOR Score: {meteor_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score: \n",
      "rouge1_fmeasure: 0.9354838728904724\n",
      "rouge1_precision: 0.90625\n",
      "rouge1_recall: 0.9666666388511658\n",
      "rouge2_fmeasure: 0.8666666746139526\n",
      "rouge2_precision: 0.8387096524238586\n",
      "rouge2_recall: 0.8965517282485962\n",
      "rougeL_fmeasure: 0.9354838728904724\n",
      "rougeL_precision: 0.90625\n",
      "rougeL_recall: 0.9666666388511658\n",
      "rougeLsum_fmeasure: 0.9354838728904724\n",
      "rougeLsum_precision: 0.90625\n",
      "rougeLsum_recall: 0.9666666388511658\n",
      "\n",
      "BLEU Score: 0.7173057794570923\n",
      "\n",
      "METEOR Score: 0.9587214041101407\n"
     ]
    }
   ],
   "source": [
    "hypothesis = \"My country economy at this season keeps escaping from the shadow of business though holds a crude oil high, so on an unstable element that continues still, and recovering gradually and well.\"\n",
    "reference = \"My country economy at this season keeps escaping from Odoba of business though holds a crude oil high so on unstable element that continues still, and recovering gradually and well.\"\n",
    "\n",
    "# rouge score\n",
    "rouge_score= rouge(preds=hypothesis, target=reference)\n",
    "\n",
    "# bleu score\n",
    "bleu_score = bleu(preds=[hypothesis], target=[[reference]]).item()\n",
    "\n",
    "# meteor score\n",
    "meteor_score = single_meteor_score(word_tokenize(reference), word_tokenize(hypothesis))\n",
    "\n",
    "# print scores\n",
    "print(f\"Rouge Score: \")\n",
    "for key, value in rouge_score.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nBLEU Score: {bleu_score}\")\n",
    "print(f\"\\nMETEOR Score: {meteor_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rouge Score: \n",
      "rouge1_fmeasure: 0.7058823704719543\n",
      "rouge1_precision: 0.6666666865348816\n",
      "rouge1_recall: 0.75\n",
      "rouge2_fmeasure: 0.5\n",
      "rouge2_precision: 0.47058823704719543\n",
      "rouge2_recall: 0.5333333611488342\n",
      "rougeL_fmeasure: 0.6470588445663452\n",
      "rougeL_precision: 0.6111111044883728\n",
      "rougeL_recall: 0.6875\n",
      "rougeLsum_fmeasure: 0.6470588445663452\n",
      "rougeLsum_precision: 0.6111111044883728\n",
      "rougeLsum_recall: 0.6875\n",
      "\n",
      "BLEU Score: 0.4118037521839142\n",
      "\n",
      "METEOR Score: 0.6944444444444445\n"
     ]
    }
   ],
   "source": [
    "hypothesis = \"It is a guide to action which ensures that the military always obeys the commands of the party\"\n",
    "reference = \"It is a guide to action that ensures that the military will forever heed Party commands\"\n",
    "\n",
    "# rouge score\n",
    "rouge_score= rouge(preds=hypothesis, target=reference)\n",
    "\n",
    "# bleu score\n",
    "bleu_score = bleu(preds=[hypothesis], target=[[reference]]).item()\n",
    "\n",
    "# meteor score\n",
    "meteor_score = single_meteor_score(word_tokenize(reference), word_tokenize(hypothesis))\n",
    "\n",
    "# print scores\n",
    "print(f\"Rouge Score: \")\n",
    "for key, value in rouge_score.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nBLEU Score: {bleu_score}\")\n",
    "print(f\"\\nMETEOR Score: {meteor_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1_fmeasure': tensor(1.),\n",
       " 'rouge1_precision': tensor(1.),\n",
       " 'rouge1_recall': tensor(1.),\n",
       " 'rouge2_fmeasure': tensor(1.),\n",
       " 'rouge2_precision': tensor(1.),\n",
       " 'rouge2_recall': tensor(1.),\n",
       " 'rougeL_fmeasure': tensor(1.),\n",
       " 'rougeL_precision': tensor(1.),\n",
       " 'rougeL_recall': tensor(1.),\n",
       " 'rougeLsum_fmeasure': tensor(1.),\n",
       " 'rougeLsum_precision': tensor(1.),\n",
       " 'rougeLsum_recall': tensor(1.)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = ['CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\\n\\nContents lists available at ScienceDirect\\n\\nCIRP Journal of Manufacturing Science and Technology']\n",
    "target = ['CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\\n\\nContents lists available at ScienceDirect\\n\\n# CIRP Journal of Manufacturing Science and Technology']\n",
    "\n",
    "rouge(preds=preds, target=[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Edit Distance: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def get_normalized_edit_distance(s1, s2):\n",
    "    edit_distance = Levenshtein.distance(s1, s2)\n",
    "    return edit_distance / max(len(s1), len(s2))\n",
    "\n",
    "normalized_edit_distance = Levenshtein.distance(target, preds)\n",
    "print(f\"Normalized Edit Distance: {normalized_edit_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order Score\n",
    "from difflib import SequenceMatcher\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def split_into_blocks(text):\n",
    "    # Basic split: by double newlines (paragraph/section boundaries)\n",
    "    blocks = [block.strip() for block in text.strip().split('\\n') if block.strip()]\n",
    "    # remove empty blocks and blocks with only whitespace\n",
    "    blocks = [block for block in blocks if block and not re.match(r'^\\s*$', block)]\n",
    "    return blocks\n",
    "\n",
    "def get_block_order_indices(pred_blocks, target_blocks):\n",
    "    indices = []\n",
    "    indices_score = []\n",
    "    for j, t_block in enumerate(target_blocks):\n",
    "        sequence_score = []\n",
    "        for i, p_block in enumerate(pred_blocks):\n",
    "            score = SequenceMatcher(None, t_block, p_block).ratio()\n",
    "            sequence_score.append(score)\n",
    "        if sequence_score:\n",
    "            max_index = sequence_score.index(max(sequence_score))\n",
    "            indices.append(max_index)\n",
    "            indices_score.append(max(sequence_score))\n",
    "    return indices, indices_score\n",
    "\n",
    "def order_score_predict(pred_text, target_text):\n",
    "    pred_blocks = split_into_blocks(pred_text)\n",
    "    target_blocks = split_into_blocks(target_text)\n",
    "\n",
    "    target_indices = list(range(len(target_blocks)))\n",
    "    pred_indices, _ = get_block_order_indices(pred_blocks, target_blocks)\n",
    "\n",
    "    if sum(pred_indices) == 0:\n",
    "        return 0.0, 0.0  # not enough data to compare order\n",
    "    \n",
    "    tau, _ = kendalltau(target_indices, pred_indices)\n",
    "    spearman = spearmanr(target_indices, pred_indices)[0]\n",
    "\n",
    "    # if nan print the values\n",
    "    if np.isnan(tau) or np.isnan(spearman):\n",
    "        # print(f\"target_indices: {target_indices}, \\npred_indices: {pred_indices}\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "    return max(tau, 0), max(spearman, 0)  # ensure non-negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# benchmarking function\n",
    "def benchmark(benchmark_pages, parser_pages):\n",
    "    cer_scores = []\n",
    "    wer_scores = []\n",
    "    rouge_scores = []\n",
    "    bleu_scores = []\n",
    "    tau_scores = []\n",
    "    spearman_scores = []\n",
    "    meteor_scores = []\n",
    "    ned_scores = []\n",
    "    # for i, page in enumerate(benchmark_pages):\n",
    "    for i in tqdm.tqdm(range(len(benchmark_pages))):\n",
    "        target = benchmark_pages[i]['markdown']\n",
    "        preds = parser_pages[i]['markdown']\n",
    "\n",
    "        # cer score\n",
    "        cer_score = cer(preds=preds, target=target).item()\n",
    "        cer_scores.append(round(cer_score, 4))\n",
    "\n",
    "        # wer score\n",
    "        wer_score = wer(preds=preds, target=target).item()\n",
    "        wer_scores.append(round(wer_score, 4))\n",
    "\n",
    "        # rouge score\n",
    "        rouge_score = rouge(preds=preds, target=target)\n",
    "        rougeL_recall = rouge_score[\"rougeL_recall\"].item()\n",
    "        rouge_scores.append(round(rougeL_recall, 4))\n",
    "\n",
    "        # bleu score\n",
    "        bleu_score = bleu(preds=[preds], target=[[target]]).item()\n",
    "        bleu_scores.append(round(bleu_score, 4))\n",
    "\n",
    "        # order score\n",
    "        tau_score, spearman_score = order_score_predict(preds, target)\n",
    "        # handle NaN values\n",
    "        # if tau_score == 0.0 and spearman_score == 0.0:\n",
    "        #     print(f\"{i} - tau: {tau_score}, spearman: {spearman_score}\")\n",
    "\n",
    "        tau_score = float(tau_score)\n",
    "        spearman_score = float(spearman_score)\n",
    "        tau_scores.append(round(tau_score, 4))\n",
    "        spearman_scores.append(round(spearman_score, 4))\n",
    "\n",
    "        # meteor score\n",
    "        # tokenize the text into words\n",
    "        target_words = word_tokenize(target)\n",
    "        preds_words = word_tokenize(preds)\n",
    "        meteor_score = single_meteor_score(target_words, preds_words)\n",
    "        meteor_scores.append(round(meteor_score, 4))\n",
    "    \n",
    "        # normalized edit distance score\n",
    "        ned_score = Levenshtein.distance(target, preds) / max(len(target), len(preds))\n",
    "        ned_score = float(ned_score)\n",
    "        ned_scores.append(round(ned_score, 4))\n",
    "\n",
    "        # Print scores\n",
    "        # print(f\"CER: {cer_score:.4f}\")\n",
    "        # print(f\"WER: {wer_score:.4f}\")\n",
    "        # print(f\"METEOR: {meteor_score:.4f}\")\n",
    "        # # print(f\"ROUGE: {rougeL_recall:.4f}\")\n",
    "        # print(f\"BLEU: {bleu_score:.4f}\")\n",
    "        # print(f\"Order Score (Kendall Tau): {tau_score:.4f}\")\n",
    "        # print(f\"Order Score (Spearman): {spearman_score:.4f}\")\n",
    "        # print(f\"Normalized Edit Distance: {ned_score:.4f}\")\n",
    "        # print()\n",
    "\n",
    "    # calculate average scores\n",
    "    avg_cer = sum(cer_scores) / len(cer_scores)\n",
    "    avg_wer = sum(wer_scores) / len(wer_scores)\n",
    "    # avg_rouge = sum(rouge_scores) / len(rouge_scores)\n",
    "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
    "    avg_tau = sum(tau_scores) / len(tau_scores)\n",
    "    avg_spearman = sum(spearman_scores) / len(spearman_scores)\n",
    "    avg_meteor = sum(meteor_scores) / len(meteor_scores)\n",
    "    avg_ned = sum(ned_scores) / len(ned_scores)\n",
    "    \n",
    "    print(f\"CER List: {cer_scores}\")\n",
    "    print(f\"Average CER: {avg_cer:.4f}\")\n",
    "    print(f\"WER List: {wer_scores}\")\n",
    "    print(f\"Average WER: {avg_wer:.4f}\")\n",
    "    print(f\"Meteor List: {meteor_scores}\")\n",
    "    print(f\"Average Meteor: {avg_meteor:.4f}\")\n",
    "    # print(f\"ROUGE List: {rouge_scores}\")\n",
    "    # print(f\"Average ROUGE: {avg_rouge:.4f}\")\n",
    "    print(f\"BLEU List: {bleu_scores}\")\n",
    "    print(f\"Average BLEU: {avg_bleu:.4f}\")\n",
    "    print(f\"Order Score (Kendall Tau) List: {tau_scores}\")\n",
    "    print(f\"Average Order Score (Kendall Tau): {avg_tau:.4f}\")\n",
    "    print(f\"Order Score (Spearman) List: {spearman_scores}\")\n",
    "    print(f\"Average Order Score (Spearman): {avg_spearman:.4f}\")\n",
    "    # print(f\"Normalized Edit Distance List: {ned_scores}\")\n",
    "    # print(f\"Average Normalized Edit Distance: {avg_ned:.4f}\")\n",
    "\n",
    "    # return {\n",
    "    #     \"cer\": cer_scores,\n",
    "    #     \"wer\": wer_scores,\n",
    "    #     \"meteor\": meteor_scores,\n",
    "    #     # \"rouge\": rouge_scores,\n",
    "    #     \"bleu\": bleu_scores,\n",
    "    #     \"tau\": tau_scores,\n",
    "    #     \"spearman\": spearman_scores,\n",
    "    #     # \"ned\": ned_scores\n",
    "    # }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length data: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [41:05<00:00,  7.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER List: [0.1635, 0.4851, 0.1707, 0.5275, 0.098, 1.9614, 0.0431, 0.672, 0.6787, 1.4829, 0.5732, 0.3585, 0.475, 0.3668, 0.4514, 0.4117, 1.9339, 1.0063, 0.1881, 0.3743, 0.2486, 0.6615, 0.5093, 0.3147, 0.4134, 0.4509, 0.3236, 0.428, 0.3309, 0.4141, 0.2822, 0.363, 0.37, 0.5681, 0.3476, 11.5829, 0.6345, 0.2355, 0.9195, 0.2297, 0.3941, 0.5724, 0.7192, 0.289, 0.6467, 0.3102, 0.415, 0.4708, 0.0876, 0.5081, 0.414, 0.6126, 0.3471, 0.3947, 0.6371, 0.3655, 0.3081, 0.6585, 0.5418, 0.3753, 0.4229, 0.4062, 0.4669, 0.5204, 0.5947, 0.4906, 0.1584, 0.9758, 0.5608, 0.1297, 0.0251, 0.0227, 0.3206, 0.3169, 0.0585, 0.141, 0.0468, 0.2585, 0.0635, 0.113, 0.0142, 0.0102, 15.5211, 1.5145, 2.9838, 0.1768, 0.0216, 0.0251, 0.5848, 0.2441, 0.5863, 0.8621, 0.552, 0.0663, 0.4926, 0.421, 0.4988, 0.6024, 0.6034, 0.6589, 0.5933, 0.5627, 0.0718, 0.4264, 0.3233, 0.1824, 0.3184, 0.1872, 0.1542, 0.164, 0.3721, 0.0917, 0.4486, 0.444, 0.3394, 0.3888, 0.5884, 0.1437, 0.0673, 0.6011, 0.1537, 0.1038, 0.2975, 0.6592, 0.445, 0.3786, 0.3854, 0.0873, 0.4129, 0.6278, 0.6059, 0.0621, 0.1577, 0.162, 0.4624, 0.0969, 0.0787, 0.0827, 0.5231, 0.1145, 0.457, 0.1229, 0.2573, 0.8354, 0.7101, 0.5532, 0.3294, 0.2936, 0.6458, 0.1927, 0.4579, 0.4602, 0.6917, 0.5551, 0.2418, 0.3304, 0.3355, 0.5242, 0.1955, 0.2131, 0.4849, 0.3729, 0.3049, 0.426, 0.4624, 0.6319, 0.4198, 0.6449, 0.3923, 0.7044, 0.5081, 0.4758, 0.1389, 0.6463, 0.489, 0.5094, 0.3016, 0.2644, 0.5049, 0.4506, 0.4933, 0.1804, 0.1324, 0.1477, 0.5855, 0.6081, 0.8577, 0.482, 0.5467, 0.5926, 0.2104, 0.315, 0.6734, 0.6647, 0.576, 0.7306, 0.6835, 0.6422, 0.6804, 0.5482, 0.36, 0.6695, 0.413, 0.3694, 0.1947, 0.2939, 0.0822, 0.5796, 0.1956, 0.5686, 0.3301, 0.0837, 0.3063, 0.3741, 0.3662, 0.6109, 0.479, 0.576, 0.0625, 0.5502, 0.325, 0.2226, 0.4047, 0.7256, 0.0678, 0.7008, 0.8331, 0.0649, 0.6473, 0.0727, 0.0689, 0.3416, 0.4441, 0.1445, 0.2558, 0.4964, 0.3341, 0.4756, 4.3628, 0.4216, 0.4338, 0.3889, 0.5296, 0.177, 0.1079, 0.5262, 0.1742, 0.6502, 0.488, 0.1822, 0.4211, 0.6192, 0.4285, 0.4275, 0.1216, 0.552, 0.5549, 0.208, 0.0819, 0.3646, 0.5294, 0.214, 0.6087, 0.2919, 0.3863, 0.1139, 0.5581, 0.2379, 0.1893, 0.5285, 0.3505, 0.6791, 0.2428, 0.13, 0.6685, 0.3185, 0.0371, 0.3049, 0.1446, 0.7199, 0.3421, 0.3565, 0.7197, 0.5333, 0.1574, 0.545, 0.4034, 0.6893, 0.3319, 0.4636, 0.1567, 0.4617, 0.4583, 0.246, 0.0552, 0.5911, 0.2999, 0.6334, 0.4446, 0.5764, 0.2626, 0.2508, 0.1098, 0.311, 0.4537, 0.0349, 0.0126, 0.0457, 0.1304, 0.3722, 0.6075, 0.4705, 0.7014, 0.0379]\n",
      "Average CER: 0.5087\n",
      "WER List: [0.1256, 0.5764, 0.1991, 0.5961, 0.1436, 2.25, 0.0545, 0.4667, 0.1716, 1.9679, 1.151, 0.6338, 0.4745, 0.3191, 0.3856, 0.5594, 2.1351, 1.6497, 0.4211, 0.5369, 0.4607, 0.4811, 0.57, 0.4315, 0.4975, 0.4569, 0.4086, 0.7757, 0.6813, 0.3498, 0.3951, 0.4843, 0.5347, 0.6578, 0.5914, 8.7366, 0.5373, 0.4981, 0.8393, 0.3465, 0.6359, 0.5926, 0.6298, 0.5155, 0.592, 0.5, 0.412, 0.617, 0.2014, 0.3393, 0.615, 1.5887, 0.5699, 0.5153, 1.0323, 0.6869, 0.3205, 0.6058, 0.4789, 0.4728, 0.9505, 0.5153, 0.5051, 0.5097, 0.6381, 0.7286, 0.3898, 1.1204, 0.1133, 0.1515, 0.0363, 0.0916, 0.2795, 0.3969, 0.1323, 0.1081, 0.113, 0.1154, 0.1532, 0.0633, 0.042, 0.0695, 24.1158, 1.7714, 3.4474, 0.2222, 0.0302, 0.0476, 0.8182, 0.4962, 0.6256, 0.9278, 0.9184, 0.129, 0.1893, 0.3966, 1.0565, 0.1256, 0.3304, 0.1881, 0.1627, 0.4886, 0.1091, 0.5215, 0.4124, 0.2014, 0.3454, 0.2123, 0.1818, 0.1856, 0.5714, 0.2955, 0.6462, 0.4836, 0.3666, 0.3926, 0.6685, 0.1445, 0.0794, 0.7244, 0.0868, 0.1168, 0.4205, 0.7209, 0.6167, 0.4279, 0.4492, 0.1098, 0.4554, 0.6194, 0.6995, 0.0549, 0.1748, 0.1675, 0.495, 0.0952, 0.0898, 0.1082, 0.5447, 0.1311, 0.5503, 0.13, 0.1718, 1.0156, 1.039, 0.5854, 0.3211, 0.3852, 0.625, 0.8165, 0.5306, 0.4351, 0.2215, 0.6389, 0.3358, 0.3333, 0.3771, 0.6285, 0.2484, 0.3193, 0.6, 0.426, 0.3761, 0.475, 0.5912, 0.7254, 0.5154, 0.7973, 0.4801, 0.7529, 0.5657, 0.5796, 0.1717, 0.7897, 0.4846, 0.6129, 0.2931, 0.2537, 0.555, 0.5138, 0.5358, 0.1762, 0.1359, 0.146, 0.734, 0.8103, 0.9423, 0.5698, 0.6743, 0.6211, 0.314, 0.4196, 0.1348, 0.1261, 0.1284, 0.1896, 0.1227, 0.1365, 0.1108, 0.1535, 0.4961, 0.8375, 0.5, 0.4667, 0.2807, 0.322, 0.1021, 0.723, 0.2376, 0.6667, 0.4452, 0.0832, 0.303, 0.378, 0.3855, 0.6795, 0.5056, 0.7778, 0.0637, 0.7218, 0.4286, 0.837, 0.481, 0.9475, 0.0812, 0.9061, 1.2436, 0.0909, 0.7048, 0.0845, 0.0982, 0.3512, 0.5088, 0.1877, 0.3814, 0.5657, 0.378, 0.4187, 5.072, 0.446, 0.5253, 0.4332, 0.6627, 0.166, 0.146, 0.56, 0.1784, 0.7624, 0.5841, 0.2203, 0.4798, 0.7572, 0.4262, 0.455, 0.141, 0.5719, 0.675, 0.2141, 0.1191, 0.4299, 0.5152, 0.2589, 0.6029, 0.3218, 0.5026, 0.1598, 0.6736, 0.3036, 0.2664, 0.5302, 0.4192, 0.6614, 0.2564, 0.1844, 0.8324, 0.3887, 0.0513, 0.3439, 0.1655, 0.809, 0.4224, 0.3702, 0.7732, 0.6248, 0.1986, 0.6695, 0.4808, 0.8425, 0.4567, 0.5136, 0.2104, 0.5047, 0.5075, 0.4618, 0.0904, 0.7436, 0.3333, 0.6758, 0.5301, 0.7427, 0.5159, 0.3602, 0.1526, 0.3607, 0.5304, 0.0816, 0.0304, 0.0444, 0.1669, 0.4295, 0.115, 0.4675, 0.8, 0.1412]\n",
      "Average WER: 0.5862\n",
      "Meteor List: [0.8936, 0.6486, 0.8134, 0.4297, 0.5348, 0.6188, 0.9589, 0.4281, 0.6944, 0.7004, 0.6183, 0.7732, 0.5057, 0.7438, 0.5972, 0.642, 0.7678, 0.6752, 0.8862, 0.5184, 0.8092, 0.5991, 0.7648, 0.7477, 0.7468, 0.7869, 0.6615, 0.7434, 0.7759, 0.6521, 0.7823, 0.7656, 0.7486, 0.6931, 0.7551, 0.2786, 0.5372, 0.7593, 0.7401, 0.8111, 0.8077, 0.6105, 0.3557, 0.6071, 0.5119, 0.7121, 0.7163, 0.8965, 0.8947, 0.6818, 0.7377, 0.617, 0.8609, 0.7654, 0.6618, 0.7109, 0.6451, 0.6458, 0.6958, 0.7313, 0.6812, 0.5549, 0.5763, 0.5483, 0.5916, 0.7902, 0.8317, 0.7862, 0.5934, 0.8699, 0.9894, 0.9548, 0.6433, 0.6423, 0.9101, 0.891, 0.9475, 0.8723, 0.8745, 0.9237, 0.9714, 0.9765, 0.0226, 0.5927, 0.4806, 0.8847, 0.9755, 0.9715, 0.7274, 0.5593, 0.4173, 0.1158, 0.5271, 0.9689, 0.8764, 0.8359, 0.5483, 0.5207, 0.4713, 0.7978, 0.591, 0.4459, 0.9335, 0.9248, 0.8609, 0.9247, 0.7352, 0.9261, 0.9196, 0.9436, 0.1064, 0.6253, 0.759, 0.9745, 0.6853, 0.846, 0.6954, 0.9843, 0.9747, 0.5204, 0.9131, 0.9715, 0.8548, 0.6936, 0.6843, 0.969, 0.7826, 0.9462, 0.6936, 0.8171, 0.7329, 0.9754, 0.8892, 0.8153, 0.9551, 0.9781, 0.9628, 0.9451, 0.5505, 0.8911, 0.9642, 0.9762, 0.8359, 0.6464, 0.7186, 0.6995, 0.7539, 0.8234, 0.0806, 0.6266, 0.5782, 0.5566, 0.5865, 0.5305, 0.8132, 0.6923, 0.9558, 0.7872, 0.9054, 0.7275, 0.7306, 0.9488, 0.7728, 0.8323, 0.842, 0.8805, 0.9462, 0.8547, 0.9504, 0.8782, 0.6618, 0.8764, 0.9413, 0.8722, 0.5561, 0.6012, 0.953, 0.9461, 0.4694, 0.5309, 0.4929, 0.945, 0.9591, 0.9701, 0.6529, 0.5399, 0.0941, 0.9615, 0.9415, 0.7763, 0.7703, 0.7682, 0.775, 0.77, 0.8294, 0.7812, 0.8236, 0.8021, 0.8107, 0.7694, 0.8568, 0.6081, 0.1064, 0.4053, 0.8299, 0.8285, 0.9668, 0.7186, 0.9307, 0.7276, 0.6875, 0.9331, 0.9504, 0.9171, 0.9236, 0.6123, 0.5137, 0.8972, 0.9854, 0.7035, 0.2679, 0.5527, 0.5978, 0.9024, 0.982, 0.8791, 0.5193, 0.917, 0.4241, 0.9339, 0.9773, 0.7234, 0.9799, 0.9561, 0.7867, 0.4999, 0.9753, 0.92, 0.3593, 0.9687, 0.9544, 0.9054, 0.9202, 0.8306, 0.9634, 0.5205, 0.9555, 0.769, 0.7175, 0.9102, 0.6352, 0.8981, 0.6922, 0.9504, 0.9594, 0.4594, 0.6277, 0.8822, 0.9262, 0.6338, 0.5633, 0.9267, 0.5226, 0.7545, 0.9041, 0.9306, 0.6565, 0.8766, 0.8417, 0.5649, 0.8269, 0.6499, 0.8131, 0.9628, 0.9365, 0.8826, 0.981, 0.9032, 0.9726, 0.2928, 0.7465, 0.9499, 0.7273, 0.9217, 0.8495, 0.4425, 0.7253, 0.8027, 0.6773, 0.9573, 0.8803, 0.9086, 0.9704, 0.887, 0.9716, 0.8257, 0.939, 0.9056, 0.592, 0.8017, 0.7481, 0.7342, 0.98, 0.6723, 0.8205, 0.9589, 0.9794, 0.9491, 0.8062, 0.6266, 0.7803, 0.6686, 0.8782, 0.8673]\n",
      "Average Meteor: 0.7585\n",
      "BLEU List: [0.8129, 0.3596, 0.8048, 0.3681, 0.8271, 0.1989, 0.9439, 0.465, 0.7681, 0.1649, 0.1918, 0.3555, 0.3581, 0.4537, 0.5519, 0.3764, 0.179, 0.1863, 0.5501, 0.2987, 0.4232, 0.3707, 0.3829, 0.3226, 0.4748, 0.4926, 0.4115, 0.2889, 0.2786, 0.6575, 0.4877, 0.3585, 0.3768, 0.3708, 0.3033, 0.0273, 0.2569, 0.3472, 0.2643, 0.4895, 0.3396, 0.3433, 0.2352, 0.3047, 0.4367, 0.358, 0.467, 0.4978, 0.6972, 0.5791, 0.5156, 0.1833, 0.6058, 0.5158, 0.3452, 0.3346, 0.657, 0.3752, 0.494, 0.355, 0.3141, 0.3079, 0.3004, 0.3482, 0.3624, 0.3974, 0.3822, 0.2888, 0.846, 0.8203, 0.9404, 0.8644, 0.6473, 0.5908, 0.8006, 0.8157, 0.8133, 0.7972, 0.8316, 0.863, 0.9151, 0.8346, 0.0, 0.2549, 0.1438, 0.7731, 0.9478, 0.9214, 0.2162, 0.2772, 0.2192, 0.0056, 0.2219, 0.726, 0.8466, 0.8041, 0.3141, 0.8487, 0.558, 0.6869, 0.6852, 0.3812, 0.8345, 0.8267, 0.6525, 0.8219, 0.673, 0.8338, 0.8518, 0.8581, 0.0, 0.3535, 0.2579, 0.9034, 0.6114, 0.8211, 0.6321, 0.944, 0.9508, 0.3931, 0.9117, 0.9098, 0.4786, 0.3459, 0.3174, 0.8995, 0.7467, 0.8965, 0.7334, 0.779, 0.6524, 0.9494, 0.848, 0.807, 0.892, 0.9448, 0.9283, 0.8863, 0.362, 0.8333, 0.914, 0.9443, 0.796, 0.2907, 0.1846, 0.5506, 0.6346, 0.6302, 0.0, 0.2241, 0.3224, 0.4648, 0.7029, 0.2968, 0.6317, 0.572, 0.9167, 0.7432, 0.7184, 0.4766, 0.6342, 0.8003, 0.72, 0.6473, 0.8097, 0.6295, 0.8849, 0.8484, 0.9058, 0.8415, 0.5471, 0.7753, 0.8862, 0.8383, 0.4194, 0.532, 0.9129, 0.9157, 0.3073, 0.3934, 0.3487, 0.9054, 0.9071, 0.9385, 0.2872, 0.158, 0.0046, 0.899, 0.8258, 0.586, 0.5287, 0.4716, 0.8451, 0.8441, 0.8663, 0.8236, 0.8384, 0.8303, 0.8922, 0.8166, 0.3934, 0.3085, 0.0, 0.3509, 0.7131, 0.7689, 0.8952, 0.6988, 0.7822, 0.4078, 0.5023, 0.908, 0.9358, 0.8162, 0.8837, 0.5543, 0.3641, 0.9081, 0.9131, 0.7191, 0.0, 0.2016, 0.4028, 0.8974, 0.942, 0.9161, 0.138, 0.9048, 0.2919, 0.911, 0.9049, 0.6302, 0.9383, 0.8237, 0.6186, 0.3465, 0.9178, 0.831, 0.0905, 0.9416, 0.8823, 0.8208, 0.8206, 0.8173, 0.8494, 0.3213, 0.9058, 0.7176, 0.5237, 0.8382, 0.4655, 0.8472, 0.496, 0.928, 0.893, 0.295, 0.4275, 0.7081, 0.8712, 0.5206, 0.4153, 0.9013, 0.4061, 0.6563, 0.6785, 0.8606, 0.5517, 0.7495, 0.7581, 0.3996, 0.7436, 0.5707, 0.6791, 0.8253, 0.9073, 0.7356, 0.9462, 0.7779, 0.8959, 0.0953, 0.6001, 0.9276, 0.6744, 0.8968, 0.7753, 0.2797, 0.4622, 0.7023, 0.506, 0.8988, 0.7475, 0.8693, 0.9163, 0.6483, 0.8714, 0.745, 0.8892, 0.5869, 0.4203, 0.7333, 0.258, 0.5933, 0.8462, 0.5685, 0.6234, 0.8901, 0.9508, 0.942, 0.852, 0.478, 0.8838, 0.5805, 0.5321, 0.8016]\n",
      "Average BLEU: 0.6124\n",
      "Order Score (Kendall Tau) List: [0.5657, 0.5542, 0.9294, 0.7543, 0.9986, 0.6183, 0.6093, 0.6022, 0.8179, 0.5546, 0.2021, 0.4612, 0.4459, 0.6203, 0.6792, 0.6814, 0.8238, 0.6635, 0.8176, 0.6684, 0.4455, 0.5486, 0.6082, 0.4025, 0.5635, 0.6801, 0.6105, 0.5067, 0.4443, 0.6602, 0.5557, 0.6338, 0.8104, 0.6348, 0.8345, 0.5201, 0.3457, 0.8027, 0.5739, 0.7866, 0.8073, 0.5449, 0.4428, 0.7946, 0.4356, 0.7203, 0.5318, 0.8656, 0.9705, 0.4059, 0.3567, 0.1442, 0.7157, 0.6542, 0.5718, 0.6721, 0.6486, 0.5138, 0.5311, 0.5137, 0.5941, 0.7184, 0.5222, 0.6209, 0.4134, 0.435, 0.5507, 0.7759, 0.9848, 0.6051, 1.0, 0.7871, 0.0925, 0.0, 0.9705, 0.7831, 1.0, 0.8648, 0.916, 0.9298, 0.8666, 1.0, 0.5477, 1.0, 0.3333, 0.9048, 0.8441, 0.0, 0.725, 0.748, 0.7571, 0.1006, 0.7364, 0.9996, 0.944, 0.5325, 0.8173, 0.8969, 0.9978, 0.5038, 0.9967, 0.8, 0.8328, 0.3871, 0.6855, 0.4402, 0.715, 0.4502, 0.5874, 0.3828, 0.9129, 1.0, 0.341, 0.6618, 0.5075, 0.2968, 0.4212, 0.2535, 0.7537, 0.1171, 0.9766, 0.7802, 0.6873, 0.0954, 0.1591, 0.6923, 0.3576, 0.4882, 0.7285, 0.17, 0.4021, 0.7566, 0.716, 0.6667, 0.7714, 0.4737, 0.4956, 0.853, 0.2915, 0.9244, 0.4177, 0.4095, 0.7933, 0.0, 0.6602, 0.6274, 0.8859, 0.7321, 0.4472, 0.8172, 0.8605, 0.6719, 0.9208, 0.5519, 0.9484, 0.6506, 0.8903, 0.5455, 0.9167, 0.9435, 0.3665, 0.8161, 0.7787, 0.6798, 0.5896, 0.5336, 0.404, 0.3675, 0.5509, 0.26, 0.6668, 0.5217, 0.9068, 0.555, 0.7308, 0.7183, 0.678, 0.7374, 0.4962, 0.8224, 0.6525, 0.5242, 0.6632, 0.6418, 0.3233, 0.2104, 0.0, 0.9605, 0.4638, 0.4054, 0.8326, 0.7459, 0.9917, 0.8984, 0.8462, 0.9115, 0.8595, 0.8482, 0.9257, 0.8786, 0.8594, 0.2, 0.8367, 0.2694, 0.3191, 0.4534, 0.4089, 0.2265, 0.6507, 0.4667, 0.1137, 0.3593, 0.4844, 0.8668, 0.7132, 0.1354, 0.549, 0.0602, 0.9235, 0.1068, 0.8165, 0.9722, 0.1826, 0.1818, 0.6171, 0.4676, 0.7278, 1.0, 0.2981, 0.561, 0.5025, 0.3519, 0.3637, 1.0, 0.5683, 0.2037, 0.8697, 0.7353, 0.2669, 0.2746, 0.8616, 0.8405, 0.8269, 0.2772, 0.7021, 0.4684, 0.9475, 0.6074, 0.6068, 0.7698, 0.5868, 0.9574, 0.9575, 0.3636, 0.9185, 0.711, 0.5001, 0.5025, 0.9223, 0.7217, 0.3221, 0.6257, 0.1334, 0.9313, 0.8724, 0.7613, 0.335, 0.7333, 0.8904, 0.6769, 0.6618, 0.0926, 0.5832, 0.7081, 0.5193, 0.7333, 0.8705, 0.7692, 0.5001, 0.2981, 0.3492, 0.2873, 0.0, 0.2933, 0.6146, 0.5883, 0.3019, 0.5843, 0.4889, 0.6667, 0.8603, 0.3693, 0.4838, 0.751, 0.9022, 0.5604, 0.7001, 0.3303, 0.66, 0.1642, 0.7226, 0.132, 1.0, 0.7821, 0.4495, 0.8155, 0.8441, 0.8446, 0.5737, 0.1818, 0.6204, 0.0332, 0.7342, 0.8769]\n",
      "Average Order Score (Kendall Tau): 0.6108\n",
      "Order Score (Spearman) List: [0.6277, 0.6426, 0.9666, 0.779, 0.9999, 0.5749, 0.6781, 0.7306, 0.7567, 0.6551, 0.2932, 0.5328, 0.5228, 0.7053, 0.7554, 0.7975, 0.9125, 0.776, 0.8726, 0.8478, 0.5139, 0.6544, 0.7104, 0.4321, 0.6512, 0.786, 0.7488, 0.6445, 0.5333, 0.7548, 0.6233, 0.7269, 0.8901, 0.7259, 0.9348, 0.645, 0.4263, 0.9167, 0.6834, 0.8958, 0.9069, 0.6323, 0.4981, 0.8152, 0.5313, 0.7008, 0.6437, 0.9374, 0.9934, 0.4686, 0.4571, 0.1888, 0.7747, 0.7761, 0.6725, 0.7416, 0.7394, 0.665, 0.6258, 0.609, 0.6859, 0.8118, 0.6433, 0.7201, 0.4925, 0.5347, 0.6494, 0.8912, 0.9975, 0.5346, 1.0, 0.7785, 0.1314, 0.0, 0.9912, 0.7223, 1.0, 0.8305, 0.9266, 0.9432, 0.8974, 1.0, 0.7379, 1.0, 0.5, 0.9643, 0.9203, 0.0, 0.8265, 0.7168, 0.7575, 0.0887, 0.8351, 1.0, 0.9731, 0.613, 0.9025, 0.9055, 0.9997, 0.5359, 0.9995, 0.7796, 0.8732, 0.3063, 0.5931, 0.5022, 0.7463, 0.4893, 0.6777, 0.2198, 0.9487, 1.0, 0.1829, 0.7034, 0.526, 0.4044, 0.4665, 0.2762, 0.8218, 0.0754, 0.9958, 0.7582, 0.7447, 0.1362, 0.0, 0.7253, 0.3594, 0.4109, 0.853, 0.0442, 0.4421, 0.8419, 0.7847, 0.6207, 0.8766, 0.2895, 0.4646, 0.9131, 0.2585, 0.9632, 0.3617, 0.3, 0.7965, 0.0, 0.7682, 0.7457, 0.9428, 0.7623, 0.4743, 0.8434, 0.9202, 0.7438, 0.9556, 0.6151, 0.9758, 0.6703, 0.9519, 0.5509, 0.9342, 0.9192, 0.4522, 0.83, 0.8293, 0.6399, 0.6664, 0.663, 0.3936, 0.3657, 0.6505, 0.2259, 0.756, 0.4987, 0.9731, 0.6166, 0.8388, 0.8451, 0.7862, 0.8574, 0.5549, 0.9012, 0.8015, 0.6282, 0.7833, 0.7343, 0.3827, 0.2405, 0.0, 0.9921, 0.5031, 0.346, 0.8689, 0.7197, 0.9989, 0.8641, 0.822, 0.8897, 0.8394, 0.7976, 0.8954, 0.8617, 0.8897, 0.2571, 0.8944, 0.2052, 0.3376, 0.5085, 0.3069, 0.2017, 0.706, 0.4286, 0.0, 0.3085, 0.4849, 0.9459, 0.815, 0.0, 0.6265, 0.0, 0.9522, 0.0695, 0.8944, 0.9938, 0.1718, 0.1322, 0.5746, 0.4766, 0.7285, 1.0, 0.3284, 0.5538, 0.4548, 0.4155, 0.3774, 1.0, 0.6037, 0.1827, 0.9543, 0.7542, 0.3384, 0.3536, 0.9368, 0.906, 0.935, 0.2392, 0.6781, 0.428, 0.9891, 0.6699, 0.6629, 0.7738, 0.5948, 0.9912, 0.9872, 0.3664, 0.9755, 0.727, 0.4977, 0.4619, 0.9648, 0.7701, 0.3968, 0.6614, 0.102, 0.9702, 0.933, 0.7703, 0.3758, 0.7455, 0.9655, 0.7437, 0.7084, 0.0, 0.5372, 0.7486, 0.5664, 0.7529, 0.927, 0.79, 0.516, 0.4554, 0.2646, 0.143, 0.0, 0.1957, 0.6502, 0.6676, 0.3803, 0.614, 0.4862, 0.7333, 0.8547, 0.4807, 0.5138, 0.8609, 0.9477, 0.7495, 0.7937, 0.3235, 0.7285, 0.0836, 0.7437, 0.1845, 1.0, 0.816, 0.4863, 0.9096, 0.8884, 0.84, 0.6167, 0.1844, 0.6725, 0.0, 0.7679, 0.8741]\n",
      "Average Order Score (Spearman): 0.6455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read json\n",
    "with open('fixed_res/Ours/dummy-data.pdf.json', encoding='utf8') as f:\n",
    "    dummy_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Ours/AF24_Alexander_Redman_Final.pdf.json', encoding=\"utf8\") as f:\n",
    "    redman_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Ours/attention_paper.pdf.json', encoding=\"utf8\") as f:\n",
    "    attention_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Ours/Astra_AR_2023 (15052024)_LR-1-220.pdf.json', encoding=\"utf8\") as f:\n",
    "    astra_ar_220_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Ours/AR for improved learnability.pdf.json', encoding=\"utf8\") as f:\n",
    "    ar_res = json.load(f)\n",
    "\n",
    "combined_res = dummy_res[\"pages\"].copy() + redman_res[\"pages\"].copy() + attention_res[\"pages\"].copy() + astra_ar_220_res[\"pages\"].copy() + ar_res[\"pages\"].copy()\n",
    "\n",
    "# benchmarking llamaparse\n",
    "print(\"Length data:\", len(combined_res))\n",
    "benchmark(combined_benchmark_data, combined_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 314/314 [38:30<00:00,  7.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER List: [0.1316, 0.8655, 0.9166, 0.2709, 0.2184, 0.0043, 0.0431, 0.0064, 0.0918, 0.5785, 0.3372, 0.4243, 0.3485, 0.1998, 0.3711, 0.214, 0.1844, 0.6911, 0.7695, 0.6433, 0.5431, 0.098, 0.5294, 0.5299, 0.528, 0.5044, 0.5609, 0.6555, 0.6265, 0.3898, 0.5584, 0.7563, 0.5007, 0.6576, 0.4639, 0.1749, 0.5029, 0.7421, 0.3887, 0.0131, 0.072, 0.064, 0.0054, 0.0439, 0.6856, 0.0496, 0.0403, 0.6789, 0.1088, 0.8736, 0.5957, 0.5907, 0.1825, 0.7197, 0.7041, 0.116, 0.3279, 0.6924, 0.6006, 0.6476, 0.7132, 0.3088, 0.7243, 0.678, 0.7104, 0.902, 0.0672, 0.7026, 0.0155, 0.0, 0.0934, 0.0014, 0.9813, 0.0018, 0.0095, 0.0008, 0.0, 0.0448, 0.6642, 0.0011, 0.0012, 0.0012, 0.7074, 1.1253, 0.6498, 0.0101, 0.0036, 0.0126, 0.4898, 0.3506, 0.0384, 0.0085, 1.3064, 0.4587, 0.0258, 0.412, 0.353, 0.0363, 0.0564, 0.173, 0.0467, 0.0888, 0.0821, 0.148, 0.0986, 0.0777, 0.4066, 0.0104, 0.1047, 0.0883, 12.7674, 0.0858, 0.6709, 0.021, 0.2296, 0.3142, 0.4251, 0.4271, 0.576, 0.5339, 0.0936, 0.0924, 0.6901, 0.8804, 0.2344, 0.3267, 0.0572, 0.5202, 0.4429, 0.2784, 0.1571, 0.0108, 0.0544, 0.5072, 0.0584, 0.0869, 0.5277, 0.4787, 0.4986, 0.5751, 0.4876, 0.1036, 0.3773, 1.1899, 1.0037, 1.5415, 0.433, 0.5465, 0.3542, 0.0782, 1.135, 0.251, 0.0412, 0.7664, 0.2276, 0.4639, 0.3793, 0.5996, 1.7514, 0.2794, 2.0605, 0.2423, 1.9558, 0.0922, 0.0769, 0.0801, 0.0733, 0.0729, 0.5066, 0.1716, 0.5096, 0.0547, 0.0706, 0.0103, 0.0479, 0.2714, 0.511, 0.0489, 1.2263, 0.0941, 0.0558, 0.1008, 0.1596, 0.0792, 1.0761, 0.8979, 0.8157, 0.1417, 0.1146, 0.8438, 2.0413, 0.1373, 0.0242, 0.0528, 0.0266, 0.0265, 0.0351, 0.0356, 0.0323, 0.0564, 0.955, 0.9105, 0.3261, 0.1036, 0.3313, 0.3763, 0.6261, 0.5395, 0.4735, 0.963, 0.8055, 0.0856, 0.0514, 0.0734, 0.0527, 0.0502, 0.5606, 0.534, 0.5964, 0.5507, 0.275, 0.1022, 0.0438, 0.0964, 0.0567, 0.086, 1.3255, 1.1429, 0.1328, 0.0173, 0.5793, 0.3831, 0.0618, 0.0718, 0.0959, 0.0147, 0.0975, 0.467, 0.4712, 0.531, 0.4578, 0.096, 0.1893, 0.0159, 0.5538, 0.3442, 0.1496, 0.5248, 0.3009, 0.751, 0.6172, 0.1877, 0.1598, 0.537, 0.1348, 0.4773, 0.8007, 0.634, 0.1256, 0.4711, 0.5225, 0.3112, 0.4078, 0.5393, 0.1288, 0.0598, 0.331, 0.046, 0.2621, 0.6576, 0.2633, 0.0968, 0.2437, 0.2734, 0.5216, 0.19, 0.4353, 0.3684, 0.1007, 1.0082, 0.3818, 0.3035, 0.511, 0.534, 0.2063, 1.0296, 0.5249, 0.3256, 0.2063, 0.3685, 0.1722, 0.503, 0.0841, 0.3068, 0.0151, 0.3573, 0.3489, 0.1829, 0.1863, 0.1114, 0.3761, 0.0741, 0.0151, 0.2586, 0.6, 0.0205, 0.0083, 0.1342, 0.0925, 0.2167, 0.277, 0.6998, 0.0189, 0.0126]\n",
      "Average CER: 0.4050\n",
      "WER List: [0.1096, 0.8289, 0.2899, 0.3725, 0.1294, 0.0, 0.0545, 0.0105, 0.1242, 0.5872, 0.449, 0.493, 0.3153, 0.2837, 0.3007, 0.302, 0.2108, 0.6271, 0.6842, 0.6404, 0.7487, 0.2358, 0.3913, 0.444, 0.4187, 0.4365, 0.4981, 0.771, 0.4835, 0.264, 0.8, 0.7399, 0.5099, 0.7556, 0.6183, 0.1989, 0.4157, 0.5131, 0.6488, 0.0149, 0.1982, 0.1667, 0.0104, 0.0621, 0.7861, 0.133, 0.264, 0.8936, 0.2086, 0.5833, 0.6681, 0.7057, 0.1507, 0.7194, 0.659, 0.1566, 0.2788, 0.7427, 0.6761, 0.6196, 0.7883, 0.3017, 0.7475, 0.5291, 0.7537, 0.9182, 0.1732, 0.7068, 0.0273, 0.0, 0.1574, 0.0064, 0.9808, 0.0067, 0.0117, 0.0017, 0.0, 0.0439, 0.3278, 0.0019, 0.0023, 0.0022, 1.1684, 1.4857, 1.0789, 0.0, 0.0, 0.0179, 0.6482, 0.5885, 0.0373, 0.0212, 0.2553, 0.5484, 0.0324, 0.3448, 0.4651, 0.0737, 0.163, 0.0986, 0.0976, 0.1591, 0.075, 0.0634, 0.0932, 0.1065, 0.4072, 0.0342, 0.1065, 0.097, 13.2857, 0.2727, 0.7385, 0.028, 0.261, 0.3211, 0.4246, 0.4853, 0.6279, 0.5556, 0.1198, 0.0949, 0.4205, 0.4651, 0.3, 0.3593, 0.0559, 0.5458, 0.5465, 0.2612, 0.1603, 0.015, 0.0567, 0.5302, 0.0565, 0.0835, 0.5604, 0.5288, 0.5604, 0.583, 0.5625, 0.1057, 0.459, 0.7188, 1.4286, 1.7683, 0.4797, 0.5082, 0.625, 0.2569, 0.3265, 0.3684, 0.1763, 0.625, 0.2044, 0.2083, 0.4162, 0.5944, 0.566, 0.1474, 0.2571, 0.142, 0.1681, 0.0938, 0.0661, 0.0756, 0.0635, 0.0676, 0.5233, 0.1749, 0.5208, 0.0503, 0.0679, 0.0062, 0.0472, 0.2259, 0.5443, 0.0562, 0.5762, 0.0688, 0.0549, 0.0688, 0.0761, 0.0471, 0.544, 0.9483, 0.8333, 0.1396, 0.1086, 0.4596, 0.5011, 0.2354, 0.0545, 0.0532, 0.0472, 0.0623, 0.0445, 0.0637, 0.064, 0.042, 0.6434, 0.825, 0.5, 0.2333, 0.3158, 0.3712, 0.7447, 0.5623, 0.2822, 0.8125, 0.5959, 0.0798, 0.0518, 0.0714, 0.0532, 0.0576, 0.6549, 0.642, 0.7432, 0.6632, 0.4286, 0.2815, 0.0886, 0.0901, 0.057, 0.0777, 0.6923, 0.0, 0.1905, 0.023, 0.6842, 0.4135, 0.0646, 0.1126, 0.1753, 0.0208, 0.0989, 0.4138, 0.5884, 0.5478, 0.5398, 0.0903, 0.0828, 0.0316, 0.562, 0.3286, 0.1476, 0.5559, 0.3761, 0.3744, 0.5471, 0.2222, 0.1899, 0.5606, 0.1517, 0.5342, 0.6438, 0.4409, 0.1465, 0.5234, 0.5455, 0.325, 0.4729, 0.5133, 0.1451, 0.0773, 0.4095, 0.0833, 0.2372, 0.532, 0.3205, 0.092, 0.2628, 0.1844, 0.628, 0.2724, 0.4316, 0.4208, 0.054, 0.7865, 0.4224, 0.3049, 0.5378, 0.545, 0.1738, 0.4407, 0.4308, 0.3443, 0.2835, 0.4212, 0.1768, 0.521, 0.0715, 0.3296, 0.0301, 0.2094, 0.3655, 0.1865, 0.3012, 0.1029, 0.627, 0.1698, 0.0162, 0.2785, 0.3913, 0.0294, 0.0007, 0.0461, 0.0969, 0.2302, 0.5111, 0.6233, 0.0208, 0.0206]\n",
      "Average WER: 0.3800\n",
      "Meteor List: [0.9468, 0.8909, 0.658, 0.9225, 0.5569, 1.0, 0.9589, 0.9945, 0.9216, 0.6667, 0.8961, 0.7107, 0.5038, 0.7284, 0.6376, 0.9499, 0.8787, 0.8878, 0.4338, 0.5554, 0.6356, 0.9577, 0.7565, 0.6302, 0.738, 0.6978, 0.6902, 0.6657, 0.6542, 0.6314, 0.6685, 0.3847, 0.6906, 0.4441, 0.6626, 0.9749, 0.6845, 0.4653, 0.9049, 0.9904, 0.9659, 0.9824, 0.9973, 0.9757, 0.5712, 0.9654, 0.9634, 0.5309, 0.9036, 0.7162, 0.6817, 0.4294, 0.8737, 0.5577, 0.4656, 0.8922, 0.6564, 0.5787, 0.7119, 0.6627, 0.5696, 0.6035, 0.4229, 0.6424, 0.5248, 0.6694, 0.9723, 0.6451, 0.9578, 1.0, 0.8946, 0.9951, 0.0096, 0.9956, 0.9917, 0.9988, 1.0, 0.9671, 0.7496, 0.9987, 0.9985, 0.9986, 0.6419, 0.5992, 0.569, 1.0, 1.0, 0.985, 0.6538, 0.5655, 0.963, 0.9803, 0.723, 0.5137, 0.9688, 0.7797, 0.8668, 0.9659, 0.943, 0.8574, 0.9456, 0.9377, 0.9281, 0.9673, 0.9108, 0.974, 0.8975, 0.9777, 0.884, 0.9723, 0.1926, 0.6388, 0.2819, 0.9707, 0.9364, 0.9867, 0.936, 0.994, 0.9394, 0.464, 0.9372, 0.9968, 0.7292, 0.7542, 0.6874, 0.9709, 0.9448, 0.4808, 0.9334, 0.9293, 0.9406, 0.9882, 0.9499, 0.4665, 0.9468, 0.9345, 0.4634, 0.9807, 0.9251, 0.3434, 0.9382, 0.9133, 0.6004, 0.5431, 0.539, 0.7064, 0.7015, 0.7023, 0.269, 0.7218, 0.7035, 0.7901, 0.9478, 0.6612, 0.8005, 0.8903, 0.9057, 0.8521, 0.6151, 0.8399, 0.6887, 0.9407, 0.6922, 0.9847, 0.9357, 0.9929, 0.9382, 0.9871, 0.4673, 0.9853, 0.4515, 0.9954, 0.9398, 0.9985, 0.9567, 0.9682, 0.4611, 0.9741, 0.4014, 0.9441, 0.9486, 0.956, 0.9485, 0.9694, 0.5779, 0.0781, 0.8155, 0.9074, 0.8918, 0.758, 0.6048, 0.8709, 0.9513, 0.9739, 0.9534, 0.9511, 0.958, 0.9454, 0.9446, 0.9709, 0.6224, 0.4077, 0.3029, 0.6012, 0.8419, 0.8922, 0.9377, 0.4506, 0.9268, 0.3972, 0.5168, 0.9335, 0.9482, 0.9449, 0.9471, 0.9944, 0.9225, 0.9596, 0.9566, 0.9724, 0.3625, 0.6435, 0.9499, 0.9173, 0.9571, 0.9292, 0.468, 0.9996, 0.8631, 0.9753, 0.9486, 0.9692, 0.9462, 0.91, 0.8954, 0.9772, 0.9361, 0.8605, 0.9557, 0.4677, 0.9289, 0.9028, 0.9684, 0.9673, 0.8814, 0.8046, 0.9411, 0.4618, 0.8639, 0.8223, 0.6238, 0.8818, 0.8394, 0.4548, 0.9361, 0.9119, 0.4762, 0.7645, 0.8665, 0.5374, 0.4797, 0.9032, 0.9391, 0.8424, 0.8835, 0.9164, 0.643, 0.9434, 0.8562, 0.8603, 0.6885, 0.911, 0.8083, 0.8801, 0.9461, 0.8163, 0.94, 0.7292, 0.9806, 0.4129, 0.6212, 0.9166, 0.9532, 0.4597, 0.8761, 0.7598, 0.7153, 0.6472, 0.7998, 0.9756, 0.879, 0.8771, 0.9362, 0.7454, 0.9771, 0.8421, 0.9244, 0.8633, 0.7945, 0.9017, 0.6568, 0.8488, 0.9873, 0.7674, 0.7701, 0.9672, 0.9994, 0.9662, 0.8531, 0.8498, 0.9795, 0.835, 0.9803, 0.9824]\n",
      "Average Meteor: 0.8019\n",
      "BLEU List: [0.8646, 0.5935, 0.6388, 0.7012, 0.8365, 1.0, 0.9439, 0.9894, 0.8314, 0.4633, 0.5022, 0.5253, 0.6643, 0.6149, 0.6773, 0.6551, 0.7373, 0.5134, 0.1941, 0.2202, 0.3751, 0.6735, 0.5352, 0.6064, 0.5004, 0.4671, 0.5018, 0.3816, 0.4923, 0.6983, 0.3702, 0.0672, 0.6049, 0.1765, 0.4431, 0.8291, 0.5509, 0.2768, 0.565, 0.985, 0.6604, 0.7047, 0.9826, 0.9427, 0.4009, 0.7608, 0.5938, 0.3427, 0.6673, 0.5338, 0.4169, 0.2719, 0.8201, 0.3077, 0.1928, 0.751, 0.6813, 0.3063, 0.3775, 0.2943, 0.3613, 0.7013, 0.2565, 0.3717, 0.2178, 0.3967, 0.6902, 0.3639, 0.9547, 1.0, 0.8438, 0.9887, 0.0, 0.9865, 0.9736, 0.9983, 1.0, 0.9551, 0.6108, 0.9981, 0.9977, 0.9978, 0.3326, 0.336, 0.3517, 1.0, 1.0, 0.982, 0.3979, 0.2735, 0.962, 0.9658, 0.6704, 0.2919, 0.9632, 0.5001, 0.6478, 0.9139, 0.8901, 0.8869, 0.8975, 0.828, 0.9221, 0.9463, 0.9023, 0.9017, 0.8778, 0.9319, 0.8693, 0.9244, 0.0343, 0.3815, 0.076, 0.9611, 0.9173, 0.9654, 0.9113, 0.9513, 0.9237, 0.2865, 0.9122, 0.9488, 0.5587, 0.5614, 0.6004, 0.9503, 0.9425, 0.302, 0.9067, 0.9034, 0.9216, 0.9804, 0.9365, 0.3243, 0.9412, 0.9064, 0.3079, 0.9541, 0.8963, 0.2471, 0.9188, 0.8857, 0.467, 0.3238, 0.2959, 0.2061, 0.3856, 0.4165, 0.3928, 0.3811, 0.584, 0.6201, 0.8725, 0.3323, 0.768, 0.812, 0.873, 0.8087, 0.3292, 0.8319, 0.7234, 0.8227, 0.795, 0.9339, 0.9316, 0.9551, 0.9345, 0.9616, 0.3239, 0.9746, 0.3247, 0.9702, 0.9255, 0.9917, 0.9501, 0.9458, 0.3004, 0.9556, 0.3141, 0.9271, 0.9418, 0.9381, 0.9297, 0.9639, 0.3757, 0.0002, 0.5434, 0.8693, 0.8854, 0.5459, 0.347, 0.6728, 0.9377, 0.9405, 0.9463, 0.9308, 0.9498, 0.9292, 0.9346, 0.9675, 0.1795, 0.1068, 0.4463, 0.5355, 0.5479, 0.9173, 0.9184, 0.2762, 0.8367, 0.1893, 0.3831, 0.9169, 0.9468, 0.9217, 0.9453, 0.9658, 0.9079, 0.9499, 0.9418, 0.9604, 0.0, 0.3805, 0.8554, 0.9033, 0.9414, 0.9171, 0.205, 1.0, 0.7738, 0.9662, 0.9267, 0.9479, 0.9333, 0.8626, 0.7709, 0.9695, 0.8992, 0.8499, 0.9341, 0.2974, 0.9084, 0.8974, 0.9026, 0.9451, 0.807, 0.7865, 0.9099, 0.2854, 0.6653, 0.7549, 0.4003, 0.7903, 0.7784, 0.279, 0.8928, 0.8524, 0.3107, 0.5375, 0.8357, 0.4172, 0.3033, 0.8945, 0.8886, 0.8101, 0.8047, 0.8986, 0.5496, 0.8554, 0.744, 0.8047, 0.6354, 0.9039, 0.6915, 0.8054, 0.9063, 0.708, 0.9142, 0.5391, 0.9375, 0.2003, 0.4877, 0.897, 0.9287, 0.2984, 0.8221, 0.5211, 0.4945, 0.5847, 0.6843, 0.9534, 0.8171, 0.8403, 0.9135, 0.5924, 0.9515, 0.8325, 0.8668, 0.8316, 0.6504, 0.8916, 0.3559, 0.7615, 0.9836, 0.74, 0.6715, 0.9552, 0.9993, 0.958, 0.8879, 0.7539, 0.9823, 0.8277, 0.9789, 0.9749]\n",
      "Average BLEU: 0.7016\n",
      "Order Score (Kendall Tau) List: [0.6602, 0.4213, 0.923, 0.5706, 0.9126, 1.0, 0.6093, 0.8355, 0.8148, 0.5787, 0.5385, 0.6652, 0.5429, 0.9287, 0.6396, 0.8688, 0.4992, 0.768, 0.2886, 0.5873, 0.5186, 0.5318, 0.549, 0.577, 0.4422, 0.796, 0.5178, 0.5718, 0.6106, 0.7163, 0.5753, 0.5975, 0.6249, 0.2322, 0.3779, 0.9938, 0.8467, 0.3072, 0.7171, 0.7731, 0.8859, 0.9036, 0.8881, 0.8554, 0.4489, 0.9814, 0.8694, 0.7698, 0.7246, 0.6461, 0.3853, 0.0802, 0.9077, 0.3732, 0.5758, 0.8845, 0.5571, 0.3601, 0.7544, 0.2268, 0.428, 0.5638, 0.4483, 0.4564, 0.3255, 0.305, 0.4792, 0.7153, 0.9935, 1.0, 0.9574, 0.8387, 0.0, 0.9646, 0.9739, 0.8074, 1.0, 0.8562, 0.4315, 0.893, 0.9752, 0.8487, 0.9129, 0.3333, 1.0, 0.9759, 1.0, 0.3504, 0.5347, 0.7531, 0.6264, 0.7588, 0.4003, 0.6709, 0.8951, 0.5697, 0.7308, 0.2779, 0.7825, 0.2158, 0.6289, 0.4519, 0.6013, 0.9971, 0.4606, 0.9187, 0.3781, 0.9963, 0.361, 0.9952, 0.9129, 1.0, 0.7738, 0.7064, 0.2957, 0.5528, 0.6215, 0.9444, 0.5435, 0.0454, 0.5387, 1.0, 0.7686, 0.5596, 0.8741, 0.6754, 0.4804, 0.3488, 0.3632, 0.2553, 0.5983, 0.7657, 0.6013, 0.5023, 0.636, 0.5775, 0.559, 0.5817, 0.56, 0.2503, 0.557, 0.4383, 0.3861, 0.7303, 0.4696, 0.3044, 0.6395, 0.6954, 0.9487, 1.0, 0.3486, 0.8047, 0.8037, 0.1055, 0.7371, 0.7981, 0.5684, 0.8487, 0.2475, 0.9682, 0.2229, 0.7613, 0.0, 0.8311, 0.666, 0.8713, 0.7345, 0.6826, 0.4797, 0.5677, 0.6633, 0.8915, 0.8477, 0.7905, 0.5155, 0.713, 0.5585, 0.7234, 0.3416, 0.5422, 0.4044, 0.611, 0.7133, 0.8022, 0.3238, 0.0213, 0.637, 0.6388, 0.7356, 0.5748, 0.1001, 0.8258, 0.8248, 0.8981, 0.8576, 0.7826, 0.8236, 0.8736, 0.874, 0.9994, 0.1702, 0.8563, 0.9487, 0.648, 0.6288, 0.557, 0.5813, 0.1982, 0.889, 0.8563, 0.5657, 0.4535, 0.712, 0.5181, 0.7161, 0.9963, 0.5283, 0.5555, 0.3661, 0.7397, 1.0, 0.9194, 0.8003, 0.5955, 0.7428, 0.2822, 0.3515, 0.9129, 0.8411, 0.2992, 0.4855, 0.472, 0.0, 1.0, 0.854, 0.6231, 0.468, 0.5029, 0.4872, 0.4758, 0.4327, 0.7615, 0.9223, 0.7641, 0.5467, 0.0, 0.6988, 0.2178, 0.5975, 0.3799, 0.5363, 0.9637, 0.4172, 0.3623, 0.487, 0.2931, 0.8602, 0.3858, 0.5364, 0.4436, 0.3785, 0.5613, 0.3868, 0.8001, 0.8937, 0.5975, 0.5721, 1.0, 0.779, 0.1525, 0.5414, 0.1193, 0.6506, 0.7121, 0.5271, 0.8572, 0.531, 0.4088, 0.8335, 0.7877, 0.3386, 0.5117, 0.5395, 0.3947, 0.5002, 0.7191, 0.562, 0.2772, 0.7502, 0.6673, 0.5948, 0.1271, 0.6013, 0.338, 0.6443, 0.7667, 0.836, 0.2455, 0.854, 0.4851, 0.7116, 0.9608, 0.7638, 0.3865, 0.3958, 0.992, 0.8335, 0.7237, 0.3463, 0.0, 0.7288, 0.2612, 0.7459, 0.8608]\n",
      "Average Order Score (Kendall Tau): 0.6217\n",
      "Order Score (Spearman) List: [0.7887, 0.5038, 0.9653, 0.6232, 0.8996, 1.0, 0.6781, 0.8244, 0.7555, 0.6697, 0.6525, 0.7646, 0.6141, 0.9432, 0.7371, 0.9239, 0.5779, 0.8604, 0.3774, 0.681, 0.6262, 0.6174, 0.6607, 0.6437, 0.5036, 0.9133, 0.6242, 0.6831, 0.715, 0.795, 0.6853, 0.6888, 0.7121, 0.3229, 0.5246, 0.9991, 0.9351, 0.3907, 0.6653, 0.7099, 0.9403, 0.9424, 0.8382, 0.8247, 0.5612, 0.9967, 0.9345, 0.8832, 0.6929, 0.7703, 0.4986, 0.1139, 0.9548, 0.47, 0.6652, 0.9217, 0.6217, 0.4501, 0.8849, 0.3037, 0.5141, 0.6083, 0.5462, 0.57, 0.3921, 0.3737, 0.5411, 0.874, 0.9989, 1.0, 0.9852, 0.8666, 0.0, 0.9831, 0.9938, 0.7288, 1.0, 0.8138, 0.5256, 0.872, 0.9889, 0.8522, 0.9487, 0.5, 1.0, 0.991, 1.0, 0.2728, 0.6096, 0.7993, 0.6026, 0.7752, 0.4993, 0.6998, 0.8782, 0.6784, 0.7939, 0.2411, 0.7489, 0.0472, 0.6138, 0.3302, 0.645, 0.9996, 0.387, 0.9562, 0.3929, 0.9994, 0.2757, 0.9991, 0.9487, 1.0, 0.8477, 0.7514, 0.288, 0.5699, 0.642, 0.9833, 0.6025, 0.0369, 0.471, 1.0, 0.8778, 0.6681, 0.9419, 0.7769, 0.4728, 0.4334, 0.3476, 0.281, 0.7422, 0.8496, 0.6001, 0.55, 0.5949, 0.5895, 0.6016, 0.6675, 0.608, 0.2891, 0.5855, 0.434, 0.3166, 0.8281, 0.4643, 0.4097, 0.7708, 0.782, 0.9747, 1.0, 0.4173, 0.8996, 0.7828, 0.1282, 0.7527, 0.7835, 0.6705, 0.9452, 0.3486, 0.9736, 0.274, 0.6872, 0.0, 0.8058, 0.6374, 0.8574, 0.7558, 0.5885, 0.4675, 0.5615, 0.6837, 0.889, 0.9094, 0.7643, 0.5752, 0.8252, 0.6414, 0.8321, 0.4149, 0.5464, 0.4387, 0.7164, 0.8039, 0.8933, 0.3381, 0.0322, 0.5674, 0.7109, 0.8392, 0.6601, 0.124, 0.8753, 0.7979, 0.864, 0.8396, 0.7517, 0.7985, 0.8704, 0.8727, 1.0, 0.2231, 0.9258, 0.9747, 0.5941, 0.6387, 0.6586, 0.6815, 0.2328, 0.9615, 0.9258, 0.6791, 0.4735, 0.7207, 0.5275, 0.7315, 0.9994, 0.6097, 0.6416, 0.3658, 0.858, 1.0, 0.9557, 0.8656, 0.623, 0.8161, 0.2365, 0.3985, 0.9487, 0.9025, 0.2471, 0.5542, 0.5288, 0.0, 1.0, 0.9058, 0.6529, 0.5379, 0.5904, 0.6174, 0.6037, 0.3922, 0.8159, 0.9648, 0.7842, 0.6167, 0.0, 0.7359, 0.2383, 0.6411, 0.4579, 0.6355, 0.9902, 0.3747, 0.4961, 0.4929, 0.2573, 0.9245, 0.4761, 0.4851, 0.5125, 0.4001, 0.6658, 0.3975, 0.8912, 0.9563, 0.5895, 0.6338, 1.0, 0.7622, 0.1948, 0.5975, 0.047, 0.6175, 0.7947, 0.5937, 0.8807, 0.6498, 0.3673, 0.9133, 0.9122, 0.3137, 0.6135, 0.6396, 0.4691, 0.4833, 0.8083, 0.6839, 0.2392, 0.7805, 0.7289, 0.6227, 0.0956, 0.6063, 0.4526, 0.5561, 0.7335, 0.9263, 0.0828, 0.9058, 0.5438, 0.7762, 0.9788, 0.8144, 0.4329, 0.32, 0.9986, 0.8859, 0.7719, 0.3818, 0.0, 0.809, 0.2554, 0.7203, 0.8682]\n",
      "Average Order Score (Spearman): 0.6590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# read json\n",
    "with open('fixed_res/Llama/llamaparse-dummy_scanned.pdf.json', encoding='utf8') as f:\n",
    "    llamaparse_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Llama/llamaparse-AF24_Alexander_Redman_Final.pdf.json', encoding=\"utf8\") as f:\n",
    "    redman_llamaparse_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Llama/llamaparse-attention_paper.pdf.json', encoding=\"utf8\") as f:\n",
    "    attention_llamaparse_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Llama/llamaparse-Astra_AR_2023 (15052024)_LR-1-220.pdf.json', encoding=\"utf8\") as f:\n",
    "    astra_ar_220_llamaparse_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Llama/llamaparse-AR for improved learnability.pdf.json', encoding=\"utf8\") as f:\n",
    "    ar_llamaparse_res = json.load(f)\n",
    "\n",
    "combined_llamaparse_res = llamaparse_res[\"pages\"].copy() + redman_llamaparse_res[\"pages\"].copy() + attention_llamaparse_res[\"pages\"].copy() + astra_ar_220_llamaparse_res[\"pages\"].copy() + ar_llamaparse_res[\"pages\"].copy()\n",
    "\n",
    "# benchmarking llamaparse\n",
    "print(len(combined_llamaparse_res))\n",
    "benchmark(combined_benchmark_data, combined_llamaparse_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 69/314 [01:34<06:25,  1.57s/it]"
     ]
    }
   ],
   "source": [
    "# read json\n",
    "with open('fixed_res/Mistral/mistralocr-dummy-data.pdf.json', encoding='utf8') as f:\n",
    "    mistralocr_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Mistral/mistralocr-AF24_Alexander_Redman_Final.pdf.json', encoding=\"utf8\") as f:\n",
    "    redman_mistralocr_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Mistral/mistralocr-attention_paper.pdf.json', encoding=\"utf8\") as f:\n",
    "    attention_mistralocr_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Mistral/mistralocr-Astra_AR_2023 (15052024)_LR-1-220.pdf.json', encoding=\"utf8\") as f:\n",
    "    astra_ar_220_mistralocr_res = json.load(f)\n",
    "\n",
    "with open('fixed_res/Mistral/mistralocr-AR for improved learnability.pdf.json', encoding=\"utf8\") as f:\n",
    "    ar_mistralocr_res = json.load(f)\n",
    "\n",
    "combined_mistralocr_res = mistralocr_res[\"pages\"].copy() + redman_mistralocr_res[\"pages\"].copy() + attention_mistralocr_res[\"pages\"].copy() + astra_ar_220_mistralocr_res[\"pages\"].copy() + ar_mistralocr_res[\"pages\"].copy()\n",
    "\n",
    "# benchmarking mistralocr\n",
    "print(len(combined_mistralocr_res))\n",
    "benchmark(combined_benchmark_data, combined_mistralocr_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1 (Yolo + GOT-OCR2 + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Pred indices: [0, 0, 1, 2, 2, 2, 4, 7, 4, 10, 7, 7, 5, 6, 8, 7]\n",
      "Pred indices score: [0.24444444444444444, 0.9921259842519685, 0.9169329073482428, 0.4691358024691358, 0.24444444444444444, 0.38235294117647056, 0.47990255785627284, 0.375, 0.7164790174002047, 0.6274509803921569, 0.5866666666666667, 0.3380281690140845, 0.9551912568306011, 0.9506545820745217, 0.37774524158125916, 0.5866666666666667]\n",
      "\n",
      "CER: 0.2011\n",
      "WER: 0.2192\n",
      "ROUGE: 0.9167\n",
      "BLEU: 0.8486\n",
      "Order Score (Kendall Tau): 0.7082\n",
      "Order Score (Spearman): 0.8393\n",
      "\n",
      "Page 2\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Pred indices: [0, 7, 0, 1, 0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 10]\n",
      "Pred indices score: [0.3252032520325203, 0.25, 0.3853211009174312, 0.19047619047619047, 0.9908256880733946, 0.9182389937106918, 0.9240121580547113, 0.6, 0.7, 0.2, 0.3512513601741023, 0.2857142857142857, 0.2594142259414226, 0.3453815261044177, 0.7144866385372715]\n",
      "\n",
      "CER: 0.3745\n",
      "WER: 0.5122\n",
      "ROUGE: 0.6835\n",
      "BLEU: 0.5230\n",
      "Order Score (Kendall Tau): 0.7748\n",
      "Order Score (Spearman): 0.8033\n",
      "\n",
      "Page 3\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Pred indices: [3, 0, 1, 1, 2, 0, 3, 0, 4, 3, 4, 3, 5, 3, 6, 6, 7, 7]\n",
      "Pred indices score: [0.09836065573770492, 0.20689655172413793, 0.6915254237288135, 0.1863013698630137, 0.4907563025210084, 0.15942028985507245, 0.9176470588235294, 0.1728395061728395, 0.2768361581920904, 0.17647058823529413, 0.2793585100879462, 0.22580645161290322, 0.9174454828660437, 0.06896551724137931, 0.4918509895227008, 0.2775253407899336, 0.5037783375314862, 0.3357142857142857]\n",
      "\n",
      "CER: 0.2221\n",
      "WER: 0.3318\n",
      "ROUGE: 0.8489\n",
      "BLEU: 0.6611\n",
      "Order Score (Kendall Tau): 0.6794\n",
      "Order Score (Spearman): 0.8168\n",
      "\n",
      "Page 4\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Pred indices: [8, 4, 4, 4, 0, 1, 2, 5, 10, 4, 4]\n",
      "Pred indices score: [0.3137254901960784, 0.24545454545454545, 0.1598360655737705, 0.22797927461139897, 0.943952802359882, 0.9261744966442953, 0.9885386819484241, 0.9946808510638298, 0.5015812776723593, 0.8979591836734694, 1.0]\n",
      "\n",
      "CER: 0.5115\n",
      "WER: 0.5108\n",
      "ROUGE: 0.7753\n",
      "BLEU: 0.6863\n",
      "Order Score (Kendall Tau): 0.0201\n",
      "Order Score (Spearman): 0.0286\n",
      "\n",
      "Page 5\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Pred indices: [0, 0, 0, 10, 6, 7, 10, 9, 1, 1, 6, 7, 8, 9, 10, 3, 3, 2, 2, 7, 2, 4, 4]\n",
      "Pred indices score: [0.5945945945945946, 1.0, 0.2671232876712329, 0.2518518518518518, 0.37412095639943743, 0.24242424242424243, 0.11386861313868613, 0.3181818181818182, 0.9879518072289156, 0.2524271844660194, 0.4899598393574297, 0.896551724137931, 0.36878347360367253, 0.9743589743589743, 0.8588235294117647, 0.4375, 0.6842105263157895, 0.3225806451612903, 0.8181818181818182, 0.26666666666666666, 0.4927536231884058, 0.21875, 0.5783132530120482]\n",
      "\n",
      "CER: 0.6646\n",
      "WER: 0.7108\n",
      "ROUGE: 0.4905\n",
      "BLEU: 0.1501\n",
      "Order Score (Kendall Tau): 0.0573\n",
      "Order Score (Spearman): 0.0810\n",
      "\n",
      "Page 6\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6]\n",
      "Pred indices: [0, 0, 0, 2, 2, 2, 2]\n",
      "Pred indices score: [0.2716049382716049, 0.6363636363636364, 0.18292682926829268, 0.15300546448087432, 0.014770057066129574, 0.16993464052287582, 0.2644628099173554]\n",
      "\n",
      "CER: 0.9830\n",
      "WER: 0.9955\n",
      "ROUGE: 0.0154\n",
      "BLEU: 0.0000\n",
      "Order Score (Kendall Tau): 0.7559\n",
      "Order Score (Spearman): 0.8660\n",
      "\n",
      "CER List: [0.2011, 0.3745, 0.2221, 0.5115, 0.6646, 0.983]\n",
      "Average CER: 0.4928\n",
      "WER List: [0.2192, 0.5122, 0.3318, 0.5108, 0.7108, 0.9955]\n",
      "Average WER: 0.5467\n",
      "ROUGE List: [0.9167, 0.6835, 0.8489, 0.7753, 0.4905, 0.0154]\n",
      "Average ROUGE: 0.6217\n",
      "BLEU List: [0.8486, 0.523, 0.6611, 0.6863, 0.1501, 0.0]\n",
      "Average BLEU: 0.4782\n",
      "Order Score (Kendall Tau) List: [0.7082, 0.7748, 0.6794, 0.0201, 0.0573, 0.7559]\n",
      "Average Order Score (Kendall Tau): 0.4993\n",
      "Order Score (Spearman) List: [0.8393, 0.8033, 0.8168, 0.0286, 0.081, 0.866]\n",
      "Average Order Score (Spearman): 0.5725\n"
     ]
    }
   ],
   "source": [
    "# read json\n",
    "with open('res/pipeline_1_res.json') as f:\n",
    "    pipeline_1_res = json.load(f)\n",
    "\n",
    "# Benchmarking pipeline_1\n",
    "benchmark(benchmark_data, pipeline_1_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2 (Yolo + Universal.io + Gemma 3 + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
      "Pred indices: [0, 1, 2, 3, 5, 7, 8, 7, 13, 19, 11, 14, 16, 18, 9, 11]\n",
      "Pred indices score: [0.7659574468085106, 0.9133858267716536, 0.9965397923875432, 0.9896907216494846, 0.9160997732426304, 0.6274509803921569, 0.937799043062201, 0.41025641025641024, 0.450354609929078, 0.47593582887700536, 1.0, 0.8852459016393442, 0.9672131147540983, 0.338368580060423, 0.463768115942029, 1.0]\n",
      "\n",
      "CER: 0.2987\n",
      "WER: 0.3470\n",
      "ROUGE: 0.8886\n",
      "BLEU: 0.7561\n",
      "Order Score (Kendall Tau): 0.7059\n",
      "Order Score (Spearman): 0.8262\n",
      "\n",
      "Page 2\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "Pred indices: [0, 2, 0, 4, 6, 7, 8, 10, 12, 11, 13, 14, 15, 17, 20]\n",
      "Pred indices score: [0.8524590163934426, 0.9647058823529412, 1.0, 0.6615384615384615, 0.9454545454545454, 0.9, 0.9907692307692307, 0.7741935483870968, 0.7777777777777778, 0.6956521739130435, 0.9984726161902684, 1.0, 0.9994029850746269, 0.84, 0.336734693877551]\n",
      "\n",
      "CER: 0.1032\n",
      "WER: 0.0788\n",
      "ROUGE: 0.9362\n",
      "BLEU: 0.8876\n",
      "Order Score (Kendall Tau): 0.9569\n",
      "Order Score (Spearman): 0.9902\n",
      "\n",
      "Page 3\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Pred indices: [0, 17, 5, 4, 25, 7, 8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 2, 23]\n",
      "Pred indices score: [0.95, 0.9852941176470589, 0.8022181146025879, 0.9577464788732394, 0.8171557562076749, 0.9552238805970149, 0.9767441860465116, 1.0, 1.0, 0.9285714285714286, 0.42209072978303747, 0.625, 0.994492525570417, 1.0, 0.9981224183251971, 1.0, 0.8715083798882681, 0.9690721649484536]\n",
      "\n",
      "CER: 0.2228\n",
      "WER: 0.2227\n",
      "ROUGE: 0.9118\n",
      "BLEU: 0.7729\n",
      "Order Score (Kendall Tau): 0.5163\n",
      "Order Score (Spearman): 0.4799\n",
      "\n",
      "Page 4\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Pred indices: [0, 1, 3, 17, 4, 6, 8, 10, 13, 7, 14]\n",
      "Pred indices score: [0.95, 0.9640287769784173, 0.11793611793611794, 0.7848101265822784, 0.5383177570093458, 0.8756388415672913, 0.8315946348733234, 0.9580756013745705, 0.7486495074674293, 0.3756345177664975, 0.8089887640449438]\n",
      "\n",
      "CER: 0.3615\n",
      "WER: 0.3558\n",
      "ROUGE: 0.8546\n",
      "BLEU: 0.7118\n",
      "Order Score (Kendall Tau): 0.6364\n",
      "Order Score (Spearman): 0.6909\n",
      "\n",
      "Page 5\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
      "Pred indices: [57, 3, 5, 7, 9, 35, 43, 47, 4, 6, 33, 36, 44, 48, 49, 50, 51, 11, 54, 24, 55, 56, 58]\n",
      "Pred indices score: [0.6181818181818182, 0.9285714285714286, 0.8142292490118577, 1.0, 0.32629558541266795, 1.0, 0.43973509933774835, 1.0, 0.9285714285714286, 0.9628252788104089, 0.27636363636363637, 1.0, 0.4080604534005038, 0.9743589743589743, 1.0, 1.0, 1.0, 1.0, 0.8674698795180723, 0.9333333333333333, 0.6938775510204082, 0.8181818181818182, 0.5766871165644172]\n",
      "\n",
      "CER: 0.6337\n",
      "WER: 0.7108\n",
      "ROUGE: 0.6551\n",
      "BLEU: 0.7095\n",
      "Order Score (Kendall Tau): 0.5336\n",
      "Order Score (Spearman): 0.5642\n",
      "\n",
      "Page 6\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6]\n",
      "Pred indices: [0, 1, 2, 2, 3, 4, 4]\n",
      "Pred indices score: [1.0, 1.0, 0.4536082474226804, 0.41333333333333333, 0.31631967763599733, 1.0, 0.27884615384615385]\n",
      "\n",
      "CER: 0.2132\n",
      "WER: 0.2715\n",
      "ROUGE: 0.8857\n",
      "BLEU: 0.6613\n",
      "Order Score (Kendall Tau): 0.9512\n",
      "Order Score (Spearman): 0.9820\n",
      "\n",
      "CER List: [0.2987, 0.1032, 0.2228, 0.3615, 0.6337, 0.2132]\n",
      "Average CER: 0.3055\n",
      "WER List: [0.347, 0.0788, 0.2227, 0.3558, 0.7108, 0.2715]\n",
      "Average WER: 0.3311\n",
      "ROUGE List: [0.8886, 0.9362, 0.9118, 0.8546, 0.6551, 0.8857]\n",
      "Average ROUGE: 0.8553\n",
      "BLEU List: [0.7561, 0.8876, 0.7729, 0.7118, 0.7095, 0.6613]\n",
      "Average BLEU: 0.7499\n",
      "Order Score (Kendall Tau) List: [0.7059, 0.9569, 0.5163, 0.6364, 0.5336, 0.9512]\n",
      "Average Order Score (Kendall Tau): 0.7167\n",
      "Order Score (Spearman) List: [0.8262, 0.9902, 0.4799, 0.6909, 0.5642, 0.982]\n",
      "Average Order Score (Spearman): 0.7556\n"
     ]
    }
   ],
   "source": [
    "# read json\n",
    "with open('res/pipeline_2_res.json') as f:\n",
    "    pipeline_2_res = json.load(f)\n",
    "\n",
    "# Benchmarking pipeline_2\n",
    "benchmark(benchmark_data, pipeline_2_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 3 (Yolo + Universal.io + Gemma 3 + phi-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('res/pipeline_4_res.json') as f:\n",
    "#     pipeline_4_res = json.load(f)\n",
    "\n",
    "# pipeline_4_cer, pipeline_4_wer = benchmark(benchmark_data, pipeline_4_res)\n",
    "\n",
    "# print(f\"CER List: {pipeline_4_cer}\")\n",
    "# print(f\"WER List: {pipeline_4_wer}\")\n",
    "# print()\n",
    "# print(f\"Average CER: {sum(pipeline_4_cer)/len(pipeline_4_cer):.4f}\")\n",
    "# print(f\"Average WER: {sum(pipeline_4_wer)/len(pipeline_4_wer):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 4 (Yolo + Universal.io + Qwen 2.5 VL + Qwen 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "CER: 0.2774\n",
      "WER: 0.3196\n",
      "METEOR: 0.9106\n",
      "BLEU: 0.7158\n",
      "Order Score (Kendall Tau): 0.7525\n",
      "Order Score (Spearman): 0.8408\n",
      "Normalized Edit Distance: 0.2774\n",
      "\n",
      "Page 2\n",
      "CER: 0.0362\n",
      "WER: 0.0938\n",
      "METEOR: 0.9597\n",
      "BLEU: 0.8560\n",
      "Order Score (Kendall Tau): 0.9124\n",
      "Order Score (Spearman): 0.9653\n",
      "Normalized Edit Distance: 0.0357\n",
      "\n",
      "Page 3\n",
      "CER: 0.3232\n",
      "WER: 0.3045\n",
      "METEOR: 0.6876\n",
      "BLEU: 0.6266\n",
      "Order Score (Kendall Tau): 0.4274\n",
      "Order Score (Spearman): 0.4249\n",
      "Normalized Edit Distance: 0.3232\n",
      "\n",
      "Page 4\n",
      "CER: 0.0757\n",
      "WER: 0.1132\n",
      "METEOR: 0.9010\n",
      "BLEU: 0.8473\n",
      "Order Score (Kendall Tau): 0.8868\n",
      "Order Score (Spearman): 0.9541\n",
      "Normalized Edit Distance: 0.0728\n",
      "\n",
      "Page 5\n",
      "CER: 0.6415\n",
      "WER: 0.7189\n",
      "METEOR: 0.5780\n",
      "BLEU: 0.3323\n",
      "Order Score (Kendall Tau): 0.4028\n",
      "Order Score (Spearman): 0.4718\n",
      "Normalized Edit Distance: 0.6415\n",
      "\n",
      "Page 6\n",
      "CER: 0.4427\n",
      "WER: 0.4422\n",
      "METEOR: 0.5503\n",
      "BLEU: 0.5076\n",
      "Order Score (Kendall Tau): 0.5265\n",
      "Order Score (Spearman): 0.6077\n",
      "Normalized Edit Distance: 0.4427\n",
      "\n",
      "CER List: [0.2774, 0.0362, 0.3232, 0.0757, 0.6415, 0.4427]\n",
      "Average CER: 0.2994\n",
      "WER List: [0.3196, 0.0938, 0.3045, 0.1132, 0.7189, 0.4422]\n",
      "Average WER: 0.3320\n",
      "Meteor List: [0.9106, 0.9597, 0.6876, 0.901, 0.578, 0.5503]\n",
      "Average Meteor: 0.7645\n",
      "BLEU List: [0.7158, 0.856, 0.6266, 0.8473, 0.3323, 0.5076]\n",
      "Average BLEU: 0.6476\n",
      "Order Score (Kendall Tau) List: [0.7525, 0.9124, 0.4274, 0.8868, 0.4028, 0.5265]\n",
      "Average Order Score (Kendall Tau): 0.6514\n",
      "Order Score (Spearman) List: [0.8408, 0.9653, 0.4249, 0.9541, 0.4718, 0.6077]\n",
      "Average Order Score (Spearman): 0.7108\n",
      "Normalized Edit Distance List: [0.2774, 0.0357, 0.3232, 0.0728, 0.6415, 0.4427]\n",
      "Average Normalized Edit Distance: 0.2989\n"
     ]
    }
   ],
   "source": [
    "with open('res/pipeline_4_3_res.json') as f:\n",
    "    pipeline_4_res = json.load(f)\n",
    "\n",
    "benchmark(benchmark_data, pipeline_4_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 5 (Yolo + Universal.io + Qwen 2.5 VL + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/pipeline_5_3_res.json') as f:\n",
    "    pipeline_5_res = json.load(f)\n",
    "\n",
    "with open('res/AF24_Alexander_Redman_Final.pdf_formatted.json') as f:\n",
    "    redman_result = json.load(f)\n",
    "\n",
    "combined_pipeline_5_res = pipeline_5_res[\"pages\"].copy() + redman_result[\"pages\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [06:36<00:00,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER List: [0.2307, 0.0178, 0.1683, 0.0728, 0.6281, 0.189, 1.824, 0.0338, 0.5486, 0.6989, 0.3446, 0.4658, 0.4243, 0.5138, 0.3469, 0.4803, 0.4885, 0.5136, 0.6202, 0.1765, 0.6506, 0.2983, 0.3588, 0.3268, 0.362, 0.3458, 0.4925, 0.4451, 0.3188, 0.255, 0.3625, 0.3378, 0.3635, 1.2305, 0.5417, 0.5354, 1.013, 1.147, 0.292, 1.3541, 0.7523, 0.1967, 0.4249, 0.5432, 0.2989, 0.5862, 0.2674, 0.4537, 0.1748, 0.1378, 0.5363, 0.3175, 0.5495, 0.4333, 0.3989, 0.6135, 0.8548, 0.3481, 0.3862, 0.5231, 0.4009, 0.4473, 0.4197, 0.4593, 0.2802, 0.5929, 0.4372, 0.4502, 0.1763, 0.5353, 0.0049]\n",
      "Average CER: 0.4622\n",
      "WER List: [0.2306, 0.0462, 0.1409, 0.1105, 0.7373, 0.1889, 1.8611, 0.0364, 0.2561, 0.3476, 0.656, 0.7796, 0.9812, 0.5318, 0.2482, 0.4216, 0.604, 0.5946, 0.9718, 0.4163, 1.3251, 0.5393, 0.6415, 0.4976, 0.4813, 0.5369, 0.5533, 0.4436, 0.6636, 0.63, 0.396, 0.4927, 0.4529, 1.2921, 0.6089, 0.6613, 0.9409, 1.5137, 0.5618, 0.9167, 0.7228, 0.5392, 0.662, 0.5709, 0.5248, 0.5622, 0.4541, 0.512, 0.5461, 0.2662, 0.4583, 0.7478, 0.5816, 0.5662, 0.602, 0.6728, 0.7677, 0.4199, 0.5685, 0.8779, 0.5598, 0.518, 0.4949, 0.5051, 0.432, 0.5784, 0.684, 0.5669, 0.4241, 0.0703, 0.0183]\n",
      "Average WER: 0.5744\n",
      "Meteor List: [0.9048, 0.9657, 0.882, 0.9356, 0.9276, 0.7903, 0.6182, 1.0, 0.5773, 0.693, 0.7328, 0.6777, 0.677, 0.488, 0.7341, 0.5916, 0.6267, 0.9046, 0.7421, 0.8894, 0.614, 0.7551, 0.7728, 0.6969, 0.6814, 0.8312, 0.7645, 0.5866, 0.7442, 0.7334, 0.6574, 0.7792, 0.7501, 0.7128, 0.6894, 0.734, 0.5517, 0.6664, 0.6833, 0.6903, 0.762, 0.7927, 0.7328, 0.5433, 0.5849, 0.6298, 0.7129, 0.6415, 0.8886, 0.9234, 0.6457, 0.6993, 0.5337, 0.8174, 0.8043, 0.7579, 0.6859, 0.5861, 0.5783, 0.6376, 0.6959, 0.6942, 0.5433, 0.6308, 0.7262, 0.5932, 0.6435, 0.5842, 0.832, 0.6517, 0.9832]\n",
      "Average Meteor: 0.7182\n",
      "BLEU List: [0.8234, 0.9212, 0.8299, 0.8525, 0.7812, 0.8284, 0.1818, 0.9619, 0.6389, 0.6697, 0.3403, 0.2562, 0.2222, 0.3983, 0.6539, 0.5764, 0.2412, 0.5013, 0.3166, 0.5571, 0.2012, 0.3496, 0.3345, 0.3728, 0.3339, 0.4544, 0.4504, 0.3463, 0.3449, 0.2648, 0.6445, 0.4755, 0.3558, 0.2538, 0.4326, 0.3746, 0.2028, 0.1699, 0.3084, 0.3764, 0.4664, 0.3533, 0.3341, 0.3418, 0.2759, 0.457, 0.4044, 0.3616, 0.5121, 0.7774, 0.5012, 0.4865, 0.2997, 0.5757, 0.4422, 0.4026, 0.3626, 0.5542, 0.2364, 0.2687, 0.3485, 0.4513, 0.2898, 0.2996, 0.4146, 0.3808, 0.4067, 0.1964, 0.4899, 0.9019, 0.9635]\n",
      "Average BLEU: 0.4529\n",
      "Order Score (Kendall Tau) List: [0.7061, 0.8443, 0.525, 0.8214, 0.5012, 0.8002, 0.6183, 0.9444, 0.8202, 0.8148, 0.5467, 0.3772, 0.3325, 0.5396, 0.7226, 0.6488, 0.7262, 0.7946, 0.4448, 0.8182, 0.51, 0.19, 0.601, 0.4767, 0.8141, 0.6187, 0.6676, 0.526, 0.4162, 0.148, 0.6734, 0.5727, 0.5997, 0.7724, 0.6234, 0.8606, 0.6801, 0.5615, 0.7964, 0.528, 0.7459, 0.8083, 0.6095, 0.3041, 0.7823, 0.3554, 0.7665, 0.506, 0.9712, 0.958, 0.5772, 0.6219, 0.0, 0.7234, 0.7436, 0.5982, 0.5108, 0.65, 0.6681, 0.4785, 0.6052, 0.6941, 0.702, 0.7129, 0.689, 0.4107, 0.5013, 0.3963, 0.7829, 0.987, 0.7782]\n",
      "Average Order Score (Kendall Tau): 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(combined_benchmark_data, combined_pipeline_5_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark(benchmark_data[\"pages\"], pipeline_5_res[\"pages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark(redman_benchmark_data[\"pages\"], redman_result[\"pages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/pipeline_7_qwen7b.json') as f:\n",
    "    pipeline_7_res = json.load(f)\n",
    "\n",
    "with open('res/AF24_Alexander_Redman_Final.pdf_formatted.json') as f:\n",
    "    redman_result = json.load(f)\n",
    "\n",
    "combined_pipeline_7_res = pipeline_7_res[\"pages\"].copy() + redman_result[\"pages\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [04:47<00:00,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER List: [0.1264, 0.0184, 0.2368, 0.0575, 0.566, 0.1626, 0.286, 0.0577, 1.824, 0.0338, 0.5486, 0.6989, 0.3446, 0.4658, 0.4243, 0.5138, 0.3469, 0.4803, 0.4885, 0.5136, 0.6202, 0.1765, 0.6506, 0.2983, 0.3588, 0.3268, 0.362, 0.3458, 0.4925, 0.4451, 0.3188, 0.255, 0.3625, 0.3378, 0.3635, 1.2305, 0.5417, 0.5354, 1.013, 1.147, 0.292, 1.3541, 0.7523, 0.1967, 0.4249, 0.5432, 0.2989, 0.5862, 0.2674, 0.4537, 0.1748, 0.1378, 0.5363, 0.3175, 0.5495, 0.4333, 0.3989, 0.6135, 0.8548, 0.3481, 0.3862, 0.5231, 0.4009, 0.4473, 0.4197, 0.4593, 0.2802, 0.5929, 0.4372, 0.4502, 0.1763, 0.5353, 0.0049]\n",
      "Average CER: 0.4524\n",
      "WER List: [0.1119, 0.0734, 0.2333, 0.0782, 0.6171, 0.1742, 0.2745, 0.0833, 1.8611, 0.0364, 0.2561, 0.3476, 0.656, 0.7796, 0.9812, 0.5318, 0.2482, 0.4216, 0.604, 0.5946, 0.9718, 0.4163, 1.3251, 0.5393, 0.6415, 0.4976, 0.4813, 0.5369, 0.5533, 0.4436, 0.6636, 0.63, 0.396, 0.4927, 0.4529, 1.2921, 0.6089, 0.6613, 0.9409, 1.5137, 0.5618, 0.9167, 0.7228, 0.5392, 0.662, 0.5709, 0.5248, 0.5622, 0.4541, 0.512, 0.5461, 0.2662, 0.4583, 0.7478, 0.5816, 0.5662, 0.602, 0.6728, 0.7677, 0.4199, 0.5685, 0.8779, 0.5598, 0.518, 0.4949, 0.5051, 0.432, 0.5784, 0.684, 0.5669, 0.4241, 0.0703, 0.0183]\n",
      "Average WER: 0.5613\n",
      "Meteor List: [0.9175, 0.9762, 0.8869, 0.9293, 0.5753, 0.8019, 0.9954, 0.555, 0.6182, 1.0, 0.5773, 0.693, 0.7328, 0.6777, 0.677, 0.488, 0.7341, 0.5916, 0.6267, 0.9046, 0.7421, 0.8894, 0.614, 0.7551, 0.7728, 0.6969, 0.6814, 0.8312, 0.7645, 0.5866, 0.7442, 0.7334, 0.6574, 0.7792, 0.7501, 0.7128, 0.6894, 0.734, 0.5517, 0.6664, 0.6833, 0.6903, 0.762, 0.7927, 0.7328, 0.5433, 0.5849, 0.6298, 0.7129, 0.6415, 0.8886, 0.9234, 0.6457, 0.6993, 0.5337, 0.8174, 0.8043, 0.7579, 0.6859, 0.5861, 0.5783, 0.6376, 0.6959, 0.6942, 0.5433, 0.6308, 0.7262, 0.5932, 0.6435, 0.5842, 0.832, 0.6517, 0.9832]\n",
      "Average Meteor: 0.7154\n",
      "BLEU List: [0.8297, 0.8969, 0.7743, 0.9035, 0.2966, 0.8171, 0.9683, 0.8544, 0.1818, 0.9619, 0.6389, 0.6697, 0.3403, 0.2562, 0.2222, 0.3983, 0.6539, 0.5764, 0.2412, 0.5013, 0.3166, 0.5571, 0.2012, 0.3496, 0.3345, 0.3728, 0.3339, 0.4544, 0.4504, 0.3463, 0.3449, 0.2648, 0.6445, 0.4755, 0.3558, 0.2538, 0.4326, 0.3746, 0.2028, 0.1699, 0.3084, 0.3764, 0.4664, 0.3533, 0.3341, 0.3418, 0.2759, 0.457, 0.4044, 0.3616, 0.5121, 0.7774, 0.5012, 0.4865, 0.2997, 0.5757, 0.4422, 0.4026, 0.3626, 0.5542, 0.2364, 0.2687, 0.3485, 0.4513, 0.2898, 0.2996, 0.4146, 0.3808, 0.4067, 0.1964, 0.4899, 0.9019, 0.9635]\n",
      "Average BLEU: 0.4584\n",
      "Order Score (Kendall Tau) List: [0.7073, 1.0, 0.6113, 0.9676, 0.5283, 0.8496, 0.7852, 0.9112, 0.6183, 0.9444, 0.8202, 0.8148, 0.5467, 0.3772, 0.3325, 0.5396, 0.7226, 0.6488, 0.7262, 0.7946, 0.4448, 0.8182, 0.51, 0.19, 0.601, 0.4767, 0.8141, 0.6187, 0.6676, 0.526, 0.4162, 0.148, 0.6734, 0.5727, 0.5997, 0.7724, 0.6234, 0.8606, 0.6801, 0.5615, 0.7964, 0.528, 0.7459, 0.8083, 0.6095, 0.3041, 0.7823, 0.3554, 0.7665, 0.506, 0.9712, 0.958, 0.5772, 0.6219, 0.0, 0.7234, 0.7436, 0.5982, 0.5108, 0.65, 0.6681, 0.4785, 0.6052, 0.6941, 0.702, 0.7129, 0.689, 0.4107, 0.5013, 0.3963, 0.7829, 0.987, 0.7782]\n",
      "Average Order Score (Kendall Tau): 0.6409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark(combined_benchmark_data, combined_pipeline_7_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target blocks: ### Enhancement of system of management\n",
      "Pred blocks: New customer's development and increasing the sale of product\n",
      "0.41509433962264153\n",
      "Sequence score: [0.926829268292683, 0.275, 0.013029315960912053, 0.23529411764705882, 0.24489795918367346, 0.026905829596412557, 0.47058823529411764, 0.2857142857142857, 0.0, 0.020202020202020204, 0.21978021978021978, 0.3018867924528302, 0.23255813953488372, 0.008695652173913044, 0.4, 0.2222222222222222, 0.009174311926605505, 0.2222222222222222, 0.004032258064516129, 0.05714285714285714, 0.3018867924528302]\n",
      "Max sequence score: 0.926829268292683\n",
      "Max sequence score index: 0\n",
      "\n",
      "Sequence score: [0.07142857142857142, 0.05970149253731343, 0.006802721088435374, 0.03636363636363636, 0.05555555555555555, 0.009523809523809525, 0.0, 0.0, 0.00881057268722467, 0.014084507042253521, 0.02564102564102564, 0.05, 0.0273972602739726, 0.009216589861751152, 0.05405405405405406, 0.08695652173913043, 0.009456264775413711, 0.04878048780487805, 0.008281573498964804, 0.024691358024691357, 0.05]\n",
      "Max sequence score: 0.08695652173913043\n",
      "Max sequence score index: 15\n",
      "\n",
      "Sequence score: [0.21176470588235294, 0.9838709677419355, 0.017094017094017096, 0.25, 0.3010752688172043, 0.0599250936329588, 0.1794871794871795, 0.20253164556962025, 0.014084507042253521, 0.05865102639296188, 0.37037037037037035, 0.32989690721649484, 0.4, 0.0364963503649635, 0.19148936170212766, 0.175, 0.029166666666666667, 0.2857142857142857, 0.018518518518518517, 0.1552511415525114, 0.32989690721649484]\n",
      "Max sequence score: 0.9838709677419355\n",
      "Max sequence score index: 1\n",
      "\n",
      "Sequence score: [0.0967741935483871, 0.20057306590257878, 1.0, 0.11869436201780416, 0.11320754716981132, 0.07723577235772358, 0.066006600660066, 0.03289473684210526, 0.003929273084479371, 0.03180212014134275, 0.26666666666666666, 0.13664596273291926, 0.2028169014084507, 0.056112224448897796, 0.11285266457680251, 0.07868852459016394, 0.03687943262411347, 0.11764705882352941, 0.03398692810457516, 0.18468468468468469, 0.13664596273291926]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 2\n",
      "\n",
      "Sequence score: [0.3142857142857143, 0.23853211009174313, 0.017857142857142856, 0.9896907216494846, 0.4358974358974359, 0.015873015873015872, 0.19047619047619047, 0.28125, 0.01486988847583643, 0.018404907975460124, 0.31666666666666665, 0.2926829268292683, 0.3130434782608696, 0.04633204633204633, 0.35443037974683544, 0.27692307692307694, 0.030107526881720432, 0.1686746987951807, 0.015238095238095238, 0.14705882352941177, 0.2926829268292683]\n",
      "Max sequence score: 0.9896907216494846\n",
      "Max sequence score index: 3\n",
      "\n",
      "Sequence score: [0.2909090909090909, 0.3191489361702128, 0.006230529595015576, 0.4634146341463415, 0.9206349206349206, 0.016877637130801686, 0.25, 0.24489795918367346, 0.0, 0.03215434083601286, 0.26666666666666666, 0.3880597014925373, 0.28, 0.00819672131147541, 0.34375, 0.24, 0.02666666666666667, 0.14705882352941177, 0.00784313725490196, 0.13756613756613756, 0.3880597014925373]\n",
      "Max sequence score: 0.9206349206349206\n",
      "Max sequence score index: 4\n",
      "\n",
      "Sequence score: [0.11555555555555555, 0.12121212121212122, 0.06517311608961303, 0.1746031746031746, 0.15450643776824036, 0.9975429975429976, 0.12844036697247707, 0.1095890410958904, 0.19339622641509435, 0.033264033264033266, 0.19636363636363635, 0.12658227848101267, 0.2222222222222222, 0.03864734299516908, 0.11965811965811966, 0.11818181818181818, 0.03870967741935484, 0.13445378151260504, 0.041176470588235294, 0.1894150417827298, 0.12658227848101267]\n",
      "Max sequence score: 0.9975429975429976\n",
      "Max sequence score index: 5\n",
      "\n",
      "Sequence score: [0.55, 0.22784810126582278, 0.013071895424836602, 0.29850746268656714, 0.20833333333333334, 0.12612612612612611, 0.8484848484848485, 0.35294117647058826, 0.008368200836820083, 0.02702702702702703, 0.15555555555555556, 0.19230769230769232, 0.18823529411764706, 0.008733624454148471, 0.5714285714285714, 0.22857142857142856, 0.01839080459770115, 0.22641509433962265, 0.012121212121212121, 0.06896551724137931, 0.19230769230769232]\n",
      "Max sequence score: 0.8484848484848485\n",
      "Max sequence score index: 6\n",
      "\n",
      "Sequence score: [0.2631578947368421, 0.23376623376623376, 0.0, 0.27692307692307694, 0.2608695652173913, 0.01818181818181818, 0.3225806451612903, 1.0, 0.02531645569620253, 0.034013605442176874, 0.1590909090909091, 0.28, 0.1927710843373494, 0.00881057268722467, 0.2978723404255319, 0.12121212121212122, 0.009237875288683603, 0.23529411764705882, 0.004056795131845842, 0.08139534883720931, 0.28]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 7\n",
      "\n",
      "Sequence score: [0.0821917808219178, 0.1937984496124031, 0.0288659793814433, 0.2032520325203252, 0.13215859030837004, 0.22942643391521197, 0.0660377358490566, 0.12206572769953052, 0.9425837320574163, 0.05894736842105263, 0.2379182156133829, 0.18181818181818182, 0.12878787878787878, 0.08333333333333333, 0.12280701754385964, 0.102803738317757, 0.035830618892508145, 0.16379310344827586, 0.03560830860534125, 0.16997167138810199, 0.18181818181818182]\n",
      "Max sequence score: 0.9425837320574163\n",
      "Max sequence score index: 8\n",
      "\n",
      "Sequence score: [0.3111111111111111, 0.14285714285714285, 0.006430868167202572, 0.19444444444444445, 0.33962264150943394, 0.01762114537444934, 0.2631578947368421, 0.41025641025641024, 0.1885245901639344, 0.046511627906976744, 0.4, 0.38596491228070173, 0.1111111111111111, 0.017094017094017096, 0.3333333333333333, 0.15, 0.004545454545454545, 0.27586206896551724, 0.004, 0.055865921787709494, 0.38596491228070173]\n",
      "Max sequence score: 0.41025641025641024\n",
      "Max sequence score index: 7\n",
      "\n",
      "Sequence score: [0.08533333333333333, 0.19806763285024154, 0.0124804992199688, 0.15920398009950248, 0.0783289817232376, 0.05385996409335727, 0.07065217391304347, 0.06504065040650407, 0.04878048780487805, 0.04754358161648178, 0.3388235294117647, 0.12919896640826872, 0.3142857142857143, 0.450354609929078, 0.07291666666666667, 0.04864864864864865, 0.03636363636363636, 0.13917525773195877, 0.05060240963855422, 0.13359528487229863, 0.12919896640826872]\n",
      "Max sequence score: 0.450354609929078\n",
      "Max sequence score index: 13\n",
      "\n",
      "Sequence score: [0.041237113402061855, 0.10909090909090909, 0.00718132854578097, 0.11320754716981132, 0.10702341137123746, 0.012684989429175475, 0.04225352112676056, 0.06315789473684211, 0.0163265306122449, 0.08043875685557587, 0.09970674486803519, 0.22442244224422442, 0.08928571428571429, 0.0125, 0.08, 0.04895104895104895, 0.03206997084548105, 0.05921052631578947, 0.013404825737265416, 0.5411764705882353, 0.22442244224422442]\n",
      "Max sequence score: 0.5411764705882353\n",
      "Max sequence score index: 19\n",
      "\n",
      "Sequence score: [0.17857142857142858, 0.35789473684210527, 0.012422360248447204, 0.26506024096385544, 0.375, 0.01680672268907563, 0.20408163265306123, 0.28, 0.00784313725490196, 0.12179487179487179, 0.3018867924528302, 1.0, 0.27722772277227725, 0.024489795918367346, 0.3076923076923077, 0.23529411764705882, 0.026607538802660754, 0.17391304347826086, 0.007827788649706457, 0.07368421052631578, 1.0]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 11\n",
      "\n",
      "Sequence score: [0.5, 0.13186813186813187, 0.018867924528301886, 0.379746835443038, 0.23333333333333334, 0.07692307692307693, 0.4444444444444444, 0.30434782608695654, 0.00796812749003984, 0.05194805194805195, 0.2549019607843137, 0.1875, 0.16494845360824742, 0.016597510373443983, 0.9836065573770492, 0.2127659574468085, 0.013422818791946308, 0.18461538461538463, 0.055226824457593686, 0.08602150537634409, 0.1875]\n",
      "Max sequence score: 0.9836065573770492\n",
      "Max sequence score index: 14\n",
      "\n",
      "Sequence score: [0.37209302325581395, 0.1951219512195122, 0.025889967637540454, 0.37142857142857144, 0.27450980392156865, 0.035555555555555556, 0.2222222222222222, 0.16216216216216217, 0.024793388429752067, 0.04013377926421405, 0.25806451612903225, 0.2545454545454545, 0.22727272727272727, 0.017241379310344827, 0.38461538461538464, 0.8947368421052632, 0.0228310502283105, 0.14285714285714285, 0.008032128514056224, 0.06779661016949153, 0.2545454545454545]\n",
      "Max sequence score: 0.8947368421052632\n",
      "Max sequence score index: 15\n",
      "\n",
      "Sequence score: [0.04576659038901602, 0.13445378151260504, 0.01991465149359886, 0.11206896551724138, 0.0898876404494382, 0.01938610662358643, 0.023255813953488372, 0.060324825986078884, 0.031446540880503145, 0.04040404040404041, 0.16837782340862423, 0.10244988864142539, 0.1825726141078838, 0.03194888178913738, 0.07623318385650224, 0.046296296296296294, 0.9975961538461539, 0.12, 0.07399103139013453, 0.05253940455341506, 0.10244988864142539]\n",
      "Max sequence score: 0.9975961538461539\n",
      "Max sequence score index: 16\n",
      "\n",
      "Sequence score: [0.22950819672131148, 0.32, 0.0, 0.3181818181818182, 0.2028985507246377, 0.01646090534979424, 0.18518518518518517, 0.21818181818181817, 0.007692307692307693, 0.01892744479495268, 0.36036036036036034, 0.136986301369863, 0.41509433962264153, 0.008, 0.3142857142857143, 0.17857142857142858, 0.008771929824561403, 0.9459459459459459, 0.003875968992248062, 0.10256410256410256, 0.136986301369863]\n",
      "Max sequence score: 0.9459459459459459\n",
      "Max sequence score index: 17\n",
      "\n",
      "Sequence score: [0.060240963855421686, 0.1340782122905028, 0.010471204188481676, 0.0838095238095238, 0.05533596837944664, 0.11176470588235295, 0.04073319755600815, 0.04878048780487805, 0.011477761836441894, 0.04509283819628647, 0.17883211678832117, 0.07058823529411765, 0.15469613259668508, 0.034934497816593885, 0.0670611439842209, 0.056795131845841784, 0.03807390817469205, 0.09393346379647749, 0.7953830010493179, 0.16139240506329114, 0.07058823529411765]\n",
      "Max sequence score: 0.7953830010493179\n",
      "Max sequence score index: 18\n",
      "\n",
      "Sequence score: [0.027586206896551724, 0.0759493670886076, 0.005706134094151213, 0.07792207792207792, 0.06320541760722348, 0.009724473257698542, 0.02336448598130841, 0.027972027972027972, 0.012618296529968454, 0.3473227206946454, 0.07422680412371134, 0.15212527964205816, 0.058333333333333334, 0.009615384615384616, 0.05405405405405406, 0.027906976744186046, 0.024096385542168676, 0.03125, 0.01348314606741573, 0.3585237258347979, 0.15212527964205816]\n",
      "Max sequence score: 0.3585237258347979\n",
      "Max sequence score index: 19\n",
      "\n",
      "Sequence score: [0.17857142857142858, 0.35789473684210527, 0.012422360248447204, 0.26506024096385544, 0.375, 0.01680672268907563, 0.20408163265306123, 0.28, 0.00784313725490196, 0.12179487179487179, 0.3018867924528302, 1.0, 0.27722772277227725, 0.024489795918367346, 0.3076923076923077, 0.23529411764705882, 0.026607538802660754, 0.17391304347826086, 0.007827788649706457, 0.07368421052631578, 1.0]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 11\n",
      "\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Pred indices: [0, 15, 1, 2, 3, 4, 5, 6, 7, 8, 7, 13, 19, 11, 14, 15, 16, 17, 18, 19, 11]\n",
      "Pred indices score: [0.926829268292683, 0.08695652173913043, 0.9838709677419355, 1.0, 0.9896907216494846, 0.9206349206349206, 0.9975429975429976, 0.8484848484848485, 1.0, 0.9425837320574163, 0.41025641025641024, 0.450354609929078, 0.5411764705882353, 1.0, 0.9836065573770492, 0.8947368421052632, 0.9975961538461539, 0.9459459459459459, 0.7953830010493179, 0.3585237258347979, 1.0]\n",
      "\n",
      "Evaluation Results:\n",
      "order_score: 0.712\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import re\n",
    "\n",
    "def split_into_blocks(text):\n",
    "    # Basic split: by double newlines (paragraph/section boundaries)\n",
    "    blocks = [block.strip() for block in text.strip().split('\\n\\n') if block.strip()]\n",
    "    return blocks\n",
    "\n",
    "def block_content_recall(pred_blocks, target_blocks):\n",
    "    matched = 0\n",
    "    for t_block in target_blocks:\n",
    "        for p_block in pred_blocks:\n",
    "            if SequenceMatcher(None, t_block, p_block).ratio() > 0.75:  # 85% similar\n",
    "                matched += 1\n",
    "                break\n",
    "    return matched / len(target_blocks) if target_blocks else 1.0\n",
    "\n",
    "def get_block_order_indices(pred_blocks, target_blocks):\n",
    "    indices = []\n",
    "    indices_score = []\n",
    "    for j, t_block in enumerate(target_blocks):\n",
    "        sequence_score = []\n",
    "        for i, p_block in enumerate(pred_blocks):\n",
    "            score = SequenceMatcher(None, t_block, p_block).ratio()\n",
    "            sequence_score.append(score)\n",
    "            # print()\n",
    "            # print(\"Target block:\", t_block)\n",
    "            # print(\"Pred blocks:\", p_block)\n",
    "            # print(\"Score:\", score)\n",
    "            # print(\"Pred block index:\", j)\n",
    "            # print()\n",
    "        print(\"Sequence score:\", sequence_score)\n",
    "        print(\"Max sequence score:\", max(sequence_score))\n",
    "        print(\"Max sequence score index:\", sequence_score.index(max(sequence_score)))\n",
    "        print()\n",
    "        if sequence_score:\n",
    "            # if max(sequence_score) > 0.5:  # 50% similar\n",
    "                max_index = sequence_score.index(max(sequence_score))\n",
    "                indices.append(max_index)\n",
    "                indices_score.append(max(sequence_score))\n",
    "    return indices, indices_score\n",
    "\n",
    "def order_score_kendall_tau(pred_blocks, target_blocks):\n",
    "    target_indices = list(range(len(target_blocks)))\n",
    "    len_indices = min(len(pred_blocks), len(target_blocks))\n",
    "    pred_indices, _ = get_block_order_indices(pred_blocks, target_blocks)\n",
    "    # pred_indices, _ = get_block_order_indices(pred_blocks, target_blocks)\n",
    "    print(\"Target indices:\", target_indices)\n",
    "    print(\"Pred indices:\", pred_indices)\n",
    "    print(\"Pred indices score:\", _)\n",
    "    print()\n",
    "    \n",
    "    if len(pred_indices) < 2:\n",
    "        return 0.0  # not enough data to compare order\n",
    "    tau, _ = kendalltau(target_indices, pred_indices)\n",
    "    return max(tau, 0)  # tau can be negative\n",
    "\n",
    "    # stat = spearmanr(target_indices[:len(pred_indices)], pred_indices)\n",
    "    # return max(stat.statistic, 0)  # stat.correlation can be negative\n",
    "    # print(\"Spearman statistic:\", stat.statistic)\n",
    "\n",
    "    # score = adjusted_rand_score(target_indices[:len(pred_indices)], pred_indices)\n",
    "    # return max(score, 0)  # score can be negative\n",
    "\n",
    "def evaluate_prediction(pred_text, target_text):\n",
    "    pred_blocks = split_into_blocks(pred_text)\n",
    "    target_blocks = split_into_blocks(target_text)\n",
    "    # print(\"Length of target blocks:\", len(target_blocks))\n",
    "    # print(\"Length of pred blocks:\", len(pred_blocks))\n",
    "    print(\"Target blocks:\", target_blocks[17])\n",
    "    print(\"Pred blocks:\", pred_blocks[1])\n",
    "    print(SequenceMatcher(None, target_blocks[17], pred_blocks[12]).ratio())\n",
    "\n",
    "    recall = block_content_recall(pred_blocks, target_blocks)\n",
    "    order = order_score_kendall_tau(pred_blocks, target_blocks)\n",
    "\n",
    "    final_score = 0.5 * (recall +  order)\n",
    "    return {\n",
    "        # \"content_recall\": round(recall, 3),\n",
    "        \"order_score\": round(order, 3),\n",
    "        # \"final_score\": round(final_score, 3)\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "idx = 0\n",
    "prediction = pipeline_5_res['pages'][idx]['markdown']\n",
    "target = benchmark_data['pages'][idx]['markdown']\n",
    "\n",
    "results = evaluate_prediction(prediction, target)\n",
    "print(\"Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target blocks: PFU Business report\n",
      "Pred blocks: # New customer's development and increasing the sale of product\n",
      "0.2682926829268293\n",
      "Sequence score: [0.2682926829268293, 0.057971014492753624, 1.0, 0.19943019943019943, 0.25225225225225223, 0.3333333333333333, 0.12030075187969924, 0.24691358024691357, 0.22784810126582278, 0.2, 0.13953488372093023, 0.1971153846153846, 0.10843373493975904, 0.35051546391752575, 0.15053763440860216, 0.21428571428571427, 0.13389121338912133, 0.3333333333333333, 0.137291280148423, 0.07563025210084033, 0.35051546391752575]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 2\n",
      "\n",
      "Sequence score: [0.013029315960912053, 0.006802721088435374, 0.017094017094017096, 1.0, 0.017857142857142856, 0.006230529595015576, 0.06517311608961303, 0.013071895424836602, 0.0, 0.0288659793814433, 0.006430868167202572, 0.0124804992199688, 0.00718132854578097, 0.012422360248447204, 0.018867924528301886, 0.025889967637540454, 0.01991465149359886, 0.0, 0.010471204188481676, 0.005706134094151213, 0.012422360248447204]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 3\n",
      "\n",
      "Sequence score: [0.24615384615384617, 0.038461538461538464, 0.25688073394495414, 0.11976047904191617, 0.9787234042553191, 0.45569620253164556, 0.17670682730923695, 0.28125, 0.2903225806451613, 0.205761316872428, 0.2028985507246377, 0.16040100250626566, 0.11428571428571428, 0.275, 0.34210526315789475, 0.3582089552238806, 0.11279826464208242, 0.3058823529411765, 0.0842911877394636, 0.0784313725490196, 0.275]\n",
      "Max sequence score: 0.9787234042553191\n",
      "Max sequence score index: 4\n",
      "\n",
      "Sequence score: [0.015625, 0.00823045267489712, 0.03333333333333333, 0.03428571428571429, 0.021052631578947368, 0.24444444444444444, 0.9227272727272727, 0.1411764705882353, 0.015810276679841896, 0.2119815668202765, 0.007692307692307693, 0.02711864406779661, 0.007905138339920948, 0.007380073800738007, 0.08239700374531835, 0.06201550387596899, 0.015337423312883436, 0.036231884057971016, 0.08695652173913043, 0.006153846153846154, 0.007380073800738007]\n",
      "Max sequence score: 0.9227272727272727\n",
      "Max sequence score index: 6\n",
      "\n",
      "Sequence score: [0.0, 0.008368200836820083, 0.02027027027027027, 0.015355086372360844, 0.042704626334519574, 0.03759398496240601, 0.25229357798165136, 0.14342629482071714, 0.1285140562248996, 0.9162790697674419, 0.015625, 0.010238907849829351, 0.0199203187250996, 0.0149812734082397, 0.08365019011406843, 0.06299212598425197, 0.033950617283950615, 0.04411764705882353, 0.00846262341325811, 0.015479876160990712, 0.0149812734082397]\n",
      "Max sequence score: 0.9162790697674419\n",
      "Max sequence score index: 9\n",
      "\n",
      "Sequence score: [0.0, 0.005221932114882507, 0.022727272727272728, 0.03308270676691729, 0.023529411764705882, 0.0, 0.034482758620689655, 0.020253164556962026, 0.010178117048346057, 0.027874564459930314, 0.115, 0.958904109589041, 0.015479876160990712, 0.009732360097323601, 0.004914004914004914, 0.01507537688442211, 0.022727272727272728, 0.009615384615384616, 0.03048065650644783, 0.005063291139240506, 0.009732360097323601]\n",
      "Max sequence score: 0.958904109589041\n",
      "Max sequence score index: 11\n",
      "\n",
      "Sequence score: [0.034722222222222224, 0.007272727272727273, 0.0963855421686747, 0.07899461400359066, 0.08832807570977919, 0.09271523178807947, 0.06779661016949153, 0.03484320557491289, 0.06315789473684211, 0.055793991416309016, 0.0684931506849315, 0.03215434083601286, 1.0, 0.22442244224422442, 0.033444816053511704, 0.027586206896551724, 0.06140350877192982, 0.03896103896103896, 0.040268456375838924, 0.1348973607038123, 0.22442244224422442]\n",
      "Max sequence score: 1.0\n",
      "Max sequence score index: 12\n",
      "\n",
      "Sequence score: [0.425531914893617, 0.058823529411764705, 0.1978021978021978, 0.11392405063291139, 0.2894736842105263, 0.32786885245901637, 0.12121212121212122, 0.5652173913043478, 0.3181818181818182, 0.11555555555555555, 0.35294117647058826, 0.07349081364829396, 0.07407407407407407, 0.2903225806451613, 0.9310344827586207, 0.3673469387755102, 0.07223476297968397, 0.29850746268656714, 0.06746031746031746, 0.049886621315192746, 0.2903225806451613]\n",
      "Max sequence score: 0.9310344827586207\n",
      "Max sequence score index: 14\n",
      "\n",
      "Sequence score: [0.008771929824561403, 0.009029345372460496, 0.028, 0.027586206896551724, 0.032989690721649485, 0.03829787234042553, 0.0375, 0.03076923076923077, 0.008830022075055188, 0.03470031545741325, 0.004347826086956522, 0.030379746835443037, 0.031161473087818695, 0.025477707006369428, 0.021413276231263382, 0.09170305676855896, 0.9741784037558685, 0.025210084033613446, 0.03066812705366922, 0.023529411764705882, 0.025477707006369428]\n",
      "Max sequence score: 0.9741784037558685\n",
      "Max sequence score index: 16\n",
      "\n",
      "Sequence score: [0.003738317757009346, 0.007662835249042145, 0.02072538860103627, 0.024875621890547265, 0.02127659574468085, 0.02185792349726776, 0.04172461752433936, 0.026217228464419477, 0.0037593984962406013, 0.04488078541374474, 0.0037105751391465678, 0.04833141542002301, 0.015286624203821656, 0.007272727272727273, 0.05860805860805861, 0.0186219739292365, 0.07303974221267455, 0.14054054054054055, 0.9596774193548387, 0.015069967707212056, 0.007272727272727273]\n",
      "Max sequence score: 0.9596774193548387\n",
      "Max sequence score index: 18\n",
      "\n",
      "Sequence score: [0.0330188679245283, 0.014598540145985401, 0.07264957264957266, 0.046176046176046176, 0.05739514348785872, 0.0593607305936073, 0.05592105263157895, 0.02364066193853428, 0.04275534441805225, 0.07308970099667775, 0.0514018691588785, 0.06596306068601583, 0.11572700296735905, 0.1548974943052392, 0.022988505747126436, 0.03286384976525822, 0.04878048780487805, 0.02702702702702703, 0.04767309875141884, 0.9046454767726161, 0.1548974943052392]\n",
      "Max sequence score: 0.9046454767726161\n",
      "Max sequence score index: 19\n",
      "\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Pred indices: [2, 3, 4, 6, 9, 11, 12, 14, 16, 18, 19]\n",
      "Pred indices score: [1.0, 1.0, 0.9787234042553191, 0.9227272727272727, 0.9162790697674419, 0.958904109589041, 1.0, 0.9310344827586207, 0.9741784037558685, 0.9596774193548387, 0.9046454767726161]\n",
      "\n",
      "Evaluation Results:\n",
      "order_score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "from scipy.stats import kendalltau, spearmanr\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "import re\n",
    "\n",
    "def split_into_blocks(text):\n",
    "    # Basic split: by double newlines (paragraph/section boundaries)\n",
    "    blocks = [block.strip() for block in text.strip().split('\\n\\n') if block.strip()]\n",
    "    return blocks\n",
    "\n",
    "def block_content_recall(pred_blocks, target_blocks):\n",
    "    matched = 0\n",
    "    for t_block in target_blocks:\n",
    "        for p_block in pred_blocks:\n",
    "            if SequenceMatcher(None, t_block, p_block).ratio() > 0.75:  # 85% similar\n",
    "                matched += 1\n",
    "                break\n",
    "    return matched / len(target_blocks) if target_blocks else 1.0\n",
    "\n",
    "def get_block_order_indices(pred_blocks, target_blocks):\n",
    "    indices = []\n",
    "    indices_score = []\n",
    "    for i, p_block in enumerate(pred_blocks):\n",
    "        sequence_score = []\n",
    "        for j, t_block in enumerate(target_blocks):\n",
    "            score = SequenceMatcher(None, t_block, p_block).ratio()\n",
    "            sequence_score.append(score)\n",
    "            # print()\n",
    "            # print(\"Target block:\", t_block)\n",
    "            # print(\"Pred blocks:\", p_block)\n",
    "            # print(\"Score:\", score)\n",
    "            # print(\"Pred block index:\", j)\n",
    "            # print()\n",
    "        print(\"Sequence score:\", sequence_score)\n",
    "        print(\"Max sequence score:\", max(sequence_score))\n",
    "        print(\"Max sequence score index:\", sequence_score.index(max(sequence_score)))\n",
    "        print()\n",
    "        if sequence_score:\n",
    "            # if max(sequence_score) > 0.5:  # 50% similar\n",
    "                max_index = sequence_score.index(max(sequence_score))\n",
    "                indices.append(max_index)\n",
    "                indices_score.append(max(sequence_score))\n",
    "    return indices, indices_score\n",
    "\n",
    "def order_score_kendall_tau(pred_blocks, target_blocks):\n",
    "    target_indices = list(range(len(target_blocks)))\n",
    "    len_indices = min(len(pred_blocks), len(target_blocks))\n",
    "    pred_indices = list(range(len(pred_blocks)))\n",
    "    pred_indices_2, _ = get_block_order_indices(pred_blocks, target_blocks)\n",
    "    # pred_indices, _ = get_block_order_indices(pred_blocks, target_blocks)\n",
    "    print(\"Target indices:\", pred_indices)\n",
    "    print(\"Pred indices:\", pred_indices_2)\n",
    "    print(\"Pred indices score:\", _)\n",
    "    print()\n",
    "    \n",
    "    if len(pred_indices) < 2:\n",
    "        return 0.0  # not enough data to compare order\n",
    "    tau, _ = kendalltau(pred_indices, pred_indices_2)\n",
    "    return max(tau, 0)  # tau can be negative\n",
    "\n",
    "    # stat = spearmanr(target_indices[:len(pred_indices)], pred_indices)\n",
    "    # return max(stat.statistic, 0)  # stat.correlation can be negative\n",
    "    # print(\"Spearman statistic:\", stat.statistic)\n",
    "\n",
    "    # score = adjusted_rand_score(target_indices[:len(pred_indices)], pred_indices)\n",
    "    # return max(score, 0)  # score can be negative\n",
    "\n",
    "def evaluate_prediction(pred_text, target_text):\n",
    "    pred_blocks = split_into_blocks(pred_text)\n",
    "    target_blocks = split_into_blocks(target_text)\n",
    "    # print(\"Length of target blocks:\", len(target_blocks))\n",
    "    # print(\"Length of pred blocks:\", len(pred_blocks))\n",
    "    print(\"Target blocks:\", target_blocks[0])\n",
    "    print(\"Pred blocks:\", pred_blocks[0])\n",
    "    print(SequenceMatcher(None, target_blocks[0], pred_blocks[0]).ratio())\n",
    "\n",
    "    recall = block_content_recall(pred_blocks, target_blocks)\n",
    "    order = order_score_kendall_tau(pred_blocks, target_blocks)\n",
    "\n",
    "    final_score = 0.5 * (recall +  order)\n",
    "    return {\n",
    "        # \"content_recall\": round(recall, 3),\n",
    "        \"order_score\": round(order, 3),\n",
    "        # \"final_score\": round(final_score, 3)\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "idx = 0\n",
    "prediction = llamaparse_res['pages'][idx]['markdown']\n",
    "target = benchmark_data['pages'][idx]['markdown']\n",
    "\n",
    "results = evaluate_prediction(prediction, target)\n",
    "print(\"Evaluation Results:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "Pred indices: [0, 15, 1, 2, 3, 4, 5, 6, 7, 8, 7, 13, 9, 11, 14, 15, 16, 17, 18, 9, 11]\n",
      "Pred indices score: [0.95, 0.08695652173913043, 0.9838709677419355, 1.0, 1.0, 0.9206349206349206, 0.9975429975429976, 0.8484848484848485, 1.0, 0.9425837320574163, 0.41025641025641024, 0.450354609929078, 0.5411764705882353, 1.0, 1.0, 0.8947368421052632, 0.9975961538461539, 0.9459459459459459, 0.7953830010493179, 0.3585237258347979, 1.0]\n",
      "\n",
      "CER: 0.2297\n",
      "WER: 0.2260\n",
      "ROUGE: 0.9134\n",
      "BLEU: 0.8233\n",
      "Order Score (Kendall Tau): 0.6923\n",
      "Order Score (Spearman): 0.7347\n",
      "\n",
      "Page 2\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Pred indices: [0, 1, 0, 3, 4, 5, 7, 9, 11, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "Pred indices score: [0.8524590163934426, 0.7671232876712328, 1.0, 0.5, 0.9818181818181818, 0.8888888888888888, 0.5826086956521739, 0.9375, 0.7777777777777778, 0.6956521739130435, 0.9984732824427481, 0.972972972972973, 0.9988066825775657, 0.9787234042553191, 1.0, 0.6466165413533834, 0.9919354838709677, 0.9885931558935361]\n",
      "\n",
      "CER: 0.0391\n",
      "WER: 0.0611\n",
      "ROUGE: 0.9653\n",
      "BLEU: 0.9051\n",
      "Order Score (Kendall Tau): 0.9705\n",
      "Order Score (Spearman): 0.9943\n",
      "\n",
      "Page 3\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "Pred indices: [0, 16, 1, 3, 4, 6, 7, 8, 9, 11, 12, 14, 17, 18, 19, 20, 21, 23]\n",
      "Pred indices score: [1.0, 0.9852941176470589, 0.7298578199052133, 1.0, 0.7165532879818595, 1.0, 1.0, 0.9629629629629629, 1.0, 0.9285714285714286, 0.3675889328063241, 0.625, 0.996066089693155, 0.896551724137931, 0.9988726042841037, 1.0, 0.6983240223463687, 1.0]\n",
      "\n",
      "CER: 0.1823\n",
      "WER: 0.1652\n",
      "ROUGE: 0.9519\n",
      "BLEU: 0.8043\n",
      "Order Score (Kendall Tau): 0.8693\n",
      "Order Score (Spearman): 0.8865\n",
      "\n",
      "Page 4\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "Pred indices: [0, 1, 2, 3, 4, 5, 6, 7, 11, 12, 13]\n",
      "Pred indices score: [1.0, 0.9852941176470589, 0.4964131994261119, 1.0, 0.9876543209876543, 0.9811320754716981, 0.9949820788530466, 0.8903508771929824, 0.6783105747856463, 0.9726027397260274, 1.0]\n",
      "\n",
      "CER: 0.0396\n",
      "WER: 0.0728\n",
      "ROUGE: 0.9704\n",
      "BLEU: 0.8937\n",
      "Order Score (Kendall Tau): 1.0000\n",
      "Order Score (Spearman): 1.0000\n",
      "\n",
      "Page 5\n",
      "Target indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
      "Pred indices: [1, 2, 4, 16, 9, 9, 16, 11, 16, 3, 5, 7, 9, 17, 12, 16, 17, 18, 19, 22, 22, 23, 23, 24, 27]\n",
      "Pred indices score: [0.625, 0.975, 1.0, 0.328125, 0.5268542199488491, 0.5303030303030303, 0.2641509433962264, 0.2494172494172494, 0.7101449275362319, 0.975, 1.0, 0.4878048780487805, 0.5210918114143921, 0.22988505747126436, 0.35294117647058826, 0.59375, 1.0, 1.0, 1.0, 0.3508771929824561, 0.8674698795180723, 0.6086956521739131, 0.6938775510204082, 0.8181818181818182, 0.5766871165644172]\n",
      "\n",
      "CER: 0.6308\n",
      "WER: 0.7393\n",
      "ROUGE: 0.6310\n",
      "BLEU: 0.7767\n",
      "Order Score (Kendall Tau): 0.7621\n",
      "Order Score (Spearman): 0.8663\n",
      "\n",
      "Page 6\n",
      "Target indices: [0, 1, 2, 3, 4, 5]\n",
      "Pred indices: [0, 1, 2, 3, 4, 4]\n",
      "Pred indices score: [0.9824561403508771, 1.0, 0.519650655021834, 0.7830315224681422, 1.0, 0.27884615384615385]\n",
      "\n",
      "CER: 0.1890\n",
      "WER: 0.1889\n",
      "ROUGE: 0.9021\n",
      "BLEU: 0.8284\n",
      "Order Score (Kendall Tau): 0.9661\n",
      "Order Score (Spearman): 0.9856\n",
      "\n",
      "CER List: [0.2297, 0.0391, 0.1823, 0.0396, 0.6308, 0.189]\n",
      "Average CER: 0.2184\n",
      "WER List: [0.226, 0.0611, 0.1652, 0.0728, 0.7393, 0.1889]\n",
      "Average WER: 0.2422\n",
      "ROUGE List: [0.9134, 0.9653, 0.9519, 0.9704, 0.631, 0.9021]\n",
      "Average ROUGE: 0.8890\n",
      "BLEU List: [0.8233, 0.9051, 0.8043, 0.8937, 0.7767, 0.8284]\n",
      "Average BLEU: 0.8386\n",
      "Order Score (Kendall Tau) List: [0.6923, 0.9705, 0.8693, 1.0, 0.7621, 0.9661]\n",
      "Average Order Score (Kendall Tau): 0.8767\n",
      "Order Score (Spearman) List: [0.7347, 0.9943, 0.8865, 1.0, 0.8663, 0.9856]\n",
      "Average Order Score (Spearman): 0.9112\n"
     ]
    }
   ],
   "source": [
    "with open('res/pipeline_5_2_res.json') as f:\n",
    "    pipeline_5_2_res = json.load(f)\n",
    "\n",
    "benchmark(benchmark_data, pipeline_5_2_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
