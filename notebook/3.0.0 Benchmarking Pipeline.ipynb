{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchmetrics jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read md file\n",
    "with open('res/benchmark_data.md', encoding=\"utf8\") as f:\n",
    "    benchmark_data = f.read()\n",
    "\n",
    "# display md file\n",
    "# display(Markdown(benchmark_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Vidavox\\Universal Doc Parsing\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Character Error rate (CER)\n",
    "from torchmetrics.text import CharErrorRate\n",
    "import jiwer\n",
    "\n",
    "\n",
    "cer = CharErrorRate()\n",
    "\n",
    "transforms = jiwer.Compose(\n",
    "    [\n",
    "        jiwer.ExpandCommonEnglishContractions(),\n",
    "        jiwer.RemoveEmptyStrings(),\n",
    "        jiwer.ToLowerCase(),\n",
    "        jiwer.RemoveMultipleSpaces(),\n",
    "        jiwer.Strip(),\n",
    "        jiwer.RemovePunctuation(),\n",
    "        jiwer.ReduceToListOfListOfWords(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmarking function\n",
    "def benchmark(benchmark_data, parser_res):\n",
    "    target = benchmark_data\n",
    "    preds = parser_res\n",
    "\n",
    "    # cer score\n",
    "    cer_score = cer(preds=preds, target=target).item()\n",
    "\n",
    "    # wer score\n",
    "    wer_score = jiwer.wer(reference=target, hypothesis=preds, truth_transform=transforms, hypothesis_transform=transforms)\n",
    "\n",
    "    return cer_score, wer_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read md file\n",
    "with open('res/llamaparse_res.md', encoding=\"utf8\") as f:\n",
    "    llamaparse_res = f.read()\n",
    "\n",
    "# display md file\n",
    "# display(Markdown(llamaparse_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.19881021976470947\n",
      "WER: 0.1814739295077192\n"
     ]
    }
   ],
   "source": [
    "# benchmarking llamaparse\n",
    "llamaparse_cer, llamaparse_wer = benchmark(benchmark_data, llamaparse_res)\n",
    "\n",
    "print(f\"CER: {llamaparse_cer}\")\n",
    "print(f\"WER: {llamaparse_wer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read md file\n",
    "with open('res/mistralocr_res.md', encoding=\"utf8\") as f:\n",
    "    mistralocr_res = f.read()\n",
    "\n",
    "# display md file\n",
    "# display(Markdown(mistralocr_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.23246526718139648\n",
      "WER: 0.27847363821730264\n"
     ]
    }
   ],
   "source": [
    "# benchmarking mistralocr\n",
    "mistralocr_cer, mistralocr_wer = benchmark(benchmark_data, mistralocr_res)\n",
    "\n",
    "print(f\"CER: {mistralocr_cer}\")\n",
    "print(f\"WER: {mistralocr_wer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1 (Yolo + GOT-OCR2 + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read md file\n",
    "with open('res/pipeline_1_res.md', encoding=\"utf8\") as f:\n",
    "    pipeline_1_res = f.read()\n",
    "\n",
    "# display md file\n",
    "# display(Markdown(pipeline_1_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.467052161693573\n",
      "WER: 0.533935333527527\n"
     ]
    }
   ],
   "source": [
    "pipeline_1_cer, pipeline_1_wer = benchmark(benchmark_data, pipeline_1_res)\n",
    "\n",
    "print(f\"CER: {pipeline_1_cer}\")\n",
    "print(f\"WER: {pipeline_1_wer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 2 (Yolo + Universal.io + Gemma 3 + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read md file\n",
    "with open('res/pipeline_2_res.md', encoding=\"utf8\") as f:\n",
    "    pipeline_2_res = f.read()\n",
    "\n",
    "# display md file\n",
    "# display(Markdown(pipeline_2_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER: 0.246193528175354\n",
      "WER: 0.25080104864549957\n"
     ]
    }
   ],
   "source": [
    "pipeline_2_cer, pipeline_2_wer = benchmark(benchmark_data, pipeline_2_res)\n",
    "\n",
    "print(f\"CER: {pipeline_2_cer}\")\n",
    "print(f\"WER: {pipeline_2_wer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 3 (Yolo + Universal.io + Gemma 3 + phi-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('json_res/pipeline_2_res.jsonl') as f:\n",
    "#     pipeline_2_res = json.load(f)\n",
    "\n",
    "# pipeline_2_cer, pipeline_2_wer = benchmark_text(benchmark_data, pipeline_2_res)\n",
    "\n",
    "# print(f\"CER List: {pipeline_2_cer}\")\n",
    "# print(f\"WER List: {pipeline_2_wer}\")\n",
    "# print()\n",
    "# print(f\"Average CER: {sum(pipeline_2_cer)/len(pipeline_2_cer):.4f}\")\n",
    "# print(f\"Average WER: {sum(pipeline_2_wer)/len(pipeline_2_wer):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
