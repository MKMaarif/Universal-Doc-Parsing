{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_images_in_markdown(markdown_str: str, images_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Replace image placeholders in markdown with base64-encoded images.\n",
    "\n",
    "    Args:\n",
    "        markdown_str: Markdown text containing image placeholders\n",
    "        images_dict: Dictionary mapping image IDs to base64 strings\n",
    "\n",
    "    Returns:\n",
    "        Markdown text with images replaced by base64 data\n",
    "    \"\"\"\n",
    "    for img_name, base64_str in images_dict.items():\n",
    "        markdown_str = markdown_str.replace(\n",
    "            f\"![{img_name}]({img_name})\", f\"![{img_name}]({base64_str})\"\n",
    "        )\n",
    "    return markdown_str\n",
    "\n",
    "def get_combined_markdown(ocr_response, method=\"default\") -> str:\n",
    "    \"\"\"\n",
    "    Combine OCR text and images into a single markdown document.\n",
    "\n",
    "    Args:\n",
    "        ocr_response: Response from OCR processing containing text and images\n",
    "\n",
    "    Returns:\n",
    "        Combined markdown string with embedded images\n",
    "    \"\"\"\n",
    "    markdowns: list[str] = []\n",
    "    # Extract images from page\n",
    "\n",
    "    # Exception for mistral\n",
    "    for page in ocr_response[\"pages\"]:\n",
    "        if method == \"mistral\":\n",
    "            image_data = {}\n",
    "            for img in page[\"images\"]:\n",
    "                image_data[img[\"id\"]] = img[\"image_base64\"]\n",
    "            # Replace image placeholders with actual images\n",
    "            markdowns.append(replace_images_in_markdown(page[\"markdown\"], image_data) + \"\\n\\n---\\n\\n\")    \n",
    "        else:\n",
    "            markdowns.append(page[\"markdown\"] + \"\\n\\n---\\n\\n\")\n",
    "\n",
    "    return \"\\n\\n\".join(markdowns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "PFU Business report\n",
       "No.068\n",
       "\n",
       "# New customer's development and increasing the sale of product\n",
       "\n",
       "My country economy at this season keeps escaping from Odoba of business though holds a crude oil high so on unstable element that continues still, and recovering gradually and well. In the IT industry, there is an influence such as competing intensification in narrowing investment field.\n",
       "\n",
       "## [The main product and service at this season]\n",
       "\n",
       "### From the product headquarters\n",
       "In the image business, the new model turning on of the A3 high-speed, two sided color scanner that achieved a high-speed reading aimed at wroom was established in United States, Europe, and Asia/Oceania.\n",
       "\n",
       "### Image business\n",
       "1) Scanner class\n",
       "A3 high-speed, two sided color scanner \"fi-5900C\" that 100 high-n function to enable industry-leading was installed was announced in ScanSnap gotten popular because of an office and individual use.\n",
       "\n",
       "2) DLM solution scanner\n",
       "The DLM solution that used received the rise of the concern to efficient management and internal management of the corporate private circumstances report in recent years and attracted attention. The function of software that the inspection of data is possible by the sense that turns over the file is strengthened, and easiness to use has been improved.\n",
       "\n",
       "| Satisfaction rating to new product |     |\n",
       "|------------------------------------|-----|\n",
       "| Very good                          | 47% |\n",
       "| Good                               | 26% |\n",
       "| Usually                            | 20% |\n",
       "| Bad                                | 7%  |\n",
       "\n",
       "## [approach on business risk]\n",
       "\n",
       "### In-house activity\n",
       "The attestation intended for each office in Shinbashi, Kansai, and Tokai was acquired in environment ISO in February, 2006. In addition, it participates in the minus 6% that is a national movement of the global warming prevention, and \"Culbiz\" is done. The scandal of the enterprise has frequently generated is received, concern is sent to the system maintenance including the observance of the law in recent years.\n",
       "\n",
       "### Enhancement of system of management\n",
       "The committee that aimed at the decrease of a variety of business risks in an individual business talk was newly established. Moreover, the recognition of \"Privacy mark\" is received to manage customer and employee's individual information appropriately in 2001, and the activity based on the protection of individual information policy is continued. It is Asia/Oceania in global. In addition, our technology, commodity power, and correspondence power were evaluating acquired.\n",
       "\n",
       "| Year | Satisfaction rating to new product |\n",
       "|------|-----------------------------------|\n",
       "| 1998 | 80                                |\n",
       "| 1999 | 28                                |\n",
       "| 2000 | 65                                |\n",
       "| 2001 | 62                                |\n",
       "| 2002 | 58                                |\n",
       "| 2003 | 35                                |\n",
       "| 2004 | 98                                |\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\n",
       "\n",
       "Contents lists available at ScienceDirect\n",
       "\n",
       "# CIRP Journal of Manufacturing Science and Technology\n",
       "\n",
       "journal homepage: www.elsevier.com/locate/cirpj\n",
       "\n",
       "# Augmented reality training for improved learnability\n",
       "\n",
       "Dedy Ariansyah a, Bens Pardamean a,b, Eddine Barbaro c, John Ahmet Erkoyuncu c,*\n",
       "\n",
       "a Bioinformatics & Data Science Research Center, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "b Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "c School of Aerospace, Transport and Manufacturing, Cranfield, Bedfordshire MK43 0AL, UK\n",
       "\n",
       "## ARTICLE INFO\n",
       "\n",
       "Keywords:\n",
       "Augmented Reality\n",
       "Learnability\n",
       "Training\n",
       "Industry 4.0\n",
       "Industry 5.0\n",
       "\n",
       "## ABSTRACT\n",
       "\n",
       "In the current era of Industry 4.0, many new technologies offer manufacturing industries to achieve high productivity. Augmented Reality (AR) is one of the emerging technologies that has been adopted in industries to aid users in acquiring complex skills and carrying out many complicated tasks such product assembly and maintenance. Nevertheless, most AR applications have been developed without clear understanding of how such technology can facilitate improved learnability in terms of knowledge reusability. This paper proposed an enhanced AR-based training system that provides multimodal information with a contextualized information to improve task comprehension and knowledge reusability compared with traditional AR that presents unimodal and decontextualized information. An empirical test was carried out to assess the task performance and the task learnability aspects of this enhanced AR compared to the traditional AR and the paper-based document. The experiment consisted of a training phase where participants carried out an electrical connection task of a sensor followed by a knowledge reuse phase where participants had to wire a second sensor using their previous training. A pre-test quiz was given before the experiment followed by the post-tests phase after the training. Post-tests consist of one post-test given directly after the experiment (short-term retention test) and a second post-test quiz given one week later (long-term retention test) to measure information retention. The results indicated that AR-based approaches could enhance knowledge acquisition by around 18 % for traditional AR and almost 25 % for enhanced AR as compared to paper-based approach. While all training systems achieved relatively equivalent well for short-term retention test, trainees who used the enhanced AR training systems statistically outperformed those in the paper-based group for long term retention test. Furthermore, there was a positive correlation between the score of short-term retention test and the score in the knowledge reusability which was also shown by the higher scores in knowledge reusability for the enhanced AR training system compared to the other two approaches. These findings are discussed in relation to the Industry 5.0's human centric core value.\n",
       "\n",
       "## 1. Introduction\n",
       "\n",
       "The adoption of Industry 4.0 technologies enables new capabilities to produce and to deliver product faster with a better quality, and more cost efficient. However, this industrial revolution is leading to an increased complexity of manufacturing systems and an increasingly rapid renewal of these systems. Consequently, upskilling employees' competencies to handle and maintain the complex engineering assets (CEAs) is indispensable. In recent years, finding a skilled worker has become a difficult task. The reason is that there is a talent shortage nowadays. Indeed, in 2018, 45 % of employers said that they could not find the necessary skills among candidates [17]. Furthermore, a new issue will arise from adapting to the changing job dynamics brought about by digitalization [27]. Despite the increased interconnectedness and availability of information globally, the progress of digitalization has not been uniformed across countries or even within industries within the same country [14]. To face this challenge and meet with the adoption of Industry 4.0, employers need to find a new way to ensure their workforces are sufficiently equipped to work with CEAs. In the aviation sector, research examined that traditional training such as in-class training and paper-based manual are not reliable means for teaching job tasks and the skills for visual inspection for the future trend in aviation [11,29]. Visual inspection requires Aircraft Maintenance Technician (AMT) to identify certain characteristics of all types of faults and make decision to troubleshoot various systems from one airplane to another. Due to highly complexity and interrelated components in the\n",
       "\n",
       "* Corresponding author.\n",
       "E-mail address: j.a.erkoyuncu@cranfield.ac.uk (J.A. Erkoyuncu).\n",
       "\n",
       "https://doi.org/10.1016/j.cirpj.2023.11.003\n",
       "Received 29 March 2023; Received in revised form 4 September 2023; Accepted 2 November 2023\n",
       "Available online 6 December 2023\n",
       "1755-5817/� 2024 The Authors. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "D. Ariansyah et al.\n",
       "\n",
       "CIRP Journal of Manufacturing Science and Technology 48 (2024) 19–27\n",
       "\n",
       "| Type          | Mean Task Completion Time (min) |\n",
       "|---------------|--------------------------------:|\n",
       "| Traditional AR| 19.26                           |\n",
       "| Enhanced AR   | 19.57                           |\n",
       "| Paper-based   | 20.47                           |\n",
       "\n",
       "Fig. 4. Mean Task Completion Time.\n",
       "\n",
       "| Type          | Mean number of mistakes |\n",
       "|---------------|------------------------:|\n",
       "| Traditional AR| 1.00                    |\n",
       "| Enhanced AR   | 0.60                    |\n",
       "| Paper-based   | 1.75                    |\n",
       "\n",
       "Fig. 5. Mean number of mistakes.\n",
       "\n",
       "among groups ((F(2,10) = 1.335, p = 0.306).\n",
       "\n",
       "### 4.8. Knowledge retention and reusability correlation\n",
       "\n",
       "The associations between knowledge retention and knowledge reusability along as well as between short- and long-term retention were shown on the Table 6. Point-Biserial Correlation determined that\n",
       "\n",
       "Table 6\n",
       "Knowledge retention scores relative to the baseline.\n",
       "\n",
       "|                    | Traditional AR group (4 People) | Enhanced AR group (5 People) | Paper-based group (4 People) |\n",
       "|--------------------|---------------------------------|------------------------------|------------------------------|\n",
       "| ST                 | * *61.37 %                      | * *67.27 %                   | * 43.18 %                    |\n",
       "| LT                 | * *54.54 %                      | * *74.54 %                   | * 40.91 %                    |\n",
       "| LT - ST            | -6.83 %                         | 7.27 %                       | -2.27 %                      |\n",
       "|ST (short-term), LT (long-term)|                      |                              |                              |\n",
       "\n",
       "*p < 0.05\n",
       "**p < 0.01\n",
       "\n",
       "knowledge reusability had a statistically significant positive correlation with short-term retention score (rpb = 0.672, n = 13, p = 0.012), but not for long-term retention scores (rpb = 0.466, n = 13, p = 0.108). However, when knowledge retention between short- and long-term was analyzed, Pearson's correlation showed that there was a positive correlation between both, which was statistically significant (rp = 0.717, n = 13, p = 0.006). Fig. 6 illustrates the comparison for the success rate of wiring a second sensor by comparing the traditional AR, Enhanced AR and Paper based approaches, achieving 50%, 80% and 25% respectively.\n",
       "\n",
       "## 5. Discussion\n",
       "\n",
       "Many applications have shown that AR technology can improve learnability when acquiring new skills or concepts over traditional training in terms of knowledge comprehension rate and knowledge retention. The superiority of AR lies in its capability to overlay interactive and animated information in a timely manner. This helps to increase user's motivation to engage with the content which is essential to encourage learning. Besides, allowing users to see the necessary information at a favorable time results in a more efficient use of cognitive resources and in turn accommodates more learning. Nevertheless, the current paradigm in using AR for training seems to focus on a limited aspect of productivity such as task performance and knowledge retention enablement. In the light of Industry 5.0 which emphasizes on human centric, sustainability, and resilience, technology is expected to be developed in ways that serve human needs for upskilling or reskilling, with efficient use of resources, and better equip human to deal with uncertainties [15,31]. In attempt to expand the knowledge in this area, this study sought to base the development of AR system for training on human centric principles to facilitate meaningful learning and achieve improved learnability in terms of retention test and transfer test (see Table 7).\n",
       "\n",
       "The results in the retention test showed that all users demonstrated statistically significant understanding in the given task regardless of which training system (see Table 5). However, users in the AR groups were able to get an overall higher number of correct answers (18% for the traditional and ~25 % for the enhanced) than paper-based manual despite completion time and number of mistakes committed were similar across groups. Although the differences were not significant in the short-term test, the higher scores observed in AR groups could be due to more extraneous processing occurred in the paper-based manual group whereas more essential processing occurred in the AR groups. Essential processing involves intrinsic load or essential material/\n",
       "\n",
       "| Type          | Success rate |\n",
       "|---------------|-------------:|\n",
       "| Traditional AR| 50%          |\n",
       "| Enhanced AR   | 80%          |\n",
       "| Paper-based   | 25%          |\n",
       "\n",
       "Fig. 6. Success rate of wiring a second sensor.\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "D. Ariansyah et al.\n",
       "\n",
       "CIRP Journal of Manufacturing Science and Technology 48 (2024) 19–27\n",
       "\n",
       "```mermaid\n",
       "graph TD\n",
       "    A[Image recognition] --> B[Vuforia]\n",
       "    B --> C[Image fetched in database]\n",
       "    C --> D[Unity]\n",
       "    D --> E[MRTK]\n",
       "    D --> F[Unity + vuforia Extension]\n",
       "    E --> G[App build]\n",
       "    F --> G[App build]\n",
       "    G --> H[Visual Studio]\n",
       "    H --> I[App deployment]\n",
       "    I --> J[Microsoft HoloLens 2]\n",
       "    J --> K[Final app]\n",
       "```\n",
       "\n",
       "Fig. 1. System architecture of AR system.\n",
       "\n",
       "Further, the task was tested under three different learning interfaces:\n",
       "(1) a paper-based document that serves as a control group against AR\n",
       "systems, (2) a traditional AR-based training system, and (3) an enhanced\n",
       "AR-based training system that was developed by applying design principles that encourage meaningful learning.\n",
       "\n",
       "### 3.3.1.1. The paper-based document\n",
       "The paper-based document (see: 10.17862/cranfield.rd.24079371) contains all information about the electronic system and its components. It also consists of a step-by-step information in the form of textual instruction and pictures to complete a wiring task.\n",
       "\n",
       "### 3.3.1.2. The traditional AR-based training system\n",
       "This training system replicated most of AR systems used for learning the assembly tasks which include textual information, graphical objects (e.g. arrow) for pointing certain objects, and videos. Users were initially presented with an overview of the electronic system and its all components using tooltips and graphical arrows (See Fig. 2(a)). To acquire skills in wiring the system, assembly instructions were presented step by step on top of the workspace in the form of texts as well as videos which describe the task and how to do it (See Fig. 2(b)). The users can pause and play the video as much as they like and proceed to the next step.\n",
       "\n",
       "### 3.3.1.3. The enhanced AR-based training system\n",
       "The enhanced AR-based training system was similar to the traditional one regarding the contents. However, it had voice cues (multimodal information) that gives additional context and information to the user. For example, during the unscrewing part of the power supply, the voice cue gives additional information on how to perform the task: \"To loosen the screws, do two or three counterclockwise turns with the screwdriver on both screws\". It also included common mistakes and consequences panel after each step to enable the user to grasp the significance of their actions and increase the understanding of the system behavior (projection of the given states and their consequences) as shown in Fig. 3.\n",
       "\n",
       "### 3.3.2. Experimental procedure\n",
       "To examine how different methods of learning affect users in understanding the task and reusing the acquired knowledge to a different situation, this study assessed independent groups of users (between-subjects test) who were assigned to each learning method to learn the same task. Each participant was asked to fill out a demographic questionnaire (see: 10.17862/cranfield.rd.24079371) which includes electronical and augmented reality background questionnaire to check whether they had done some tasks related electronics system and if they were familiar with the use of AR prior to the experiment. After that, each participant was given a questionnaire with questions related to the studied wiring task to test their initial knowledge about the system. The test consisted of questions about the identification of different components they would use during the task and about general knowledge given during the experiment. Following this, a total of thirteen participants were involved in this experiment where four people were assigned in traditional AR group, five people in the enhanced AR group, and four people in the paper-based document group. They were all students (Male = 6, Female = 7) and aged between 25 and 35 years old. Their knowledge about electronics was balanced across the groups (See Section 4.1). The test was graded over 11 questions and was also given after they finished the task to measure the amount of information they learned after going through a training (short term retention test). One week later, each participant was assessed again with the same questionnaire to test their capability to remember what they learned (long term retention test). The duration of a week has been used in many studies for memory retention test [16,26]. Furthermore, participants were not told that the questionnaire would be the same after one week. Existing studies that measured task learnability typically focused on\n",
       "\n",
       "\n",
       "Traditional AR-based training system showing the overview of the electronic wiring system and assembly instructions in textual form and video.\n",
       "\n",
       "Fig. 2. Traditional AR-based training system: (a) the overview of the electronic wiring system, (b) assembly instructions in the textual form and video.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "# UNITED TRACTORS\n",
       "member of ASTRA\n",
       "\n",
       "# PT UNITED TRACTORS Tbk DAN ENTITAS ANAK\n",
       "\n",
       "PERNYATAAN DIREKSI\n",
       "TENTANG TANGGUNG JAWAB TERHADAP\n",
       "LAPORAN KEUANGAN\n",
       "KONSOLIDASIAN INTERIM\n",
       "PT UNITED TRACTORS Tbk\n",
       "DAN ENTITAS ANAK (“GRUP”)\n",
       "TANGGAL 31 MARET 2024 DAN 31 DESEMBER 2023\n",
       "SERTA PERIODE-PERIODE TIGA BULAN\n",
       "YANG BERAKHIR 31 MARET 2024 DAN 2023\n",
       "\n",
       "Kami yang bertanda tangan di bawah ini:\n",
       "\n",
       "1.  Nama : FXL Kesuma\n",
       "    Alamat kantor : Jl. Raya Bekasi Km 22 Cakung, Jakarta 13910\n",
       "    Alamat rumah : Jl. Wijaya Kusuma 49 Cilandak Jakarta Selatan\n",
       "    No. Telepon : 021 - 24579999\n",
       "    Jabatan : Presiden Direktur\n",
       "2.  Nama : Vilihati Surya\n",
       "    Alamat kantor : Jl. Raya Bekasi Km 22 Cakung, Jakarta 13910\n",
       "    Alamat rumah : Jl. Janur Elok VII QF-7/11A Kelapa Gading Jakarta Utara\n",
       "    No. Telepon : 021 - 24579999\n",
       "    Jabatan : Direktur\n",
       "\n",
       "menyatakan bahwa:\n",
       "\n",
       "1. Kami bertanggung jawab atas penyusunan dan penyajian laporan keuangan konsolidasian interim Grup;\n",
       "2. Laporan .keuangan konsolidasian interim Grup telah disusun dan disajikan sesuai dengan Standar Akuntansi\n",
       "Keuangan di Indonesia;\n",
       "3.  a. Semua _ informasi dalam  laporan keuangan konsolidasian interim Grup telah dimuat secara lengkap dan benar;\n",
       "    b. Laporan keuangan konsolidasian interim Grup tidak mengandung informasi atau fakta material yang tidak benar, dan tidak menghilangkan informasi atau fakta material;\n",
       "4. Kami bertanggung jawab atas sistem pengendalian internal dalam Grup.\n",
       "\n",
       "Demikian pernyataan ini dibuat dengan sebenarnya.\n",
       "\n",
       "# PT UNITED TRACTORS Tbk AND SUBSIDIARIES\n",
       "\n",
       "BOARD OF DIRECTORS’ STATEMENT\n",
       "REGARDING THE RESPONSIBILITY FOR\n",
       "THE INTERIM CONSOLIDATED\n",
       "FINANCIAL STATEMENTS\n",
       "OF PT UNITED TRACTORS Tbk\n",
       "AND SUBSIDIARIES (THE “GROUP”)\n",
       "AS AT 31 MARCH 2024 AND 31 DECEMBER 2023\n",
       "AND FOR THE THREE-MONTH PERIODS\n",
       "ENDED 31 MARCH 2024 AND 2023\n",
       "\n",
       "We, the undersigned:\n",
       "1.  Name : FXL Kesuma\n",
       "    Office address : Jl. Raya Bekasi Km 22 Cakung, Jakarta 13910\n",
       "    Residential address: Jl. Wijaya Kusuma 49 Cilandak Jakarta Selatan\n",
       "    Telephone No. : 021 - 24579999\n",
       "    Title : President Director\n",
       "2.  Name : Vilihati Surya\n",
       "    Office address : Jl. Raya Bekasi Km 22 Cakung, Jakarta 13910\n",
       "    Residential address: Jl. Janur Elok VII QF-7/11A Kelapa Gading Jakarta Utara\n",
       "    Telephone No. / 021 - 24579999\n",
       "    Title : Director\n",
       "\n",
       "declare that:\n",
       "\n",
       "1. We are responsible for the preparation and presentation of the Group’s interim consolidated financial statements;\n",
       "2. The Group’s interim consolidated financial statements have been prepared and presented in accordance with the Indonesian Financial Accounting Standards;\n",
       "3.  a. All information in the Group’s interim consolidated financial statements has been disclosed in a complete and truthful manner;\n",
       "    b. The Group’s interim consolidated financial statements do not contain any incorrect information or material fact, nor do they omit information or material fact;\n",
       "4. We are responsible for Group’s internal control system.\n",
       "\n",
       "Thus this statement is made truthtully.\n",
       "\n",
       "Atas nama dan mewakili Direksi/For and on behalf of the Board of Directors\n",
       "\n",
       "JAKARTA\n",
       "\n",
       "29 April 2024\n",
       "\n",
       "FXL Kesuma\n",
       "\n",
       "Presiden Direktur/President Director\n",
       "\n",
       "Vilihati Surya\n",
       "\n",
       "Direktur/Director\n",
       "\n",
       "Moving as one\n",
       "\n",
       "PT UNITED TRACTORS Tbk | Jl. Raya Bekasi Km 22, Jakarta 13910 - Indonesia | T: +62 21 2457 9999 | F: +62 21 4600657\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "# PT UNITED TRACTORS Tbk DAN ENTITAS ANAK/AND SUBSIDIARIES\n",
       "\n",
       "Lampiran 1/1 Schedule\n",
       "\n",
       "## LAPORAN POSISI KEUANGAN KONSOLIDASIAN INTERIM 31 MARET 2024 DAN 31 DESEMBER 2023\n",
       "(Dinyatakan dalam jutaan Rupiah, kecuali dinyatakan lain)\n",
       "\n",
       "## INTERIM CONSOLIDATED STATEMENTS OF FINANCIAL POSITION 31 MARCH 2024 AND 31 DECEMBER 2023\n",
       "(Expressed in millions of Rupiah, unless otherwise stated)\n",
       "\n",
       "| | 31/03/2024 | Catatan/ Notes | 31/12/2023 | |\n",
       "|---|---|---|---|---|\n",
       "| Aset | | | | Assets |\n",
       "| Aset lancar | | | | Current assets |\n",
       "| Kas dan setara kas | 22,246,140 | 3 | 18,596,609 | Cash and cash equivalents |\n",
       "| Piutang usaha | | | | Trade receivables |\n",
       "| - Pihak ketiga | 18,435,677 | 4 | 18,953,089 | Third parties - |\n",
       "| - Pihak berelasi | 981,633 | 4,35c | 1,321,493 | Related parties - |\n",
       "| Piutang non-usaha | | | | Non-trade receivables |\n",
       "| - Pihak ketiga | 773,229 | | 833,144 | Third parties - |\n",
       "| - Pihak berelasi | 1,342,150 | 35c | 1,207,575 | Related parties - |\n",
       "| Persediaan | 17,220,278 | 6 | 17,184,208 | Inventories |\n",
       "| Proyek dalam pelaksanaan | | | | Project under construction |\n",
       "| - Pihak ketiga | 114,648 | | 111,259 | Third parties |\n",
       "| Pajak dibayar dimuka | | | | Prepaid taxes |\n",
       "| - Pajak penghasilan badan | 1,100,303 | 16a | 910,334 | Corporate income taxes - |\n",
       "| - Pajak lain-lain | 1,589,010 | 16a | 2,196,826 | Other taxes - |\n",
       "| Uang muka dan biaya dibayar dimuka | 1,247,514 | 7 | 1,103,109 | Advances and prepayments |\n",
       "| Aset lancar lain-lain | 256,470 | | 249,459 | Other current assets |\n",
       "| | 65,307,052 | | 62,667,105 | |\n",
       "| Aset tidak lancar | | | | Non-current assets |\n",
       "| Kas dan deposito berjangka yang dibatasi penggunaannya | 621,233 | 3 | 561,219 | Restricted cash and time deposits |\n",
       "| Piutang usaha | | | | Trade receivables |\n",
       "| - Pihak ketiga | 351,299 | 4 | 107,565 | Third parties - |\n",
       "| - Pihak berelasi | 15,841 | 4,35c | 16,514 | Related parties - |\n",
       "| Piutang non-usaha | | | | Non-trade receivables |\n",
       "| - Pihak ketiga | 306,151 | | 311,702 | Third parties - |\n",
       "| - Pihak berelasi | 3,505,595 | 35c | 2,867,712 | Related parties - |\n",
       "| Persediaan | 86,947 | 6 | 82,497 | Inventories |\n",
       "| Pajak dibayar dimuka | | | | Prepaid taxes |\n",
       "| - Pajak penghasilan badan | 23,164 | 16a | 75,699 | Corporate income tax - |\n",
       "| - Pajak lain-lain | 2,098,755 | 16a | 1,731,673 | Other taxes - |\n",
       "| Uang muka dan biaya dibayar dimuka | 389,139 | 7 | 1,298,672 | Advances and prepayments |\n",
       "| Investasi pada entitas asosiasi dan ventura bersama | 17,551,248 | 8 | 14,853,244 | Investments in associates and joint ventures |\n",
       "| Investasi jangka panjang | 1,288,213 | 8 | 1,243,018 | Long-term investments |\n",
       "| Aset tetap | 37,512,715 | 9 | 36,001,559 | Fixed assets |\n",
       "| Properti pertambangan | 17,698,024 | 10a | 17,845,848 | Mining properties |\n",
       "| Properti investasi | 228,097 | 11 | 228,097 | Investment properties |\n",
       "| Beban eksplorasi dan pengembangan tangguhan | 2,513,388 | 10b | 2,374,321 | Deferred exploration and development expenditures |\n",
       "| Aset tambang berproduksi | 4,496,914 | 10c | 4,488,727 | Production mining assets |\n",
       "| Beban tangguhan | 1,413,176 | | 1,448,506 | Deferred charges |\n",
       "| Aset pajak tangguhan | 3,697,201 | 16d | 3,537,279 | Deferred tax assets |\n",
       "| Goodwill | 2,342,623 | 12 | 2,287,291 | Goodwill |\n",
       "| | 96,119,723 | | 91,361,143 | |\n",
       "| Jumlah aset | 161,426,775 | | 154,028,248 | Total assets |\n",
       "\n",
       "Catatan atas laporan keuangan konsolidasian merupakan bagian yang tidak terpisahkan dari laporan keuangan konsolidasian.\n",
       "\n",
       "The accompanying notes form an integral part of these consolidated financial statements.\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read json file\n",
    "with open('res/benchmark_data.json') as f:\n",
    "    benchmark_data = json.load(f)\n",
    "\n",
    "# Display\n",
    "display(Markdown(get_combined_markdown(benchmark_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LlamaParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# New customer's development and increasing the sale of product\n",
       "\n",
       "My country economy at this season keeps escaping from Odoba of business though holds a crude oil high so on unstable element that continues still, and recovering gradually and well. In the IT industry, there is an influence such as competing intensification in narrowing investment field.\n",
       "\n",
       "## The main product and service at this season\n",
       "\n",
       "### From the product headquarters\n",
       "In the image business, the new model turning on of the A3 high-speed, two sided color scanner that achieved a high-speed reading aimed at wroom was established in United States, Europe, and Asia/Oceania.\n",
       "\n",
       "### Image business\n",
       "1) Scanner class\n",
       "A3 high-speed, two sided color scanner \"fi-5900C\" that 100 high-n function to enable industry-leading was installed was announced in ScanSnap gotten popular because of an office and individual use.\n",
       "\n",
       "2) DLM solution scanner\n",
       "The DLM solution that used received the rise of the concern to efficient management and internal management of the corporate private circumstances report in recent years and attracted attention. The function of software that the inspection of data is possible by the sense that turns over the file is strengthened, and easiness to use has been improved.\n",
       "\n",
       "| Satisfaction rating to new product |     |\n",
       "|------------------------------------|-----|\n",
       "| Very good                          | 47% |\n",
       "| Good                               | 26% |\n",
       "| Usually                            | 20% |\n",
       "| Bad                                | 7%  |\n",
       "\n",
       "## Approach on business risk\n",
       "\n",
       "### In-house activity\n",
       "The attestation intended for each office in Shinbashi, Kansai, and Tokai was acquired in environment ISO in February, 2006. In addition, it participates in the minus 6% that is a national movement of the global warming prevention, and \"Culbiz\" is done. The scandal of the enterprise has frequently generated is received, concern is sent to the system maintenance including the observance of the law in recent years.\n",
       "\n",
       "### Enhancement of system of management\n",
       "The committee that aimed at the decrease of a variety of business risks in an individual business talk was newly established. Moreover, the recognition of \"Privacy mark\" is received to manage customer and employee's individual information appropriately in 2001, and the activity based on the protection of individual information policy is continued. It is Asia/Oceania in global. In addition, our technology, commodity power, and correspondence power were evaluating acquired.\n",
       "\n",
       "| Year | Satisfaction rating to new product |\n",
       "|------|-----------------------------------|\n",
       "| 1998 | 80                                |\n",
       "| 1999 | 28                                |\n",
       "| 2000 | 65                                |\n",
       "| 2001 | 62                                |\n",
       "| 2002 | 58                                |\n",
       "| 2003 | 35                                |\n",
       "| 2004 | 98                                |\n",
       "        \n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\n",
       "\n",
       "Contents lists available at ScienceDirect\n",
       "\n",
       "# CIRP Journal of Manufacturing Science and Technology\n",
       "\n",
       "journal homepage: www.elsevier.com/locate/cirpj\n",
       "\n",
       "## Augmented reality training for improved learnability\n",
       "\n",
       "Dedy Ariansyah a, Bens Pardamean a,b, Eddine Barbaro c, John Ahmet Erkoyuncu c,*\n",
       "\n",
       "a Bioinformatics & Data Science Research Center, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "b Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "c School of Aerospace, Transport and Manufacturing, Cranfield, Bedfordshire MK43 0AL, UK\n",
       "\n",
       "### ARTICLE INFO\n",
       "\n",
       "**Keywords:**\n",
       "Augmented Reality\n",
       "Learnability\n",
       "Training\n",
       "Industry 4.0\n",
       "Industry 5.0\n",
       "\n",
       "### ABSTRACT\n",
       "\n",
       "In the current era of Industry 4.0, many new technologies offer manufacturing industries to achieve high productivity. Augmented Reality (AR) is one of the emerging technologies that has been adopted in industries to aid users in acquiring complex skills and carrying out many complicated tasks such product assembly and maintenance. Nevertheless, most AR applications have been developed without clear understanding of how such technology can facilitate improved learnability in terms of knowledge reusability. This paper proposed an enhanced AR-based training system that provides multimodal information with a contextualized information to improve task comprehension and knowledge reusability compared with traditional AR that presents unimodal and decontextualized information. An empirical test was carried out to assess the task performance and the task learnability aspects of this enhanced AR compared to the traditional AR and the paper-based document. The experiment consisted of a training phase where participants carried out an electrical connection task of a sensor followed by a knowledge reuse phase where participants had to wire a second sensor using their previous training. A pre-test quiz was given before the experiment followed by the post-tests phase after the training. Post-tests consist of one post-test given directly after the experiment (short-term retention test) and a second post-test quiz given one week later (long-term retention test) to measure information retention. The results indicated that AR-based approaches could enhance knowledge acquisition by around 18 % for traditional AR and almost 25 % for enhanced AR as compared to paper-based approach. While all training systems achieved relatively equivalent well for short-term retention test, trainees who used the enhanced AR training systems statistically outperformed those in the paper-based group for long term retention test. Furthermore, there was a positive correlation between the score of short-term retention test and the score in the knowledge reusability which was also shown by the higher scores in knowledge reusability for the enhanced AR training system compared to the other two approaches. These findings are discussed in relation to the Industry 5.0's human centric core value.\n",
       "\n",
       "### 1. Introduction\n",
       "\n",
       "The adoption of Industry 4.0 technologies enables new capabilities to produce and to deliver product faster with a better quality, and more cost efficient. However, this industrial revolution is leading to an increased complexity of manufacturing systems and an increasingly rapid renewal of these systems. Consequently, upskilling employees' competencies to handle and maintain the complex engineering assets (CEAs) is indispensable. In recent years, finding a skilled worker has become a difficult task. The reason is that there is a talent shortage nowadays. Indeed, in 2018, 45 % of employers said that they could not find the necessary skills among candidates [17]. Furthermore, a new issue will arise from adapting to the changing job dynamics brought about by digitalization [27]. Despite the increased interconnectedness and availability of information globally, the progress of digitalization has not been uniformed across countries or even within industries within the same country [14]. To face this challenge and meet with the adoption of Industry 4.0, employers need to find a new way to ensure their workforces are sufficiently equipped to work with CEAs. In the aviation sector, research examined that traditional training such as in-class training and paper-based manual are not reliable means for teaching job tasks and the skills for visual inspection for the future trend in aviation [11,29]. Visual inspection requires Aircraft Maintenance Technician (AMT) to identify certain characteristics of all types of faults and make decision to troubleshoot various systems from one airplane to another. Due to highly complexity and interrelated components in the\n",
       "\n",
       "* Corresponding author.\n",
       "E-mail address: j.a.erkoyuncu@cranfield.ac.uk (J.A. Erkoyuncu).\n",
       "\n",
       "https://doi.org/10.1016/j.cirpj.2023.11.003\n",
       "Received 29 March 2023; Received in revised form 4 September 2023; Accepted 2 November 2023\n",
       "Available online 6 December 2023\n",
       "1755-5817/© 2024 The Authors. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n",
       "        \n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "knowledge reusability had a statistically significant positive correlation with short-term retention score (rpb = 0.672, n = 13, p = 0.012), but not for long-term retention scores (rpb = 0.466, n = 13, p = 0.108). However, when knowledge retention between short- and long-term was analyzed, Pearson's correlation showed that there was a positive correlation between both, which was statistically significant (rp = 0.717, n = 13, p = 0.006). Fig. 6 illustrates the comparison for the success rate of wiring a second sensor by comparing the traditional AR, Enhanced AR and Paper based approaches, achieving 50%, 80% and 25% respectively.\n",
       "\n",
       "## 5. Discussion\n",
       "\n",
       "Many applications have shown that AR technology can improve learnability when acquiring new skills or concepts over traditional training in terms of knowledge comprehension rate and knowledge retention. The superiority of AR lies in its capability to overlay interactive and animated information in a timely manner. This helps to increase user's motivation to engage with the content which is essential to encourage learning. Besides, allowing users to see the necessary information at a favorable time results in a more efficient use of cognitive resources and in turn accommodates more learning. Nevertheless, the current paradigm in using AR for training seems to focus on a limited aspect of productivity such as task performance and knowledge retention enablement. In the light of Industry 5.0 which emphasizes on human centric, sustainability, and resilience, technology is expected to be developed in ways that serve human needs for upskilling or reskilling, with efficient use of resources, and better equip human to deal with uncertainties [15,31]. In attempt to expand the knowledge in this area, this study sought to base the development of AR system for training on human centric principles to facilitate meaningful learning and achieve improved learnability in terms of retention test and transfer test (see Table 7).\n",
       "\n",
       "The results in the retention test showed that all users demonstrated statistically significant understanding in the given task regardless of which training system (see Table 5). However, users in the AR groups were able to get an overall higher number of correct answers (18% for the traditional and ~25 % for the enhanced) than paper-based manual despite completion time and number of mistakes committed were similar across groups. Although the differences were not significant in the short-term test, the higher scores observed in AR groups could be due to more extraneous processing occurred in the paper-based manual group whereas more essential processing occurred in the AR groups. Essential processing involves intrinsic load or essential material/\n",
       "\n",
       "| Type          | Mean Task Completion Time (min) |\n",
       "|---------------|--------------------------------:|\n",
       "| Traditional AR| 19.26                           |\n",
       "| Enhanced AR   | 19.57                           |\n",
       "| Paper-based   | 20.47                           |\n",
       "\n",
       "Fig. 4. Mean Task Completion Time.\n",
       "\n",
       "| Type          | Mean number of mistakes |\n",
       "|---------------|------------------------:|\n",
       "| Traditional AR| 1.00                    |\n",
       "| Enhanced AR   | 0.60                    |\n",
       "| Paper-based   | 1.75                    |\n",
       "\n",
       "Fig. 5. Mean number of mistakes.\n",
       "\n",
       "among groups ((F(2,10) = 1.335, p = 0.306).\n",
       "\n",
       "### 4.8. Knowledge retention and reusability correlation\n",
       "\n",
       "The associations between knowledge retention and knowledge reusability along as well as between short- and long-term retention were shown on the Table 6. Point-Biserial Correlation determined that\n",
       "\n",
       "Table 6\n",
       "Knowledge retention scores relative to the baseline.\n",
       "\n",
       "| Group              | Traditional AR group (4 People) | Enhanced AR group (5 People) | Paper-based group (4 People) |\n",
       "|--------------------|---------------------------------|------------------------------|------------------------------|\n",
       "| ST                 | *61.37 %                        | *67.27 %                     | 43.18 %                      |\n",
       "| LT                 | *54.54 %                        | *74.54 %                     | 40.91 %                      |\n",
       "| LT - ST            | -6.83 %                         | 7.27 %                       | -2.27 %                      |\n",
       "\n",
       "ST (short-term), LT (long-term)\n",
       "*p < 0.05\n",
       "**p < 0.01\n",
       "\n",
       "| Type          | Success rate |\n",
       "|---------------|-------------:|\n",
       "| Traditional AR| 50%          |\n",
       "| Enhanced AR   | 80%          |\n",
       "| Paper-based   | 25%          |\n",
       "\n",
       "Fig. 6. Success rate of wiring a second sensor.\n",
       "        \n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read json data from file\n",
    "with open('json_res/llamaparse_res.jsonl') as f:\n",
    "    llamaparse_res = json.load(f)\n",
    "\n",
    "# Display combined markdowns and images\n",
    "display(Markdown(get_combined_markdown(llamaparse_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mistral OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'json_res/mistralocr_res.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read json data from file\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mjson_res/mistralocr_res.jsonl\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      3\u001b[39m     mistralocr_res = json.load(f)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Display combined markdowns and images\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Vidavox\\Universal Doc Parsing\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:325\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    320\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    321\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'json_res/mistralocr_res.jsonl'"
     ]
    }
   ],
   "source": [
    "# Read json data from file\n",
    "with open('res/mistralocr_res.json') as f:\n",
    "    mistralocr_res = json.load(f)\n",
    "\n",
    "# Display combined markdowns and images\n",
    "display_md = get_combined_markdown(mistralocr_res, method=\"mistral\")\n",
    "\n",
    "# save to file\n",
    "with open('res/mistralocr_res.md', 'w') as f:\n",
    "    f.write(display_md)\n",
    "\n",
    "display(Markdown(display_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1 (Yolo + GOT-OCR2 + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# New customer's development and increasing the sale of product\n",
       "\n",
       "My country economy at this season keeps escaping from Odoba of business though holds a crude oil high so on unstable element that continues still, and recovering gradually and well.\n",
       "In the IT industry, there is an influence such as competing intensification in narrowing investment field.\n",
       "## [The main product and service at this season]\n",
       "\n",
       "## From the product headquarters\n",
       "\n",
       "In the image business, the new model turning on of the A3 high-speed, two sided color scanner that achieved a high-speed reading aimed at. wroom was established in United States, Europe, and Asia/Oceania.\n",
       "## Image business\n",
       "\n",
       "1) Scanner class\n",
       "A3 high-speed, two sided color scanner \"fi-5900C\" that 100 high-*n* function to enable industry-leading was installed was announced in ScanSnap gotten popular because of an office and individual use.\n",
       "2) DLM solution scanner\n",
       "The DLM solution that used received the rise of the concern to efficient management and internal management of the corporate private circumstances report in recent years and attracted attention. The function of software that the inspection of data is possible by the sense that turns over the file is strengthened, and easiness to use has been improved.\n",
       "## [approach on business risk]\n",
       "\n",
       "## In-house activity\n",
       "The attestation intended for each office in Shinbashi, Kansai, and Tokai was acquired in environment ISO in February, 2006. In addition, it participates in the minus 6 % that is a national movement of the global warming prevention, and \"Culbiz\" is done. The scandal of the enterprise has frequently generated is received, concern is sent to the system maintenance including the observance of the law in recent years.\n",
       "## Enhancement of system of management\n",
       "\n",
       "The committee that aimed at the decrease of a variety of business risks in an individual business talk was newly established. Moreover, the recognition of \"Privacy mark\" is received to manage customer and employee's individual information appropriately in 2001, and the activity based on the protection of individual information policy is continued. It is...DAsia/Oceania in globalin addition, our technology, commodity power, and correspondence power were evaluating acquired.\n",
       "\n",
       "### Satisfaction Rating Chart\n",
       "\n",
       "| Year | Satisfaction Rating |\n",
       "|---|---|\n",
       "| 1998 | 80 |\n",
       "| 1999 | 30 |\n",
       "| 2000 | 60 |\n",
       "| 2001 | 55 |\n",
       "| 2002 | 30 |\n",
       "| 2003 | 100 |\n",
       "| 2004 | 15 |\n",
       "\n",
       "### Satisfaction Rating\n",
       "\n",
       "| Category        | Percentage |\n",
       "|-----------------|------------|\n",
       "| Very good       | 47%        |\n",
       "| Good            | 26%        |\n",
       "| Usually         | 20%        |\n",
       "| Bad             | 7%         |\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "## Augmented reality training for improved learnability\n",
       "\n",
       "Dedy Ariansyah ¹, Bens Pardamean ¹, Eddine Barbaro ² , John Ahmet Erkoyuncu * ³\n",
       "\n",
       "* ¹ Bioinformatics \\& Data Science Research Center, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "* ² Computer Science Department, BINIS Graduate Program - Master of Computer Sciences, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "* ³ School of Aerospace, Transport and Manufacturing, Cranfield, Bedfordshire MK47 0AL, UK\n",
       "\n",
       "**A R T I C L E I N F O**\n",
       "\n",
       "**Keywords:**\n",
       "Augmented Reality, Training, Training, Industry 5.0\n",
       "\n",
       "**A B S T R A C T**\n",
       "\n",
       "In the current era of Industry 4.0, many new technologies offer manufacturing industries to achieve high processing, productivity. Augmented Reality (AR) is one of the emerging technologies that has been adopted in industries to aid users in acquiring complex skills and carrying out many complicated tasks such product assembly and maintenance. Nevertheless, most AR applications have been developed without clear understanding of how such technology can facilitate improved learnability in terms of knowledge reusability. This paper proposed an enhanced AR-based training system that provides multimodal information with a contextualized information to the software and the software and the software that is used to support the application of the software and decontextualized information. An empirical test was carried out to assess the task performance and the task learnability aspects of this enhanced AR compared to the traditional AR and the paper-based document. The experiment consisted of a training phase where participants carried out an electrical connection task of a sensor and a sensor to detect the sensor. The experiment consisted of a training phase with a sensor and a sensor training. A pre-test quiz was given before the experiment followed by the post-tests phase after the training. Posttests consist of one post-test given directly after the experiment (short-term retention test) and a second post-test unit (four-year one week later (long-term retention test) to measure the performance of the test. The test was performed on the test set of the test set. The test was performed by around 18 % for traditional AR and almost 25 % for enhanced AR as compared to paper-based approach. While all training systems achieved relatively equivalent well for short-term retention test, trainees who used the enhanced AR training systems statistically outperformed those in the paper-based group for long term retention test. Furthermore, there was a positive correlation between the score of short-term retention test and the score in the knowledge reusability which was also shown by the higher scores in knowledge reusability for the enhanced AR training system compared to the other two approaches. These findings are discussed in relation to the industry 5.05 human centre core value.\n",
       "\n",
       "**Table 1: Experiment Results**\n",
       "\n",
       "| Approach          | Short-Term Retention (%) | Long-Term Retention (%) |\n",
       "|-------------------|-------------------------|-------------------------|\n",
       "| Traditional AR    | 18                       | 25                       |\n",
       "| Enhanced AR       | 25                       | N/A                     |\n",
       "| Paper-Based       | N/A                     | N/A                     |\n",
       "\n",
       "**Footnotetext:**\n",
       "1. Introduction\n",
       "The adoption of Industry 4.0 technologies enables new capabilities to produce and to deliver product faster with a better quality, and more cost efficient. However, this industrial revolution is leading to an increased complexity of manufacturing systems and an increasingly high cost product. However, the industry has been able to be able to approaches. These findings are discussed in relation to the industry 5.05 human centre core value.\n",
       "\n",
       "**Footnotetext:**\n",
       "* Corresponding author.\n",
       "E-mail address: ja.erkoyuncu@cranfield.ac.uk (J.A. Erkoyuncu).\n",
       "https://doi.org/10.1016/j.cirpj.2023.11.003\n",
       "* Corresponding author. In this paper, in revised form 4 September 2023; Accepted 2 November 2023\n",
       "Available online 6 December 2023\n",
       "1755-5817/0 2024 The Authors. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "24:00\n",
       "22:00\n",
       "20:00\n",
       "18:00\n",
       "16:00\n",
       "14:00\n",
       "12:00\n",
       "10:00\n",
       "Traditional AR \\(\\quad\\) Enhanced AR \\(\\quad\\) Paper-based\n",
       "\n",
       "Fig. 4. Mean Task Completion Time.\n",
       "\n",
       "| Method           | Mean Task Completion Time (min) |\n",
       "|------------------|---------------------------------|\n",
       "| Traditional AR   | 19:26                          |\n",
       "| Enhanced AR      | 19:57                          |\n",
       "| Paper-based      | 20:47                          |\n",
       "\n",
       "Traditional AR \\(\\quad\\) Enhanced AR \\(\\quad\\) Paper-based\n",
       "\n",
       "Fig. 5. Mean Number of Mistakes.\n",
       "| Method           | Mean Number of Mistakes | Standard Error |\n",
       "|------------------|-------------------------|----------------|\n",
       "| Traditional AR   | 1.0                     | 0.2            |\n",
       "| Enhanced AR      | 0.6                     | 0.2            |\n",
       "| Paper-based      | 1.75                    | 0.2            |\n",
       "among groups \\((F(2,10)=1.335, p=0.306)\\).\n",
       "\n",
       "\n",
       "### 4.8. Knowledge retention and reusability correlation\n",
       "The associations between knowledge retention and knowledge reusability along as well as between short- and long-term retention were shown on the Table 6. Point-Biserial Correlation determined that\n",
       "Table 6\n",
       "Knowledge retention scores relative to the baseline.\n",
       "| Category          | Traditional AR group (4 People) | Enhanced AR group (5 People) | Paper-based group (4 People) |\n",
       "|-------------------|---------------------------------|-------------------------------|-----------------------------|\n",
       "| ST               | \\(* * 61.37 \\%\\)                | \\(* * 67.27 \\%\\)              | \\(* 43.18 \\%\\)              |\n",
       "| \\(SD\\)    | \\(* * 1.00 \\%\\)                | \\(* 77.54 \\%\\)                | \\(* 40.91 \\%\\)              |\n",
       "| LT - ST           | \\(-6.83 \\%\\)                   | \\(\\mathbf{7. 2 7} \\%\\)         | \\(-2.27 \\%\\)               |\n",
       "| ST (short-term), LT (long-term) | & & & |\n",
       "| \\({ }^{*} p<0.05\\) | & & & |\n",
       "| \\({ }^{* * *} p<0.01\\) | & & & |\n",
       "\n",
       "knowledge reusability had a statistically significant positive correlation with short-term retention score \\((rpb=0.672, n=13, p=0.012)\\), but not for long-term retention scores \\((rpb=0.466, n=13, p=0.108)\\). However, when knowledge retention between short- and long-term was analyzed, Pearson's correlation showed that there was a positive correlation between both, which was statistically significant \\((rp=0.717\\), \\(n=13, p=0.006\\) ). Fig. 6 illustrates the comparison for the success rate of wiring a second sensor by comparing the traditional AR, Enhanced AR and Paper based approaches, achieving \\(50 \\%, 80 \\%\\) and \\(25 \\%\\) respectively..\n",
       "\n",
       "\n",
       "## 5. Discussion\n",
       "Many applications have shown that AR technology can improve learnability when acquiring new skills or concepts over traditional training in terms of knowledge comprehension rate and knowledge retention. The superiority of AR lies in its capability to overlay interrelated learning. In this paper, we propose a novel framework to increase user's motivation to engage with the content which is essential to encourage learning. Besides, allowing users to see the necessary information at a favorable time results in a more efficient use of cognitive resources and in turn accommodates more learning. Nevertheless, the results are based on the results of the proposed method. In this paper, the aspect of productivity such as task performance and knowledge retention enablement. In the light of Industry 5.0 which emphasizes on human centric, sustainability, and resilience, technology is expected to be developed in ways that serve human needs for upskilling or reskilling, and the need for the development of the learning environment. In the current uncertainties [15,. In attempt to expand the knowledge in this area, this study sought to base the development of AR system for training on human centric principles to facilitate meaningful learning and achieve improved learnability in terms of retention test and transfer test (see Table 1).\n",
       "The results in the retention test showed that all users demonstrated statistically significant understanding in the given task regardless of which training system (see Table 5). However, users in the AR groups were able to get an overall higher number of correct answers (18\\% for the first one) and the second one (18\\% for the second one) despite completion time and number of mistakes committed were similar across groups. Although the differences were not significant in the short-term test, the higher scores observed in AR groups could be due to more extraneous processing occurred in the paper-based manual group whereas more essential processing occurred in the AR groups. Essential processing involves intrinsic load or essential material/\n",
       "\n",
       "Fig. 6. Success rate of wiring a second sensor.\n",
       "| Category          | Success Rate (%) |\n",
       "|-------------------|------------------|\n",
       "| Traditional AR    | 50               |\n",
       "| Enhanced AR       | 80               |\n",
       "| Paper-based       | 25               |\n",
       "\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('json_res/pipeline_1_res.jsonl') as f:\n",
    "    pipeline_1_res = json.load(f)\n",
    "\n",
    "# Display combined markdowns and images\n",
    "display(Markdown(get_combined_markdown(pipeline_1_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Augmented reality training for improved learnability\n",
       "\n",
       "## Authors:\n",
       "Dedy Ariansyah ¹, Bens Pardamean ¹,², Eddine Barbaro ³, John Ahmet Erkoyuncu ³\\*\n",
       "¹ Bioinformatics & Data Science Research Center, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "² Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "³ School of Aerospace, Transport and Manufacturing, Cranfield, Bedfordshire MK43 0AL, UK\n",
       "\n",
       "## Keywords:\n",
       "Augmented Reality, Learnability, Training, Industry 4.0, Industry 5.0\n",
       "\n",
       "## Abstract\n",
       "\n",
       "In the current era of Industry 4.0, many new technologies offer manufacturing industries to achieve high productivity. Augmented Reality (AR) is one of the emerging technologies that has been adopted in industries to aid users in acquiring complex skills and carrying out many complicated tasks such as product assembly and maintenance. Nevertheless, most AR applications have been developed without a clear understanding of how such technology can facilitate improved learnability in terms of knowledge reusability. This paper proposed an approach to design and develop software with the aim of improving task comprehension and knowledge reusability compared with traditional AR that presents unimodal and decontextualized information. An empirical test was carried out to assess the task performance and the task learnability aspects of this enhanced AR compared to the traditional AR and the paper-based document. The results show that the software has been developed in the literature. In this paper, we propose a novel framework developed by a knowledge reuse phase where participants had to wire a second sensor using their previous training. A pre-test quiz was given before the experiment followed by the post-tests phase after the training. Posttests consist of one post-test given directly after the experiment (short-term retention test) and a second post-test quiz given one week later (long-term retention test) to measure information retention. The results indicated that the test results were used to compare the performance of the test results. The results were used to be used to perform an enhanced AR as compared to paper-based approach. While all training systems achieved relatively equivalent well for short-term retention test, trainees who used the enhanced AR training systems statistically outperformed those in the paper-based group for long term retention test. Furthermore, there was a positive correlation between the score of short-term retention test and the score in the knowledge reusability which was also shown by the higher scores in knowledge reusability for the enhanced AR training system compared to the other two approaches. These findings are discussed in relation to the Industry 5.0s human centric core value.\n",
       "\n",
       "## 1. Introduction\n",
       "\n",
       "The adoption of Industry 4.0 technologies enables new capabilities to produce and to deliver product faster with a better quality, and more cost efficient. However, this industrial revolution is leading to an increased complexity of manufacturing systems and an increasingly rapid renewal of these systems. Consequently, upskilling employees' competencies to handle and maintain the complex engineering assets (CEAs) is indispensable. In recent years, finding a skilled worker has become a difficult task. The reason is that there is a talent shortage nowadays. Indeed, in 2018, 45 % of employers said that they could not find the necessary skills among candidates. Furthermore, a new issue will arise from adapting to the changing job dynamics brought about by digitalization. Despite the increased interconnectedness has not been uniformed across countries or even within industries within the same country [1-. To face this challenge and meet with the adoption of Industry 4.0, employers need to find a new way to ensure their workforces are sufficiently equipped to work with CEAs. In the aviation sector, research examined that traditional training such as in-class training and paper-based manual are not reliable means for teaching job tasks and the skills for visual inspection for the future trend in aviation [11,. Visual inspection requires Aircraft Maintenance Technician (AMT) to identify certain characteristics of all types of faults and make decision to troubleshoot various systems from one airplane to another. Due to highly complexity and interrelated components in the\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "aircraft, conventional training could lead to long hours of training, and the ability to train training could lead to high levels of training. This is the second that Augmented reality (AR)-based training could help to reduce learning time, cognitive workload, and facilitate knowledge retention [12,16,]. However, training effectiveness with AR could be decreased when the users fail to integrate training materials with their prior knowledge which could lead to poor knowledge retention and knowledge reusability. During real maintenance, this situation could result in prolonged asset downtime, an increase in cost and time associated with a low first-time fix rate. Addressing this challenge entails a strategy or a new paradigm to improve task learnability.\n",
       "\n",
       "In this paper, we propose a novel framework to simplify as \"the degree to which knowledge or skill (in something) can be acquired through study or experience or by being taught\". In the field of cognitive science, the 'ACT-R' (Adaptive Control of Thought-Rational) theory distinguishes knowledge into declarative and procedural knowledge. Procedural knowledge is acquired through practice and refers to information about how to perform a task and an action that can be directly connected to the task. In this paper, we propose a novel framework to implement a cannot be executed directly but can be applied for a specific goal that goes through interpretative process. Complex industrial settings consist of tasks that can contain declarative and procedural knowledge such as design, diagnosis, assembly, management, repair, and training. In nowadays, the way knowledge is acquired and how it is managed to be able to learn and learn the knowledge of the knowledge of the cognitive advantages for organizations. In the organizational context, learnability is defined as \"a concept that captures the ability of employees to acquire the information and know-how necessary and sufficient to execute organizational practices\". A weak learnability in an organization refers to a longer process, an extended effort, and a more frequent exposure need for the employees to acquire know-how in a process that is a good way to improve the quality of the information to a high loss of time and a higher potential for errors which can affect productivity. In general, learning can be evaluated by measuring how much information or know-how can be remembered (retention test) and being able to use the information to solve new problems (transfer test). This means that high learnability entails a high amount of information to be used to improve the quality of the information.\n",
       "\n",
       "Recently, the introduction of Industry 5.0 has been viewed as a forward thinking of how new technologies embraced in Industry 4.0 can be better developed to address the aspects of human-centric, sustainability, and resilience. In this paradigm, there is a growing demand for the development of lifelong learning for workers whereby technologies are used to support one's needs and interests to continuously improve the quality of the information to solve the information to solve the circumstances in the current industrial landscape brought about by the technology shift. Therefore, increasing knowledge retention in long term and knowledge reusability could serve as foundation for lifelong learning which is to enable the ongoing learning and development throughout an individual's life. In this context, it is easy to see that there is a strong influence on the knowledge of the knowledge of the knowledge in a complex, achieving the necessary knowledge more efficiently but also to enable them to retain and to reuse their training in different situations. Augmented Reality (AR) is one of the most promising technologies for Industry 4.0. However, there is limited research that shows how AR is developed to foster long life learning in the industrial context. This is a good way to improve the quality of the information to solve the information to solve this technology and shows the extent to which it could be used for knowledge transmission, more specifically on learnability, retention of knowledge over time, and reusability of knowledge compared to more common learning methods. The next section of this paper reviews existing studies in the literature and presents research questions addressed in this study. Section 3 provides the methods used in this study followed by the results and analysis in the following Section. Section 5 discusses the findings of this work related in focusing study and Section 6 provides conclusion and the future work.\n",
       "\n",
       "## 2. Related work\n",
       "\n",
       "Over the years, Augmented Reality (AR) has been investigated in different applications to understand how it can facilitate learnability. Early research of AR to assist assembly task found that the ability of AR to overlay graphical information on the task at hand to provide step by step guidance on procedural knowledge and corrective instruction can increase users' perception and skills. The increase in perception was found to result in higher knowledge acquisition compared to traditional method. Recent study to provide distance learning also showed that hybrid laboratory leveraging AR could improve knowledge transfer of assembly task to the remote technician. Moreover, AR has also been shown to facilitate knowledge transfer of declarative information on the monitoring of system's performance) through a cloud-enabled AR.\n",
       "\n",
       "Similarly, in the electronic assembly, AR was also found to increase knowledge retention of participants in a procedural task when specific feedback was presented to the user. The results of this study showed that the use of the information delivery, AR users were able to recall more information from long-term memory (e.g., seven day period) in the aviation/aerospace training, leading to a minimal amount of information loss. Moreover, AR was also tested in a simulated control room study to examine its effectiveness as an assistance system for procedural tasks. Compared to the results of the users who used the AR-based approach, the software was able to evaluate the ability of the machine with indicators that AR was more effective in facilitating task comprehension or implementation of a procedure. Accordingly, some studies have attempted to push forward the intake of AR technologies for industrial tasks by developing an AR content authoring tool to support non-AR experts and AR collaboration tools to enable visual augmentation and training.\n",
       "\n",
       "There are a couple of main reasons as to why AR can lead to better knowledge acquisition and retention compared to conventional approaches. Firstly, learning contents presented in AR can enhance learning motivation which involves attention, relevance, confidence, and satisfaction. Motivation can help learners to engage, persist, and improve the ability to learn the information to be used to improve outcomes than unmotivated learners. Secondly, AR allows learning information to be presented in the 3D environment; in the appropriate place and time, enabling learners to easily access the contextual information and avoid the excessive use of their cognitive resources. Since humans have a limited working memory, the way cognitive resources are focused and used in learning an confidence task performance. The results of this study showed that the knowledge comprehension and effective use of information to complete a task. All the previously existing studies have been focused solely on using AR in presenting learning contents and assessing its effect on knowledge acquisition and retention. Nevertheless, there is currently no study that examines how AR can improve knowledge reusability, that is the ability to use learned information to solve new problems. Furthermore, the methods include values have explored the positive effect of AR feedback to users while limiting, little is known as too low it is associated with knowledge reusability.\n",
       "\n",
       "Knowledge reusability is an important aspect of learnability since the acquired knowledge structure is a major role in the use of the knowledge reusability in similar problems. Assessing the level of knowledge reusability can give insights into the effectiveness of learnability obtained from a learning media/approach to novel situations. One of the determining factors for human resources management to improve organization productivity lies in its ability to induce learning and exploit the know-how information for various situations. Developing a new training approach that encourages learning and enables knowledge reuse can take a company to achieve a new level of productivity. Therefore, this paper sought to examine two research questions that have not been addressed in the literature: (1) how AR can be designed to\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "promote efficient knowledge comprehension and reusability and (2) how does knowledge reusability relate to improved learnability.\n",
       "\n",
       "### 3. Methods\n",
       "\n",
       "In the Cognitive theory of Multimedia Learning (CTML), knowledge reuse is facilitated when learners engage in meaningful learning. Meaningful learning involves the learner making sense of the presented information by integrating the received information with the existing knowledge to form a coherent representation of new knowledge. According to CTML, learners engage in three cognitive processes to explore the understanding of the knowledge and the knowledge selected material by building structural relations among the elements, and integrating the selected material with the relevant prior existing knowledge. Nevertheless, this does not mean that human minds can always operate through all these processes when presented by information. Augmented Reality as a technology that can overlay augmented information in the real world has been shown to promote enhanced learning achievement in the educational settings overall.\n",
       "\n",
       "In the study, the authors found that the new knowledge is an example. In the industrial setting, the augmented information that provides context to the real environment can ease the comprehension of the task and can reduce mental workload [12,. Table 1 outlines how AR can facilitate motivation.\n",
       "\n",
       "Existing studies using AR to support learning have been primarily focused on presenting information in a passive way where the user is presented with information that allows him to complete the task. This kind of approach puts the user as a rather passive information receiver and might not be effective to achieve knowledge reusability. In the attempt to achieve meaningful learning, this study shows how AR was developed to encourage thinking or sensemaking that allows user to build the mental model of the system.\n",
       "\n",
       "### 3.1. The design of enhanced AR-based information delivery\n",
       "\n",
       "Traditional AR system used in engineering training typically focused on presenting training materials to help users go through a task/a processes as clearly possible with minimum error. However, the information is often isolated to a specific sub-task or a process which may not be suitable for a complex system with highly interrelated components. Complex Engineering Assets (CEAs) constitute multiple layers of complexity (e.g. operational and task complexity) that are often challenge to the use of the system. In this study, the authors found to be enhanced in a way that facilitates learning to take place. To be models its way during the complexity and developing a mental model of the system, one of the approaches could be to increase the transparency and the observability of the system behavior and functionality. This can be achieved by showing the information that the user is expected to operate and foresee. Providing such information can increase user awareness of the system, which can help users in combining newly perceived information with the user's existing knowledge to form an\n",
       "\n",
       "**Table 1**\n",
       "How AR can facilitate meaningful learning.\n",
       "\n",
       "| Cognitive process | How AR can facilitate |\n",
       "|---|---|\n",
       "| Selecting | - Minimizing extraneous information by overlaying only relevant information in the real environment (i.e. considering contextual relevance including users, task, equipment, workplace, etc. [32, ] |\n",
       "|  | - Displaying additional information to user based on on-demand request |\n",
       "| Organizing | - Showing a step-by-step information to complete a task. |\n",
       "| Integrating | - Combine the presented information dynamically in real-time |\n",
       "|  | - Displaying supplementing multimodal information |\n",
       "|  | - Adding contextual information to enhance task awareness |\n",
       "\n",
       "updated picture of changing situations. Another thing that can reduce the potential for learning in a complex system is the excessive use of working memory resources due to the large amount of information to be processed. Since human information processing system consists of multiple channels in which each channel has a limited capacity to process information, multimodal information delivery has been suggested to facilitate information perception and understanding. Based on the theoretical constructs, three design principles were adopted to develop a new framework-based information delivery system:\n",
       "1. Multimodal information: combine visual information with vocal explanation in the feature space.\n",
       "2. Contextual information: provide necessary information to prevent extraneous information processing.\n",
       "3. Projection of the given states: shows common mistakes and consequences for the projection of the given states.\n",
       "\n",
       "### 3.2. Development of augmented reality system\n",
       "\n",
       "The AR system developed in this study was targeted on a headmounted display Microsoft Hololens 2. It allows users to see their surrounding environment through transparent glasses while the holographic contents are projected onto these glasses and superimposed on the real world. It is also equipped with multiple sensors such as depth and camera. The object detection of the object is a single source of the visual sources acceleration and rotation of the device in three dimensions, and four visible cameras that are used in conjunction to accurately track user's hands in real-time. AR application was developed using Unity engine which supports multiple platforms for AR development. For AR library, Vuforia engine was used for vision-based tracking. Vuforia has an augmented/mixed reality SDK that can be imported into Unity as a plugin. The user interface (UI) was developed using the Mixed Reality System (VU) and a Deep Learning Network (VU) and a Deep Learning Network (VU). Inels2. The MRTK includes a range of features and tools that can help developers with various aspects of mixed reality development, such as spatial mapping, hand tracking, gesture recognition, voice commands, and data processing.\n",
       "\n",
       "To enable AR for our experiment, an image that the Vuforia Engine can identify, and track is used. This kind of image can be referred to as \"an image Target\". By comparing extracted natural characteristics from the camera picture against a predefined target resource database, the Vuforia Engine can identify and track the image, and can show augmented content on top of it. This solution was chosen as targeting different components was difficult without their associated 3D models which needs to be created for that purpose. Moreover, small objects such as wires are difficult to track due to their size. System architecture of the AR system is presented in Fig. 1.\n",
       "\n",
       "### 3.3. Experimental validation\n",
       "\n",
       "### 3.3.1. Experimental conditions\n",
       "\n",
       "To simulate an industrial scenario that is complex enough to test different methods of learning, an electronic wiring task was defined. This scenario was motivated by several reasons: it can be easily repeated, and the complexity of an electronic task is quite high if the user has no previous knowledge about this field. Furthermore, as an electronic wiring task must be done precisely and consist of multiple variations to achieve the objective, the selected task is suitable for the evaluation of retention and transfer test. The task contained five following subtasks:\n",
       "- Wire a power supply.\n",
       "- Connect the power supply to a voltage regulator board.\n",
       "- Connect the voltage regulator board to a terminal block.\n",
       "- Connect a sensor to the terminal block.\n",
       "- Connect an Arduino board to the installation through a breadboard.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "\\begin{abstract}\n",
       "Further, the task was tested under three different learning interfaces: (1) a paper-based document that serves as a control group against AR systems, (2) a traditional AR-based training system, and (3) an enhanced AR-based training system that was developed by applying design principles that encourage meaningful learning.\n",
       "\\end{abstract}\n",
       "3.3.1.1. The paper-based document. The paper-based document (see: 10.17862/cranfield.rd.240793971) contains all information about the electronic system and its components. It also consists of a step-by-step information in the form of textual instruction and pictures to complete the electronic system.\n",
       "\n",
       "3.3.1.2. The traditional AR-based training system. This training system replicated most of AR systems used for learning the assembly tasks which include textual information, graphical objects (e.g., arrow) for pointing certain objects, and videos. Users were initially presented with an overview of the electronic system and its all components using toillops and graphical arrows (See Fig. 2(a)). To acquire skills in wiring the system, assembly instructions were presented step by step on top of the workspace in the form of texts as well as videos which describe the task and how to do it (See Fig. 2(b)). The users can pause and play the video as much as they like and proceed to the next step.\n",
       "\n",
       "3.3.1.3. The enhanced AR-based training system. The enhanced ARbased training system was similar to the traditional one regarding the contents. However, it had voice cues (multimodal information) that gives additional context and information to the user. For example, during the unscrewing part of the power supply, the voice cue gives additional information on how to perform the task: \"To loosen the screws, do two or three counterclockwise turns with the screwdriver on both screws\". It also included common mistakes and consequences panel after each step to enable the user to grasp the significance of their actions and increase the understanding of the system behavior (projection of the given states and their consequences) as shown in Fig. 3.\n",
       "\n",
       "## 3.3.2. Experimental procedure\n",
       "\n",
       "To examine how third methods of learning affect users in understanding the task and unraveling the acquired knowledge to a different situation, this study assessed independent groups of users (between subjects and their subjects, assigned to each learning method to learn the subjects. Each participant was asked to fill out a demographic questionnaire (see: 10.17862/cranfield.rd.24079371) which includes electronic and augmented reality background questionnaire to check whether they had done some tasks related electronics system and if they were familiar with the use of AR prior to the experiment. After that, each other was used to identify the data and the data generated by the studied wiring task to test their initial knowledge about the system.\n",
       "\n",
       "The test consisted of questions about the identification of different components they would use during the task and about general knowledge given during the experiment. Following this, a total of thirteen participants were involved in this experiment where four people were assigned in traditional AR group, five people in the enhanced AR group, and four people in the paper-based document group. They were all available for the first two of the three participants. The first two were three. Their knowledge about electronics was balanced across the groups (See Section 4.1). The test was graded over 11 questions and was also given after they finished the task to measure the amount of information they learned after going through a training (short term retention test). One week later, each participant was assessed again with the same questionnaire to test their capability to remember what they learned (long term retention test). The duration of a week has been used in many studies for memory retention test \\([11,26,\\). Furthermore, participants were not told that the questionnaire would be the same after one week. Existing studies that measured task learnability typically focused on\n",
       "\n",
       "(a)\n",
       "\n",
       "(b)\n",
       "\n",
       "### Fig. 2. Traditional AR-based training system: (a) the overview of the electronic wiring system, (b) assembly instructions in the textual form and video.\n",
       "\n",
       "| Component        | Location            | Connection Details             |\n",
       "|------------------|---------------------|--------------------------------|\n",
       "| Power Supply     | Back of the unit    | V2 and G2 terminals           |\n",
       "| Breadboard       | Central area        | Connected to various components |\n",
       "| Arduino          | Central area        | Connected to various components |\n",
       "| Terminal Block   | Near the power supply| Possibly connects to the Arduino |\n",
       "\n",
       "### System Architecture of AR System\n",
       "\n",
       "| Component        | Description                               |\n",
       "|------------------|-------------------------------------------|\n",
       "| Unity            | The game engine used for development.       |\n",
       "| Visual Studio    | The IDE used for app build.               |\n",
       "| MRTK Mixed Reality Toolkit | A toolkit for building mixed reality apps. |\n",
       "| Vuforia Extension | A plugin for image recognition.           |\n",
       "| Vuforia          | Platform for image tracking and AR.       |\n",
       "| Database         | Stores and retrieves image data.           |\n",
       "| Microsoft HoloLens 2 | The Augmented Reality device.             |\n",
       "| Final App        | The complete augmented reality application. |\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "Testing declarative knowledge of a task through questionnaires or procedural knowledge through executing the task without assistance. In addition, objective assessments measuring time completion and the number of mistakes were also administered to measure how well they understand the learning contents. Unlike the previous studies, in this study participants were also asked to wire a second sensor to a terminal board without any guidance. To complete this task successfully, the participant must have the right understanding of the electronic system to identify the correct connection to the power source. Since there was no existing connection between them, they had to create a new procedure, it was used to assess knowledge resubility.\n",
       "\n",
       "## 3.3.3. Data analysis\n",
       "\n",
       "To analyze the effect of different learning methods to learnability, this study examined the score of each question in the pre-test to test the initial knowledge across different groups. The same analysis was also carried out in the post-tests for short- and long-term retention tests. The score for each question was normalized with respect to the number of questions, and the number of questions was calculated. The results of the results of all significantly significant differences among the means of the groups. It helps identify if there are significant differences among the groups and provides insights into which groups may differ from each other. Additionally, one-way repeated measure ANOVA was run to examine if there were statistically significant difference among the means of test score for each question. The results of the results of the study were similar to the number of questions, and to assess the effect on the task performance such as completion time, number of mistakes, and knowledge resubility. Finally, Point-Biserial and Pearson's correlation were run to examine the relation between knowledge retention and knowledge resubility as well as short- and long-term retention respectively. Statistical analysis was run by SPSS v 29 with statistical significance was determined when p < 0.05.\n",
       "\n",
       "## 4. Results\n",
       "\n",
       "## 4.1. Participants' data\n",
       "\n",
       "Table 2 presents a snapshot of participant demographics, occupation, nationality, and assessment responses. It shows almost all participants had no experience in performing electronic-related and wiring task (QS and Q 6 ) and only one participant had done electronic task related. The were more participants who had used AR (Q7) but rarely (Q8) and mostly for educational purposes (Q9). Only two participants preferred self-learning than with instructor (Q10). Overall, the participants in this study were homogeneous in terms of age, occupation, and their knowledge of electronic-related task.\n",
       "\n",
       "**Fig. 2**\n",
       "Demographics.\n",
       "\\begin{tabular}{lll}\n",
       "\\hline Measure & Items & Preq. & Details \\\\\n",
       "\\hline Gender & Male & 6 & \\\\\n",
       "& Female & 7 & \\\\\n",
       "Age & \\(<25\\) & 12 & \\\\\n",
       "& \\(25-35\\) & 13 & \\\\\n",
       "Occupation & \\(1-1\\) & 1 & \\\\\n",
       "Nationality & Chinese & 8 & \\\\\n",
       "& Indian & 1 & \\\\\n",
       "& French & 2 & \\\\\n",
       "& South & 3 & \\\\\n",
       "& Dutch & 12 & Rarely \\\\\n",
       "Assessment & \\(1-1\\) & 12 & Education \\\\\n",
       "& 05 (Yes) & 12 & \\\\\n",
       "& Q6 (No) & 12 & \\\\\n",
       "& Q6 (Yes) & 1 & \\\\\n",
       "& Q7 (Yes) & 1 & \\\\\n",
       "& Q8 (No) & 9 & \\\\\n",
       "& Q8 (Yes) & 9 & \\\\\n",
       "& Q9 (Yes) & 4 & \\\\\n",
       "& Q10 (Instructor) & 11 & \\\\\n",
       "& Q10 (self-learned) & 2 & \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\n",
       "## 4.2. Learnability pre-test\n",
       "\n",
       "Table 2 shows the result of pre-test for three groups of participants to assess their knowledge in the electronic task. As can be seen, the percentage of right answers from three groups were in a range from 12.73 % to 15.91 % and there were no statistical significant differences between groups as determined by one-way ANOVA (F(2,30)=0.124, p=0.884) indicating that all participants in all groups were not familiar with the given electronic task. From this result, the baseline knowledge about electronic in all groups was balanced and the subsequent result in the post-test can be reliably compared as a certain extent participants acquire new knowledge after participating in the training.\n",
       "\n",
       "## 4.3. Learnability post-test (short-term retention)\n",
       "\n",
       "Table 3 shows the score of the post-test from three different groups using different modes of training for electronics training. The results indicated that AR-based approaches could enhance knowledge acquisition to over 20 % for traditional AR and almost 25 % for enhanced AR as compared to traditional paper-based approach. Nevertheless, one-way ANOVA determined that these differences were not statistically significantly different (F(2,30)=3.012, p=0.064).\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "Table 3\n",
       "Scores of pre-test for learnability questionnaire.\n",
       "\n",
       "| Question # | Correct answer                               | Traditional AR group (4 people) | Enhanced AR group (5 people) | Paper-based manual group (4 people) |\n",
       "| :-------- | :------------------------------------------- | :------------------------------- | :----------------------------- | :---------------------------------- |\n",
       "| 1: Power supply | 0                                           | 0                               | 2                               | 0                                   |\n",
       "| 2: Terminal block | 1                                           | 1                               | 2                               | 1                                   |\n",
       "| 3: Arduino board | 1                                           | 1                               | 2                               | 1                                   |\n",
       "| 4: Breadboard | 2                                           | 2                               | 1                               | 1                                   |\n",
       "| 5: Image regulator board | 0                                           | 0                               | 0                               | 1                                   |\n",
       "| 6: Sensor | 1                                           | 1                               | 0                               | 0                                   |\n",
       "| 7: Image regulator connection | 0                                           | 0                               | 1                               | 0                                   |\n",
       "| 8: Proximity sensor | 0                                           | 0                               | 1                               | 1                                   |\n",
       "| 9: Image regulator | 0                                           | 0                               | 0                               | 0                                   |\n",
       "| 9: Voltage regulator board terminal | 1                                           | 1                               | 0                               | 0                                   |\n",
       "| 10: writing and supply | 0                                           | 0                               | 0                               | 1                                   |\n",
       "| 10: output voltage answers | 34                                          | 34                               | 44                               | 25                                  |\n",
       "| 11: Wire color switching | 1                                           | 1                               | 0                               | 0                                   |\n",
       "| Total of correct answers | 7                                           | 7                               | 7                               | 6                                   |\n",
       "| Total of correct answers | 37                                          | 37                               | 48                               | 38                                  |\n",
       "| Percentage of right answers | 15.91 %                                     | 15.91 %                           | 12.73 %                          | 13.64 %                             |\n",
       "\n",
       "## 4.4. Learnability post-test (long-term retention)\n",
       "\n",
       "The result of the post-test after one week from the experiment across different groups was shown on the Table 4. While, the paper-based group seems to relatively retain the knowledge they learned after one week, there was a slight decrease observed in the total number of correct answers for traditional AR group whereas a small increment of the total of correct answer was observed for enhanced AR group. In this post-test\n",
       "\n",
       "Table 4\n",
       "Scores of post-test for learnability questionnaire (short-term retention).\n",
       "\n",
       "| Question # | Correct answer | Traditional AR group (4 people) | Enhanced AR group (5 people) | Paper-based manual group (4 people) |\n",
       "| :-------- | :------------ | :------------------------------- | :----------------------------- | :---------------------------------- |\n",
       "| 1: Power supply | 4             | 4                               | 0                               | 0                                   |\n",
       "| 2: Terminal block | 4             | 4                               | 5                               | 3                                   |\n",
       "| 3: Arduino board | 4             | 4                               | 5                               | 3                                   |\n",
       "| 4: Video regulator | 3             | 3                               | 4                               | 4                                   |\n",
       "| 5: Voltage regulator | 3             | 3                               | 4                               | 4                                   |\n",
       "| 6: board | 4             | 4                               | 4                               | 4                                   |\n",
       "| 7: Video regulator | 4             | 4                               | 5                               | 4                                   |\n",
       "| 8: 24-9 V | 4             | 4                               | 4                               | 2                                   |\n",
       "| 8: Performance | 4             | 4                               | 4                               | 2                                   |\n",
       "| 8: Proximity sensor wire | 1             | 1                               | 3                               | 1                                   |\n",
       "| 9: Wire colors | 1             | 1                               | 5                               | 3                                   |\n",
       "| 9: Voltage regulator | 2             | 2                               | 3                               | 1                                   |\n",
       "| 10: Power supply | 1             | 1                               | 3                               | 0                                   |\n",
       "| 10: output voltage answers | 34            | 34                               | 44                               | 25                                  |\n",
       "| 11: Wire color switching | 3             | 3                               | 3                               | 2                                   |\n",
       "| Total of correct answers | 34            | 34                               | 44                               | 25                                  |\n",
       "| Total of incorrect | 13            | 13                               | 7                               | 7                                   |\n",
       "| Percentage of right answers | 77.27 %        | 77.27 %                           | 80.00 %                          | 56.82 %                             |\n",
       "\n",
       "## 4.5. Short- and long-term retention comparison\n",
       "\n",
       "Further analysis was carried out to assess the differences in the knowledge retention between short- and long-term test across the groups relative to the baseline (i.e. learnability pre-test). As indicated on the Table 5, each training methods led to statistically significant improvement of correct answers compared to pre-test as determined by one-way repeated measure ANOVA whereas there were no statistically significant differences in knowledge retention test between long- and short-term across all groups.\n",
       "\n",
       "## 4.6. Task performance\n",
       "\n",
       "The task performance in terms of completion time and the number of errors were compared across three different experimental settings. Fig. 4 shows that the traditional AR led to the shortest mean completion time with 30 s and more than 70 s compared to the enhanced AR and paperbased document respectively. It also shows that the traditional AR had the highest variability of task completion whereas the lowest variability was observed in the paper-based group. One-way ANOVA determined there were no statistically significant differences among all group in terms of mean task completion time (F(2,10)=0.176, p=0.841) and mean number of overall errors (F(2,10)=0.497, p=0.623).\n",
       "\n",
       "## 4.7. Knowledge reusability test\n",
       "\n",
       "Fig. 5 presents the percentage of participants who could reuse the knowledge acquired and apply it to different situation. Almost all participants ( 4 of 3) in the enhanced AR group could successfully apply the knowledge correctly. However, there were only 50 % (two out of four) and 25 % (one out of four) in traditional AR and paper-based group respectively who could reuse the knowledge successfully. One way ANOVA determined that the differences were not statistically significant\n",
       "\n",
       "No figure was found on this page.\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "24:00\n",
       "22:00\n",
       "20:00\n",
       "18:00\n",
       "16:00\n",
       "14:00\n",
       "12:00\n",
       "10:00\n",
       "7:00\n",
       "4:00\n",
       "2:00\n",
       "1:00\n",
       "0\n",
       "1\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "1\n",
       "0\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "Table 7\n",
       "Relation between knowledge retention and knowledge reusability.\n",
       "\n",
       "|                     | Knowledge reusability | Short-term retention | Long-term retention |\n",
       "|---------------------|-----------------------|----------------------|---------------------|\n",
       "| Knowledge reusability | 1                     | 0.672*               | 0.466               |\n",
       "| Knowledge retention   | 1                     | 0.717* *             |                     |\n",
       "| Long-term retention   | 1                     |                      | 1                   |\n",
       "\n",
       "({ }^{*} p < 0.05)\n",
       "\n",
       "The number of participants in the intervention group was the information to be learned whereas extraneous processing involves extrinsic load that does not serve the instruction goal and does not promote transfer of learning. In line with this, several studies [4,  also argued that AR learning could save users from some cognitive processing necessary to search and select the essential information to be learned which could provide the reason why AR could lead to higher knowledge acquisition score than traditional training method. When using traditional approach like paper-based manual, users need to scan all information before deciding which section that is essential and relevant to the completion of the task. This imposes more workload to be used to obtain the information to be learned from searching task so that they can focus on interpreting the presented information. Besides, it is also important to note that embedding added contextual information in the enhanced AR training environment such as counsel use and projection of condition-consequence states may increase the learning time compared to typical AR that presents unimodal and decontextualization information. This is to be expected since users are not able to be trained to learn the information to be able to acquire more knowledge because the additional information enhances knowledge formulation and facilitates better integration with the users' prior knowledge. One study has also observed similar findings whereby enabling AR system to identify user's mistake and suggest correction to users while training can improve learning test score as opposed to the user's ability to learn the information to be able to support the person on long term retention and knowledge reusability, little is known whether such feedback is effective to achieve meaningful learning.\n",
       "\n",
       "In terms of long-term retention test, there were no statistically significant differences between short- and long-term retention test for all groups which might suggest that all training systems tested in this study seemed to work effectively in helping users to remember what they had to be able to be able to support the person on long term retention test. However, they should be knowledge (short-term retention) were associated with having the ability to retain the acquired knowledge we seek after (long-term retention). However, when inter-group training systems were compared, the enhanced AR training led to better knowledge retention score than the paper-based group as indicated by a statistically significant difference between the two groups. In addition, the proposed method was better when the paper-based and the enhanced AR group a week after. Similar findings were also observed when comparing AR learning method with a video and a paper-based presentation in which after seven days, the amount of information loss was significant for traditional training but not for AR. On the contrary, one study found that AR training led to paper-based development (2020). While other studies have been reported in the paper-based document (2020), who the difficult to pinpoint the underlying factors responsible for the discrepancies observed across studies as memory retention can be influenced by many factors (e.g. individual differences, content and task requirement, etc.), helping users building a strong association between the task and information seems to play an important role for learning to take places.\n",
       "\n",
       "In this study, users in the enhanced AR group performed better in knowledge acquisition and long-term retention than users in paperbased group could be influenced by the sensemaking task involved in the enhanced AR group. The transparency of the system behavior was increased through the projection of given states and their consequences which encourage users to think and make sense of presented information. Think more deeply of relevant information leaves more memory traces which enables them to retain the information. In the CTML, the authors have been working on the research and development of the knowledge, the information learned is moved from working memory to long term memory for future information retrieval. This might explain why traditional AR systems in which users were conditioned as solely information receiver and implementer might not be able to retain the information effectively. Furthermore, users in AR groups seemed to more likely succeeding in applying the knowledge acquired to the user. The authors were also interested in developing the correlation between short-term retention and transfer test which suggests that users who scored high in knowledge acquisition test immediately after the training was related with being able to successfully reusibly transfer the same.\n",
       "\n",
       "Finally, it seems that applying human-centric design principles such as providing contextual information in multimodal form facilitates users in attending the relevant and essential information while increasing system transparency encourages thinking and sensemaking of the presented information. This had shown a positive impact in achieving meaningful learning whereby users were more able to recall the lesson learnt and reuse it in different settings without going through explicit information. The results of the research and development of the knowledge acquisition on human-centric approach rather than their capabilities is a crucial factor. To align with Industry 5.0 core value that emphasizes human and societal goal in technology intake, knowledge reusability plays a vital role in enabling employee's empowerment, promoting collaboration, and adaptability, as well as fostering long life learning. This paper presents a new approach in adopting AR technology that looks at aspects of the use of the software. The research and development of the knowledge Resource research is required to expand the integration of new technologies and people which are built to serve humans and fit the needs and diversity of industrial workers. This study is limited in terms of number of people who participated as well as the case for knowledge reusability tests. However, it has shown that applying human-centric design principles in the technology development can better accommodate human needs for training in developing their own skills and grow in their roles, which aligns with Industry 5.0's human-centric approach of valuing, empowering, and engaging the workforce.\n",
       "\n",
       "Section 6. Conclusion and further research\n",
       "\n",
       "In the face of the current industrial landscape, which is described as dynamic and fast-paced as it is constantly evolving due to advancements in technologies, industries are implementing various strategies to increase the productivity of their workforce. Nevertheless, the adoption of new technologies should not be focused to solve their bridge task performance but rather to promote the development of lifelong learning and training. In this study, the research and development of the knowledge acquisition study, we demonstrated the improvement of knowledge acquisition and reusability by applying human-centric design principles over traditional training which addresses two previously presented research questions. Firstly, regarding how AR can be designed to promote efficient knowledge comprehension and reusability, the results of this study showed that providing additional context in the form of voice cue to complement the information to the user. In this study, the research and development of the knowledge acquisition process and to attend to essential information. This could lead to increased knowledge comprehension which was indicated by a higher number of correct answers in the use case. In addition, improving system transparency to the users encourages sensemaking of presented information which may increase the success of knowledge transfer to a new situation. Secondly, this study found that knowledge reusability had a positive correlation with short-term knowledge retention test scores. This relation is consistent with the expectation that when the more\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "## Knowledge is acquired, the more capable one can adapt the knowledge to a new situation which leads to improved learnability.\n",
       "\n",
       "Further research may consider how different learning styles can improve the learning outcomes. Adopting Artificial Intelligence technology to learn about users' learning style and deliver personalized learning contents accordingly to assess its impact on improved learnability in terms of retention and transfer test will be the object of the future study.\n",
       "\n",
       "## CRediT authorship contribution statement\n",
       "\n",
       "Dedy Ariansyah: Software, Methodology, Validation, Investigation, Writing (original draft). Bens Lamparaan: Verification, Writing (review editing). Icedie Barbaro: Verification, Writing (review editing), John Ahmet Erkoyuncu: Conceptualization, Resources, Writing (review editing), Supervision, Funding.\n",
       "\n",
       "## Declaration of Competing Interest\n",
       "\n",
       "The authors declare that they have no known competing financial interests or personal relationships that could have appeared to influence the work reported in this paper.\n",
       "\n",
       "## Acknowledgments\n",
       "\n",
       "This work was funded by the EPSCR as part of the \"Digital Toolkit for Optimization of operators and technology in manufacturing partnerships\" project (DigITOP; https://digitop.ac.uk; EP/0R32718/1). For access to the data underlying this paper, please see the Cranfield University repository, CoRR, at DOI: 10.17862/cranl.24703791.\n",
       "\n",
       "## References\n",
       "\n",
       "1. Akcory M, AkcoryR. Advantages and challenges associated with augmented reality for education: a systematic review of the literature. *Educ Res Rev* 2017;2: 1-11. https://doi.org/10.1016/j.rudew.2017.11.002.\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('json_res/pipeline_1_2_res.jsonl') as f:\n",
    "    pipeline_1_2_res = json.load(f)\n",
    "\n",
    "# Display combined markdowns and images\n",
    "display(Markdown(get_combined_markdown(pipeline_1_2_res)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline 1 (Yolo + Universal.io + Gemma 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## PFU Business report - New customer's development and increasing the sale of product\n",
       "\n",
       "**[The main product and service at this season)**\n",
       "\n",
       "From the product headquarters\n",
       "\n",
       "In the image business, the new model turning on of the A3 high-speed, two sided color scanner that achieved a high-speed reading aimed at. wroom was established in United States, Europe, and Asia/Oceania.\n",
       "\n",
       "**@image business**\n",
       "\n",
       "1) Scanner class\n",
       "\n",
       "A3 high-speed, two sided color scanner \"fi-5900C\" that 100 high-n function to enable industry-leading was installed was announced in ScanSnap gotten popular because of an office and individual use. 2) DLM solution scanner\n",
       "\n",
       "| Year | Satisfaction Rating |\n",
       "|---|---|\n",
       "| 1998 | 80 |\n",
       "| 1999 | 30 |\n",
       "| 2000 | 60 |\n",
       "| 2001 | 55 |\n",
       "| 2002 | 30 |\n",
       "| 2003 | 100 |\n",
       "| 2004 | 15 |\n",
       "\n",
       "**[approach on business risk]**\n",
       "\n",
       "In-house activity\n",
       "\n",
       "The attestation intended for each office in Shinbashi, Kansai, and Tokai was acquired in environment ISO in February, 2006. In addition, it participates in the minus 6% that is a national movement of the global warming prevention, and \"Culbiz\" is done. The scandal of the enterprise has frequently generated is received, concern is sent to the system mainte- nance including the observance of the law in recent years.\n",
       "\n",
       "**@Enhancement of system of management**\n",
       "\n",
       "The committee that aimed at the decrease of a variety of business risks in an individual business talk was newly established. Moreover, the recognition of \"Privacy mark\" is received to manage customer and employee's individual information appropriately in 2001, and the activity based on the protection of individual information policy is continued. It is .bAsia/Oceania in globalln addition, our technology, commodity power, and correspondence power were evaluating acquired.\n",
       "\n",
       "| Category        | Percentage |\n",
       "|-----------------|------------|\n",
       "| Very Good       | 47%        |\n",
       "| Good            | 26%        |\n",
       "| Usually         | 20%        |\n",
       "| Bad             | 7%         |\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "# CIRP Journal of Manufacturing Science and Technology 48 (2024) 19-27\n",
       "\n",
       "## Contents lists available at ScienceDirect\n",
       "\n",
       "### CIRP Journal of Manufacturing Science and Technology\n",
       "\n",
       "[Journal homepage: www.elsevier.com/locate/cirpj](www.elsevier.com/locate/cirpj)\n",
       "\n",
       "---\n",
       "\n",
       "## Augmented reality training for improved learnability\n",
       "\n",
       "**Dedy Ariansyah\\*, Bens Pardamean\\*, Eddine Barbaro, John Ahmet Erkoyuncu\\***\n",
       "\n",
       "\\* Bioinformatics & Data Science Research Center, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "\n",
       ">  Computer Science Department, BINUS Graduate Program - Master of Computer Science, Bina Nusantara University, Jakarta 11480, Indonesia\n",
       "\n",
       "© School of Aerospace, Transport and Manufacturing, Cranfield, Bedfordshire MK43 0AL, UK\n",
       "\n",
       "### ARTICLE INFO\n",
       "\n",
       "**ABSTRACT**\n",
       "\n",
       "**Keywords:** Augmented Reality, Learnability, Training, Industry 4.0, Industry 5.0\n",
       "\n",
       "In the current era of Industry 4.0, many new technologies offer manufacturing industries to achieve high productivity. Augmented Reality (AR) is one of the emerging technologies that has been adopted in industries to aid users in acquiring complex skills and carrying out many complicated tasks such product assembly and maintenance. Nevertheless, most AR applications have been developed without clear understanding of how such technology can facilitate improved learnability in terms of knowledge reusability. This paper proposed an enhanced AR-based training system that provides multimodal information with a contextualized information to improve task comprehension and knowledge reusability compared with traditional AR that presents unimodal and decontextualized information. An empirical test was carried out to assess the task performance and the task learnability aspects of this enhanced AR compared to the traditional AR and the paper-based document. The experiment consisted of a training phase where participants carried out an electrical connection task of a sensor followed by a knowledge reuse phase where participants had to wire a second sensor using their previous training. A pre-test quiz was given before the experiment followed by the post-tests phase after the training. Post-tests consist of one post-test given directly after the experiment (short-term retention test) and a second post-test quiz given one week later (long-term retention test) to measure information retention. The results indicated that AR-based approaches could enhance knowledge acquisition by around 18 % for traditional AR and almost 25 % for enhanced AR as compared to paper-based approach. While all training systems achieved relatively equivalent well for short-term retention test, trainees who used the enhanced AR training systems statistically outperformed those in the paper-based group for long term retention test. Furthermore, there was a positive correlation between the score of short-term retention test and the score in the knowledge reusability which was also shown by the higher scores in knowledge reusability for the enhanced AR training system compared to the other two approaches. These findings are discussed in relation to the Industry 5.0's human centric core value.\n",
       "\n",
       "### 1. Introduction\n",
       "\n",
       "The adoption of Industry 4.0 technologies enables new capabilities to produce and to deliver product faster with a better quality, and more cost efficient. However, this industrial revolution is leading to an increased complexity of manufacturing systems and an increasingly rapid renewal of these systems. Consequently, upskilling employees’ competencies to handle and maintain the complex engineering assets (CEAs) is indispensable. In recent years, finding a skilled worker has become a difficult task. The reason is that there is a talent shortage nowadays. Indeed, in 2018, 45 % of employers said that they could not find the necessary skills among candidates [17]. Furthermore, a new issue will arise from adapting to the changing job dynamics brought about by digitalization [27]. Despite the increased interconnectedness and availability of information globally, the progress of digitalization has not been uniformed across countries or even within industries within the same country [14]. To face this challenge and meet with the adoption of Industry 4.0, employers need to find a new way to ensure their workforces are sufficiently equipped to work with CEAs. In the aviation sector, research examined that traditional training such as in-class training and paper-based manual are not reliable means for teaching job tasks and the skills for visual inspection for the future trend in aviation [11,29]. Visual inspection requires Aircraft Maintenance Technician (AMT) to identify certain characteristics of all types of faults and make decision to troubleshoot various systems from one airplane to another. Due to highly complexity and interrelated components in the\n",
       "\n",
       "\\* Corresponding author.\n",
       "\n",
       "E-mail address: j.a.erkoyuncu@cranfield.ac.uk (J.A. Erkoyuncu).\n",
       "\n",
       "[https://doi.org/10.1016/j.cirpj.2023.11.003](https://doi.org/10.1016/j.cirpj.2023.11.003)\n",
       "\n",
       "Received 29 March 2023; Received in revised form 4 September 2023; Accepted 2 November 2023 Available online 6 December 2023\n",
       "\n",
       "1755-5817/© 2024 The Authors. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "Image Name: Figure 4 & 5 - Task Performance Comparison\n",
       "\n",
       "This image presents a comparison of task performance metrics across three different training methods: Traditional AR, Enhanced AR, and Paper-based. It includes data on task completion time, number of mistakes, and knowledge retention.\n",
       "\n",
       "Here’s the structured data in Markdown format:\n",
       "\n",
       "**Table 1: Task Completion Time**\n",
       "\n",
       "| Method           | Mean Task Completion Time (min) |\n",
       "|------------------|---------------------------------|\n",
       "| Traditional AR   | 19.26                           |\n",
       "| Enhanced AR      | 19.57                           |\n",
       "| Paper-based      | 20.47                           |\n",
       "\n",
       "**Table 2: Number of Mistakes**\n",
       "\n",
       "| Method          | Mean Number of Mistakes | Standard Deviation |\n",
       "|-----------------|-------------------------|--------------------|\n",
       "| Traditional AR  | 1.0                     | 0.6                |\n",
       "| Enhanced AR     | 0.6                     | 0.6                |\n",
       "| Paper-based     | 1.75                    | 0.6                |\n",
       "\n",
       "**Table 3: Knowledge Retention**\n",
       "\n",
       "|  | Traditional AR group (4 People) | Enhanced AR group (5 People) | Paper-based group (4 People) |\n",
       "|---|---|---|---|\n",
       "| ST | 61.37 % | 67.27 % | 43.18 % |\n",
       "| LT | 54.54 % | 45.45 % | 40.91 % |\n",
       "| LT - ST | -6.83 % | 7.27 % | -2.27 % |\n",
       "\n",
       "*ST = Short-term, LT = Long-term*\n",
       "\n",
       "**Table 4: Success Rate**\n",
       "\n",
       "| Method          | Success Rate (%) |\n",
       "|-----------------|------------------|\n",
       "| Traditional AR  | 50               |\n",
       "| Enhanced AR     | 80               |\n",
       "| Paper-based     | 25               |\n",
       "\n",
       "\n",
       "---\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open('json_res/pipeline_2_res.jsonl') as f:\n",
    "    pipeline_2_res = json.load(f)\n",
    "\n",
    "# Display combined markdowns and images\n",
    "display(Markdown(get_combined_markdown(pipeline_2_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
