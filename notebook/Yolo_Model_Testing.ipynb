{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\Vidavox\\Universal Doc Parsing\\.venv\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\Vidavox\\Universal Doc Parsing\\.venv\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# !pip install -q pdf2image ultralytics supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/AR for improved learnability.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder structure setup\n",
    "import os\n",
    "\n",
    "BASE_DIR = \"\"\n",
    "DIRECTORIES = [\"img/pages\", \"img/annotated\", \"img/figures\"]\n",
    "for dir in DIRECTORIES:\n",
    "    os.makedirs(os.path.join(BASE_DIR, dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle image size\n",
    "def resize_img(image):\n",
    "    # change the image to RGB mode\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    # change image width to 1440 and maintain the aspect ratio\n",
    "    basewidth = 1440\n",
    "    wpercent = (basewidth / float(image.size[0]))\n",
    "\n",
    "    # change the height of the image\n",
    "    hsize = int((float(image.size[1]) * float(wpercent)))\n",
    "\n",
    "    # resize the image\n",
    "    image = image.resize((basewidth, hsize))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img/pages/page_0.png',\n",
       " 'img/pages/page_1.png',\n",
       " 'img/pages/page_2.png',\n",
       " 'img/pages/page_3.png',\n",
       " 'img/pages/page_4.png',\n",
       " 'img/pages/page_5.png',\n",
       " 'img/pages/page_6.png',\n",
       " 'img/pages/page_7.png',\n",
       " 'img/pages/page_8.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "img_path = \"img\"\n",
    "page_path = f\"{img_path}/pages\"\n",
    "\n",
    "\n",
    "# Function to split PDF into images\n",
    "def split_pdf(pdf_path):\n",
    "    pages = []\n",
    "    page_images = convert_from_path(pdf_path, 96)\n",
    "    for i, page in enumerate(page_images):\n",
    "        # Save Image\n",
    "        # page = resize_img(page)\n",
    "        path = f\"{page_path}/page_{i}.png\"\n",
    "        page.save(path, \"PNG\")\n",
    "        pages.append(path)\n",
    "\n",
    "    return pages\n",
    "\n",
    "pages = split_pdf(PDF_PATH)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "fig_path = f\"{img_path}/figures\"\n",
    "\n",
    "# detect text, table, and figure using YOLOv11 model\n",
    "def detect_text(pages, model=YOLO(\"../model/best.pt\")):\n",
    "    detected_images = []\n",
    "    annotated_images =[]\n",
    "    figures = []\n",
    "    for j, page in enumerate(pages):\n",
    "        image = cv2.imread(page)\n",
    "        results = model(image, conf=0.35, iou=0.7)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        detected_images.append(detections)\n",
    "\n",
    "        # save annotated image\n",
    "        annotated_image = image.copy()\n",
    "        annotated_image = sv.BoxAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        annotated_image = sv.LabelAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        output_image_path = f\"img/annotated/page_{j+1}_annotated.png\"\n",
    "        cv2.imwrite(output_image_path, annotated_image)\n",
    "        annotated_images.append(output_image_path)\n",
    "\n",
    "        # save figure class_name\n",
    "        # for i, class_name in enumerate(detections.data['class_name']):\n",
    "\n",
    "        #     if class_name == 'figure':\n",
    "        #         x1, y1, x2, y2 = map(int, detections.xyxy[i])\n",
    "        #         section = image[y1:y2, x1:x2]\n",
    "        #         output_filename = f\"{fig_path}/page_{j}_figure_{i}.png\"\n",
    "        #         cv2.imwrite(output_filename, section)\n",
    "        #         # save metadata\n",
    "        #         metadata = {\n",
    "        #             \"file_path\": output_filename,\n",
    "        #             \"bbox\": [x1, y1, x2, y2],\n",
    "        #             \"name\": \"\",\n",
    "        #             \"type\": \"\",\n",
    "        #             \"data\": \"\",\n",
    "        #             \"description\": \"\"\n",
    "        #         }\n",
    "        #         page[\"figures\"].append(metadata)\n",
    "        #         figures.append(output_filename)\n",
    "\n",
    "    return detected_images, annotated_images, figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 header, 1 image, 1 logo, 4 texts, 1 title, 1524.2ms\n",
      "Speed: 92.6ms preprocess, 1524.2ms inference, 134.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 text, 139.6ms\n",
      "Speed: 12.4ms preprocess, 139.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 table, 1 text, 120.4ms\n",
      "Speed: 2.3ms preprocess, 120.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 header, 1 image, 2 logos, 1 text, 127.4ms\n",
      "Speed: 2.6ms preprocess, 127.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 graph, 1 table, 2 texts, 136.7ms\n",
      "Speed: 2.7ms preprocess, 136.7ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 3 tables, 2 texts, 1 title, 120.3ms\n",
      "Speed: 2.3ms preprocess, 120.3ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 3 graphs, 1 table, 2 texts, 133.1ms\n",
      "Speed: 2.6ms preprocess, 133.1ms inference, 19.7ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 table, 4 texts, 134.7ms\n",
      "Speed: 2.2ms preprocess, 134.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 1 text, 131.5ms\n",
      "Speed: 2.5ms preprocess, 131.5ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     667.91,      193.03,      708.32,      239.29],\n",
       "       [     46.813,      678.18,      745.85,      866.14],\n",
       "       [     265.37,      350.59,       746.8,       647.2],\n",
       "       [     235.46,      44.158,      558.88,      60.754],\n",
       "       [     49.552,      217.73,      480.59,      243.81],\n",
       "       [     45.289,      73.279,      132.54,      179.03],\n",
       "       [     156.96,      78.929,      643.62,       174.1],\n",
       "       [     46.033,      279.99,         573,      318.72]], dtype=float32), mask=None, confidence=array([    0.83712,     0.61782,     0.56934,     0.53512,     0.52899,     0.45109,     0.41553,     0.37539], dtype=float32), class_id=array([4, 7, 7, 2, 8, 3, 7, 7]), tracker_id=None, data={'class_name': array(['logo', 'text', 'text', 'header', 'title', 'image', 'text', 'text'], dtype='<U6')}, metadata={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_images, annotated_images, figures = detect_text(pages)\n",
    "detected_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
