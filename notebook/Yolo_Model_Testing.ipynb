{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pdf2image ultralytics supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/dummy_scanned.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder structure setup\n",
    "import os\n",
    "\n",
    "# if any img directory remains, remove it\n",
    "if os.path.exists(\"img\"):\n",
    "    import shutil\n",
    "\n",
    "    shutil.rmtree(\"img\")\n",
    "    \n",
    "# create the img directory\n",
    "BASE_DIR = \"\"\n",
    "DIRECTORIES = [\"img/pages\", \"img/annotated\", \"img/figures\"]\n",
    "for dir in DIRECTORIES:\n",
    "    os.makedirs(os.path.join(BASE_DIR, dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle image size\n",
    "def resize_img(image, width=1440):\n",
    "    # change the image to RGB mode\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    # change image width and maintain the aspect ratio\n",
    "    basewidth = width\n",
    "    wpercent = (basewidth / float(image.size[0]))\n",
    "\n",
    "    # change the height of the image\n",
    "    hsize = int((float(image.size[1]) * float(wpercent)))\n",
    "\n",
    "    # resize the image\n",
    "    image = image.resize((basewidth, hsize))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img/pages/page_0.png',\n",
       " 'img/pages/page_1.png',\n",
       " 'img/pages/page_2.png',\n",
       " 'img/pages/page_3.png',\n",
       " 'img/pages/page_4.png',\n",
       " 'img/pages/page_5.png',\n",
       " 'img/pages/page_6.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "img_path = \"img\"\n",
    "page_path = f\"{img_path}/pages\"\n",
    "\n",
    "\n",
    "# Function to split PDF into images\n",
    "def split_pdf(pdf_path):\n",
    "    pages = []\n",
    "    page_images = convert_from_path(pdf_path, 400)\n",
    "    for i, page in enumerate(page_images):\n",
    "        page = resize_img(image=page, width=1440)\n",
    "        # grayscale the image\n",
    "        # page = page.convert(\"L\")\n",
    "        # save the image\n",
    "        path = f\"{page_path}/page_{i}.png\"\n",
    "        page.save(path, \"PNG\")\n",
    "        pages.append(path)\n",
    "\n",
    "    return pages\n",
    "\n",
    "pages = split_pdf(PDF_PATH)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "fig_path = f\"{img_path}/figures\"\n",
    "\n",
    "# detect text, table, and figure using YOLOv11 model\n",
    "def detect_text(pages, model=YOLO(\"../model/new_last.pt\")):\n",
    "    detected_images = []\n",
    "    annotated_images =[]\n",
    "    figures = []\n",
    "    for j, page in enumerate(pages):\n",
    "        image = cv2.imread(page)\n",
    "        results = model(image, conf=0.35, iou=0.7)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        detected_images.append(detections)\n",
    "\n",
    "        # save annotated image\n",
    "        annotated_image = image.copy()\n",
    "        annotated_image = sv.BoxAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        annotated_image = sv.LabelAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        output_image_path = f\"img/annotated/page_{j+1}_annotated.png\"\n",
    "        cv2.imwrite(output_image_path, annotated_image)\n",
    "        annotated_images.append(output_image_path)\n",
    "\n",
    "    return detected_images, annotated_images, figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 footer, 2 graphs, 1 logo, 2 texts, 1 title, 185.4ms\n",
      "Speed: 5.5ms preprocess, 185.4ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 header, 3 logos, 4 texts, 182.8ms\n",
      "Speed: 3.7ms preprocess, 182.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 3 graphs, 1 table, 2 texts, 152.5ms\n",
      "Speed: 2.5ms preprocess, 152.5ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 footer, 2 images, 2 logos, 1 text, 157.9ms\n",
      "Speed: 3.2ms preprocess, 157.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 footer, 3 logos, 3 texts, 1 title, 204.3ms\n",
      "Speed: 2.9ms preprocess, 204.3ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 footer, 1 table, 199.8ms\n",
      "Speed: 4.5ms preprocess, 199.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 480x640 2 graphs, 2 texts, 2 titles, 164.5ms\n",
      "Speed: 3.0ms preprocess, 164.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     67.727,       328.6,      1239.3,      437.59],\n",
       "       [     124.57,       132.9,      1207.4,      305.88],\n",
       "       [     870.02,      1468.8,      1367.4,        1889],\n",
       "       [     695.63,      1936.5,      731.59,      1978.4],\n",
       "       [     913.09,      602.69,      1352.6,      1015.7],\n",
       "       [     1260.4,           0,        1383,      82.137],\n",
       "       [     54.716,      1265.9,      1382.7,        1795]], dtype=float32), mask=None, confidence=array([    0.77915,     0.74794,     0.47732,      0.4393,      0.4086,     0.38949,     0.36391], dtype=float32), class_id=array([7, 8, 1, 0, 1, 4, 7]), tracker_id=None, data={'class_name': array(['text', 'title', 'graph', 'footer', 'graph', 'logo', 'text'], dtype='<U6')}, metadata={})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_images, annotated_images, figures = detect_text(pages)\n",
    "detected_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
