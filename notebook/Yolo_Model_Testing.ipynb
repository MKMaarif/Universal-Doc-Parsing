{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q pdf2image ultralytics supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/dummy_scanned.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder structure setup\n",
    "import os\n",
    "\n",
    "# if any img directory remains, remove it\n",
    "if os.path.exists(\"img\"):\n",
    "    import shutil\n",
    "\n",
    "    shutil.rmtree(\"img\")\n",
    "    \n",
    "# create the img directory\n",
    "BASE_DIR = \"\"\n",
    "DIRECTORIES = [\"img/pages\", \"img/annotated\", \"img/figures\"]\n",
    "for dir in DIRECTORIES:\n",
    "    os.makedirs(os.path.join(BASE_DIR, dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle image size\n",
    "def resize_img(image, width=1440):\n",
    "    # change the image to RGB mode\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "    # change image width and maintain the aspect ratio\n",
    "    basewidth = width\n",
    "    wpercent = (basewidth / float(image.size[0]))\n",
    "\n",
    "    # change the height of the image\n",
    "    hsize = int((float(image.size[1]) * float(wpercent)))\n",
    "\n",
    "    # resize the image\n",
    "    image = image.resize((basewidth, hsize))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img/pages/page_0.png',\n",
       " 'img/pages/page_1.png',\n",
       " 'img/pages/page_2.png',\n",
       " 'img/pages/page_3.png',\n",
       " 'img/pages/page_4.png',\n",
       " 'img/pages/page_5.png',\n",
       " 'img/pages/page_6.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "img_path = \"img\"\n",
    "page_path = f\"{img_path}/pages\"\n",
    "\n",
    "\n",
    "# Function to split PDF into images\n",
    "def split_pdf(pdf_path):\n",
    "    pages = []\n",
    "    page_images = convert_from_path(pdf_path, 400)\n",
    "    for i, page in enumerate(page_images):\n",
    "        page = resize_img(image=page, width=1440)\n",
    "        # grayscale the image\n",
    "        # page = page.convert(\"L\")\n",
    "        # save the image\n",
    "        path = f\"{page_path}/page_{i}.png\"\n",
    "        page.save(path, \"PNG\")\n",
    "        pages.append(path)\n",
    "\n",
    "    return pages\n",
    "\n",
    "pages = split_pdf(PDF_PATH)\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "\n",
    "fig_path = f\"{img_path}/figures\"\n",
    "\n",
    "# detect text, table, and figure using YOLOv11 model\n",
    "def detect_text(pages, model=YOLO(\"../model/yolo11_best.pt\")):\n",
    "    detected_images = []\n",
    "    annotated_images =[]\n",
    "    figures = []\n",
    "    for j, page in enumerate(pages):\n",
    "        image = cv2.imread(page)\n",
    "        results = model(image, conf=0.35, iou=0.7)[0]\n",
    "        detections = sv.Detections.from_ultralytics(results)\n",
    "        detected_images.append(detections)\n",
    "\n",
    "        # save annotated image\n",
    "        annotated_image = image.copy()\n",
    "        annotated_image = sv.BoxAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        annotated_image = sv.LabelAnnotator().annotate(scene=annotated_image, detections=detections)\n",
    "        output_image_path = f\"img/annotated/page_{j+1}_annotated.png\"\n",
    "        cv2.imwrite(output_image_path, annotated_image)\n",
    "        annotated_images.append(output_image_path)\n",
    "\n",
    "    return detected_images, annotated_images, figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 2 figures, 4 texts, 1333.2ms\n",
      "Speed: 150.5ms preprocess, 1333.2ms inference, 175.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 4 texts, 311.5ms\n",
      "Speed: 3.6ms preprocess, 311.5ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 3 figures, 2 tables, 5 texts, 228.7ms\n",
      "Speed: 3.6ms preprocess, 228.7ms inference, 87.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 figures, 7 texts, 304.7ms\n",
      "Speed: 22.4ms preprocess, 304.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 3 tables, 286.1ms\n",
      "Speed: 3.6ms preprocess, 286.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 640x512 1 table, 315.9ms\n",
      "Speed: 4.8ms preprocess, 315.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 480x640 1 figure, 198.9ms\n",
      "Speed: 3.9ms preprocess, 198.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Detections(xyxy=array([[     51.744,      1482.3,      831.68,      1794.4],\n",
       "       [      51.57,      1196.7,        1379,      1450.4],\n",
       "       [     859.08,      1464.7,      1369.8,      1885.4],\n",
       "       [     77.871,      127.42,      1242.6,      299.47],\n",
       "       [     52.838,      502.84,      830.21,      723.21],\n",
       "       [     903.59,       603.6,      1375.6,      1014.9]], dtype=float32), mask=None, confidence=array([    0.89725,     0.85007,     0.77208,     0.67358,     0.43092,     0.42072], dtype=float32), class_id=array([2, 2, 0, 2, 2, 0]), tracker_id=None, data={'class_name': array(['text', 'text', 'figure', 'text', 'text', 'figure'], dtype='<U6')}, metadata={})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_images, annotated_images, figures = detect_text(pages)\n",
    "detected_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
